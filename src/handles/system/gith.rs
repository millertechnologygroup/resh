use anyhow::{Context, Result};
use chrono;
use git2::{
    CredentialType, Cred, FetchOptions, 
    RemoteCallbacks, Repository, BranchType, Status as GitStatus, 
    Index, Signature, Oid, Commit, Time
};
use serde::{Deserialize, Serialize};
use serde_json::{json, Value};
use std::path::{Path, PathBuf};
use std::time::Duration;
use thiserror::Error;
use url::Url;

use crate::core::{
    registry::{Args, Handle, IoStreams},
    status::Status,
};

/// Git handle implementation
#[derive(Debug)]
pub struct GitHandle {
    alias: String,
}

/// Git connection profile for authentication
#[derive(Debug, Clone)]
pub struct GitConnectionProfile {
    pub ssh_key_path: Option<PathBuf>,
    pub known_hosts_path: Option<PathBuf>,
    pub username: Option<String>,
    pub password: Option<String>,
    pub token: Option<String>,
}

/// Clone configuration structure
#[derive(Debug, Clone, Deserialize)]
pub struct CloneConfig {
    pub url: String,
    pub path: String,
    pub branch: Option<String>,
    pub depth: Option<u32>,
    pub recursive: Option<bool>,
    pub ssh_key: Option<String>,
    pub username: Option<String>,
    pub password: Option<String>,
    pub token: Option<String>,
    pub timeout_ms: Option<u32>,
}

/// Pull configuration structure
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct PullConfig {
    pub path: String,
    pub remote: Option<String>,
    pub branch: Option<String>,
    pub rebase: Option<bool>,
    pub ff_only: Option<bool>,
    pub depth: Option<u32>,
    pub prune: Option<bool>,
    pub ssh_key: Option<String>,
    pub username: Option<String>,
    pub password: Option<String>,
    pub token: Option<String>,
    pub timeout_ms: Option<u64>,
}

/// Push configuration structure
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct PushConfig {
    pub path: String,
    pub remote: Option<String>,
    pub branch: Option<String>,
    pub branches: Option<Vec<String>>,
    pub tags: Option<bool>,
    pub force: Option<bool>,
    pub ff_only: Option<bool>,
    pub set_upstream: Option<bool>,
    pub ssh_key: Option<String>,
    pub username: Option<String>,
    pub password: Option<String>,
    pub token: Option<String>,
    pub timeout_ms: Option<u64>,
}

/// Status configuration structure
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct StatusConfig {
    pub path: String,
    pub include_ignored: Option<bool>,
    pub include_untracked: Option<bool>,
    pub include_staged: Option<bool>,
    pub include_branch: Option<bool>,
    pub include_remote: Option<bool>,
    pub timeout_ms: Option<u64>,
}

/// Status short configuration structure
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct StatusShortConfig {
    pub path: String,
    pub branch: Option<String>,
    pub remote: Option<String>,
    pub include_remote: Option<bool>,
    pub include_dirty: Option<bool>,
    pub include_conflicts: Option<bool>,
    pub symbols: Option<StatusShortSymbols>,
    pub timeout_ms: Option<u64>,
}

/// Status short symbols configuration
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct StatusShortSymbols {
    pub detached: Option<String>,
    pub ahead: Option<String>,
    pub behind: Option<String>,
    pub dirty: Option<String>,
    pub conflict: Option<String>,
    pub no_upstream: Option<String>,
}

/// Branch action enumeration
#[derive(Debug, Clone, PartialEq, Deserialize, Serialize)]
#[serde(rename_all = "lowercase")]
pub enum BranchAction {
    List,
    Create,
    Delete,
    Rename,
    Checkout,
}

impl Default for BranchAction {
    fn default() -> Self {
        BranchAction::List
    }
}

/// Branch configuration structure
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct BranchConfig {
    pub path: String,
    pub action: Option<BranchAction>,
    pub name: Option<String>,
    pub new_name: Option<String>,
    pub start_point: Option<String>,
    pub local_only: Option<bool>,
    pub remote_only: Option<bool>,
    pub all: Option<bool>,
    pub force: Option<bool>,
    pub track: Option<bool>,
    pub remote: Option<String>,
    pub timeout_ms: Option<u64>,
}

/// Timestamp for commit operations
#[derive(Debug, Clone, Deserialize, Serialize)]
#[serde(untagged)]
pub enum CommitTimestamp {
    Iso8601(String),
    UnixSeconds(u64),
}

/// Diff mode enumeration
#[derive(Debug, Clone, PartialEq, Deserialize, Serialize)]
#[serde(rename_all = "snake_case")]
pub enum DiffMode {
    WorkdirVsIndex,
    IndexVsHead,
    HeadVsWorkdir,
    CommitVsCommit,
    CommitVsWorkdir,
    CommitVsIndex,
}

impl Default for DiffMode {
    fn default() -> Self {
        DiffMode::WorkdirVsIndex
    }
}

/// Commit configuration structure
#[derive(Debug, Clone, Deserialize)]
pub struct CommitConfig {
    pub path: String,
    pub message: Option<String>,
    pub all: Option<bool>,
    pub paths: Option<Vec<String>>,
    pub allow_empty: Option<bool>,
    pub author_name: Option<String>,
    pub author_email: Option<String>,
    pub committer_name: Option<String>,
    pub committer_email: Option<String>,
    pub signoff: Option<bool>,
    pub amend: Option<bool>,
    pub no_edit: Option<bool>,
    pub timestamp: Option<CommitTimestamp>,
    pub timeout_ms: Option<u64>,
}

/// Diff configuration structure
#[derive(Debug, Clone, Deserialize)]
pub struct DiffConfig {
    pub path: String,
    pub mode: Option<DiffMode>,
    pub from: Option<String>,
    pub to: Option<String>,
    pub paths: Option<Vec<String>>,
    pub unified: Option<i32>,
    pub ignore_whitespace: Option<bool>,
    pub ignore_whitespace_change: Option<bool>,
    pub ignore_whitespace_eol: Option<bool>,
    pub detect_renames: Option<bool>,
    pub rename_threshold: Option<u8>,
    pub binary: Option<bool>,
    pub max_files: Option<u32>,
    pub max_hunks: Option<u32>,
    pub timeout_ms: Option<u64>,
}

/// Tag action enumeration
#[derive(Debug, Clone, PartialEq, Deserialize, Serialize)]
#[serde(rename_all = "lowercase")]
pub enum TagAction {
    List,
    Create,
    Delete,
}

impl Default for TagAction {
    fn default() -> Self {
        TagAction::List
    }
}

/// Tag sort enumeration
#[derive(Debug, Clone, PartialEq, Deserialize, Serialize)]
#[serde(rename_all = "lowercase")]
pub enum TagSort {
    Name,
    Version,
    TaggerDate,
    CommitterDate,
}

impl Default for TagSort {
    fn default() -> Self {
        TagSort::Name
    }
}

/// Timestamp for tag operations
#[derive(Debug, Clone, Deserialize, Serialize)]
#[serde(untagged)]
pub enum TagTimestamp {
    Iso8601(String),
    UnixSeconds(u64),
}

/// Tag configuration structure
#[derive(Debug, Clone, Deserialize)]
pub struct TagConfig {
    pub path: String,
    pub action: Option<TagAction>,
    pub name: Option<String>,
    pub names: Option<Vec<String>>,
    pub pattern: Option<String>,
    pub sort: Option<TagSort>,
    pub annotated: Option<bool>,
    pub message: Option<String>,
    pub target: Option<String>,
    pub force: Option<bool>,
    pub author_name: Option<String>,
    pub author_email: Option<String>,
    pub timestamp: Option<TagTimestamp>,
    pub timeout_ms: Option<u64>,
}

/// Author/committer information
#[derive(Debug, Serialize, Deserialize)]
pub struct CommitIdentity {
    pub name: String,
    pub email: String,
}

/// Commit information in result
#[derive(Debug, Serialize, Deserialize)]
pub struct CommitInfo {
    pub oid: String,
    pub message: String,
    pub author: CommitIdentity,
    pub committer: CommitIdentity,
    pub amend: bool,
    pub allow_empty: bool,
}

/// Commit statistics
#[derive(Debug, Serialize, Deserialize)]
pub struct CommitStats {
    pub staged_files: usize,
    pub insertions: Option<usize>,
    pub deletions: Option<usize>,
}

/// Commit result structure
#[derive(Debug, Serialize, Deserialize)]
pub struct CommitResult {
    pub backend: String,
    pub alias: String,
    pub path: String,
    pub action: String,
    pub commit: CommitInfo,
    pub stats: CommitStats,
}

/// Diff line structure
#[derive(Debug, Serialize, Deserialize)]
pub struct DiffLine {
    #[serde(rename = "type")]
    pub line_type: String,  // "context" | "add" | "delete"
    pub content: String,
}

/// Diff hunk structure
#[derive(Debug, Serialize, Deserialize)]
pub struct DiffHunk {
    pub old_start: u32,
    pub old_lines: u32,
    pub new_start: u32,
    pub new_lines: u32,
    pub lines: Vec<DiffLine>,
}

/// Diff file structure
#[derive(Debug, Serialize, Deserialize)]
pub struct DiffFile {
    pub old_path: Option<String>,
    pub new_path: Option<String>,
    pub status: String,  // "added" | "deleted" | "modified" | "renamed" | "copied" | "typechange"
    pub is_binary: bool,
    pub hunks: Vec<DiffHunk>,
}

/// Diff summary structure
#[derive(Debug, Serialize, Deserialize)]
pub struct DiffSummary {
    pub files_changed: u32,
    pub insertions: u32,
    pub deletions: u32,
    pub truncated: bool,
}

/// Diff result structure
#[derive(Debug, Serialize, Deserialize)]
pub struct DiffResult {
    pub backend: String,
    pub alias: String,
    pub path: String,
    pub mode: String,
    pub from: String,
    pub to: String,
    pub summary: DiffSummary,
    pub files: Vec<DiffFile>,
}

/// Clone result structure
#[derive(Debug, Serialize)]
pub struct CloneResult {
    pub backend: String,
    pub alias: String,
    pub url: String,
    pub path: String,
    pub branch: Option<String>,
    pub depth: Option<u32>,
    pub recursive: bool,
    pub status: String,
}

/// Pull result structure
#[derive(Debug, Serialize, Deserialize)]
pub struct PullResult {
    pub backend: String,
    pub alias: String,
    pub path: String,
    pub remote: String,
    pub branch: String,
    pub status: String, // "updated" | "up_to_date"
    pub rebase: bool,
    pub ff_only: bool,
    pub ahead_by: Option<usize>,
    pub behind_by: Option<usize>,
    pub commits_fetched: Option<usize>,
}

/// Branch status for push operation
#[derive(Debug, Serialize, Deserialize)]
pub struct PushBranchStatus {
    pub name: String,
    pub status: String, // "pushed" | "up_to_date"
    pub ahead_by: usize,
    pub behind_by: usize,
}

/// Push result structure
#[derive(Debug, Serialize, Deserialize)]
pub struct PushResult {
    pub backend: String,
    pub alias: String,
    pub path: String,
    pub remote: String,
    pub branches: Vec<PushBranchStatus>,
    pub tags_pushed: bool,
}

/// File status entry for status operation
#[derive(Debug, Serialize, Deserialize)]
pub struct FileStatus {
    pub path: String,
    pub status: String,
}

/// Upstream information for a branch
#[derive(Debug, Serialize, Deserialize)]
pub struct UpstreamInfo {
    pub name: String,
    pub remote: String,
    pub ahead_by: usize,
    pub behind_by: usize,
}

/// Branch information for status operation
#[derive(Debug, Serialize, Deserialize)]
pub struct BranchInfo {
    pub name: Option<String>,
    pub detached: bool,
    pub head: String,
    pub upstream: Option<UpstreamInfo>,
}

/// Working tree status information
#[derive(Debug, Serialize, Deserialize)]
pub struct WorkingTreeStatus {
    pub clean: bool,
    pub staged: Vec<FileStatus>,
    pub unstaged: Vec<FileStatus>,
    pub untracked: Vec<FileStatus>,
    pub ignored: Vec<FileStatus>,
    pub conflicts: Vec<FileStatus>,
}

/// In-progress operation flags
#[derive(Debug, Serialize, Deserialize)]
pub struct InProgressFlags {
    pub merge: bool,
    pub rebase: bool,
    pub cherry_pick: bool,
    pub revert: bool,
    pub bisect: bool,
}

/// Status result structure
#[derive(Debug, Serialize, Deserialize)]
pub struct StatusResult {
    pub backend: String,
    pub alias: String,
    pub path: String,
    pub branch: Option<BranchInfo>,
    pub working_tree: WorkingTreeStatus,
    pub in_progress: InProgressFlags,
}

/// Branch upstream information for branch operation
#[derive(Debug, Serialize, Deserialize)]
pub struct BranchUpstreamInfo {
    pub remote: String,
    pub name: String,
    pub full_ref: String,
}

/// Individual branch information for branch list
#[derive(Debug, Serialize, Deserialize)]
pub struct BranchListEntry {
    pub name: String,
    pub full_ref: String,
    pub is_remote: bool,
    pub is_current: bool,
    pub upstream: Option<BranchUpstreamInfo>,
    pub head: String,
}

/// Branch list result structure
#[derive(Debug, Serialize, Deserialize)]
pub struct BranchListResult {
    pub backend: String,
    pub alias: String,
    pub path: String,
    pub action: String,
    pub branches: Vec<BranchListEntry>,
}

/// Branch operation result structure (for create/delete/rename/checkout)
#[derive(Debug, Serialize, Deserialize)]
pub struct BranchOpResult {
    pub backend: String,
    pub alias: String,
    pub path: String,
    pub action: String,
    pub status: String,
    pub branch: serde_json::Value,
}

/// Tag target information
#[derive(Debug, Serialize, Deserialize)]
pub struct TagTarget {
    pub oid: String,
    #[serde(rename = "type")]
    pub object_type: String,  // "commit" | "tag" | "tree" | "blob"
}

/// Tag tagger information
#[derive(Debug, Serialize, Deserialize)]
pub struct TagTagger {
    pub name: String,
    pub email: String,
    pub timestamp: String,
}

/// Tag entry in results
#[derive(Debug, Serialize, Deserialize)]
pub struct TagEntry {
    pub name: String,
    pub annotated: bool,
    pub message: Option<String>,
    pub target: TagTarget,
    pub tagger: Option<TagTagger>,
}

/// Tag list result structure
#[derive(Debug, Serialize, Deserialize)]
pub struct TagListResult {
    pub backend: String,
    pub alias: String,
    pub path: String,
    pub action: String,
    pub pattern: Option<String>,
    pub sort: String,
    pub tags: Vec<TagEntry>,
    pub count: usize,
}

/// Tag create result structure
#[derive(Debug, Serialize, Deserialize)]
pub struct TagCreateResult {
    pub backend: String,
    pub alias: String,
    pub path: String,
    pub action: String,
    pub tag: TagEntry,
    pub status: String,  // "created" | "overwritten"
    pub force: bool,
}

/// Tag delete result structure
#[derive(Debug, Serialize, Deserialize)]
pub struct TagDeleteResult {
    pub backend: String,
    pub alias: String,
    pub path: String,
    pub action: String,
    pub requested: Vec<String>,
    pub deleted: Vec<String>,
    pub missing: Vec<String>,
    pub force: bool,
}

/// Merge configuration structure
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct MergeConfig {
    pub path: String,
    pub source: String,
    pub target: Option<String>,
    pub ff_only: Option<bool>,
    pub no_ff: Option<bool>,
    pub squash: Option<bool>,
    pub commit_message: Option<String>,
    pub author_name: Option<String>,
    pub author_email: Option<String>,
    pub committer_name: Option<String>,
    pub committer_email: Option<String>,
    pub allow_uncommitted: Option<bool>,
    pub abort_on_conflict: Option<bool>,
    pub timeout_ms: Option<u64>,
}

/// Merge result structure
#[derive(Debug, Serialize, Deserialize)]
pub struct MergeResult {
    pub backend: String,
    pub alias: String,
    pub path: String,
    pub action: String,
    pub source: String,
    pub target: String,
    pub mode: String,      // "fast_forward" | "normal" | "squash" | "up_to_date"
    pub status: String,    // "merged" | "fast_forward" | "squashed" | "up_to_date"
    pub ff_only: bool,
    pub no_ff: bool,
    pub squash: bool,
    pub commit: Option<CommitInfo>,
}

/// Rebase operation type
#[derive(Debug, Clone, PartialEq, Deserialize, Serialize)]
#[serde(rename_all = "lowercase")]
pub enum RebaseOperation {
    Start,
    Continue,
    Abort,
}

impl Default for RebaseOperation {
    fn default() -> Self {
        RebaseOperation::Start
    }
}

/// Rebase configuration structure
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct RebaseConfig {
    pub path: String,
    pub operation: Option<RebaseOperation>,
    pub branch: Option<String>,
    pub upstream: Option<String>,
    pub ff_only: Option<bool>,
    pub preserve_merges: Option<bool>,
    pub autosquash: Option<bool>,
    pub allow_uncommitted: Option<bool>,
    pub abort_on_conflict: Option<bool>,
    pub author_name: Option<String>,
    pub author_email: Option<String>,
    pub committer_name: Option<String>,
    pub committer_email: Option<String>,
    pub timeout_ms: Option<u64>,
}

/// Pull strategy for sync operations
#[derive(Debug, Clone, PartialEq, Deserialize, Serialize)]
#[serde(rename_all = "snake_case")]
pub enum PullStrategy {
    Rebase,
    Merge,
    FfOnly,
}

impl Default for PullStrategy {
    fn default() -> Self {
        PullStrategy::Rebase
    }
}

/// Sync configuration structure
#[derive(Debug, Clone, Deserialize)]
pub struct SyncConfig {
    pub path: String,
    pub remote: Option<String>,
    pub branch: Option<String>,
    pub remote_branch: Option<String>,
    pub pull_strategy: Option<PullStrategy>,
    pub ff_only: Option<bool>,
    pub allow_uncommitted: Option<bool>,
    pub stash_uncommitted: Option<bool>,
    pub abort_on_conflict: Option<bool>,
    pub push: Option<bool>,
    pub push_tags: Option<bool>,
    pub force_push: Option<bool>,
    pub set_upstream: Option<bool>,
    pub dry_run: Option<bool>,
    pub timeout_ms: Option<u64>,
}

/// Status summary configuration structure
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct StatusSummaryConfig {
    pub path: String,
    pub remote: Option<String>,
    pub branch: Option<String>,
    pub include_untracked: Option<bool>,
    pub include_ignored: Option<bool>,
    pub include_remote: Option<bool>,
    pub compute_diffstats: Option<bool>,
    pub max_files: Option<u32>,
    pub timeout_ms: Option<u64>,
}

/// Git-specific error types
#[derive(Error, Debug)]
pub enum GitError {
    #[error("connection not found: alias '{alias}' is not configured")]
    ConnectionNotFound { alias: String },

    #[error("invalid clone config: {message}")]
    InvalidCloneConfig { message: String },

    #[error("clone failed: {message}")]
    CloneFailed { message: String },

    #[error("authentication failed: {message}")]
    CloneAuthFailed { message: String },

    #[error("clone operation timed out after {timeout_ms}ms")]
    CloneTimeout { timeout_ms: u32 },

    #[error("clone target directory is not empty: {path}")]
    CloneTargetNotEmpty { path: String },

    #[error("unsupported git backend")]
    CloneUnsupportedBackend,

    // Pull-specific errors
    #[error("invalid pull config: {message}")]
    InvalidPullConfig { message: String },

    #[error("repository not found: {path}")]
    RepositoryNotFound { path: String },

    #[error("remote not found: {remote}")]
    RemoteNotFound { remote: String },

    #[error("remote branch not found: {branch}")]
    PullRemoteBranchNotFound { branch: String },

    #[error("pull from detached HEAD state requires explicit branch")]
    PullDetachedHead,

    #[error("pull fetch failed: {message}")]
    PullFetchFailed { message: String },

    #[error("pull authentication failed: {message}")]
    PullAuthFailed { message: String },

    #[error("dirty working tree prevents safe pull")]
    PullDirtyWorktree,

    #[error("non-fast-forward pull refused with ff_only=true")]
    PullNonFastForward,

    #[error("merge conflicts detected during pull")]
    PullConflict,

    #[error("pull operation timed out after {timeout_ms}ms")]
    PullTimeout { timeout_ms: u64 },

    #[error("pull operation failed: {message}")]
    PullFailed { message: String },

    // Push-specific errors
    #[error("invalid push config: {message}")]
    InvalidPushConfig { message: String },

    #[error("push from detached HEAD state requires explicit branch")]
    PushDetachedHead,

    #[error("push local branch not found: {branch}")]
    PushLocalBranchNotFound { branch: String },

    #[error("push would not be fast-forward and ff_only=true")]
    PushNonFastForward,

    #[error("push authentication failed: {message}")]
    PushAuthFailed { message: String },

    #[error("push rejected by remote: {message}")]
    PushRejected { message: String },

    #[error("push operation failed: {message}")]
    PushFailed { message: String },

    #[error("push operation timed out after {timeout_ms}ms")]
    PushTimeout { timeout_ms: u64 },

    // Status-specific errors
    #[error("invalid status config: {message}")]
    InvalidStatusConfig { message: String },

    #[error("status operation timed out after {timeout_ms}ms")]
    StatusTimeout { timeout_ms: u64 },

    #[error("status operation failed: {message}")]
    StatusFailed { message: String },

    // Status short-specific errors
    #[error("invalid status_short config: {message}")]
    InvalidStatusShortConfig { message: String },

    #[error("status_short branch not found: {branch}")]
    StatusShortBranchNotFound { branch: String },

    #[error("status_short operation timed out after {timeout_ms}ms")]
    StatusShortTimeout { timeout_ms: u64 },

    #[error("status_short operation failed: {message}")]
    StatusShortFailed { message: String },

    // Branch-specific errors
    #[error("invalid branch config: {message}")]
    InvalidBranchConfig { message: String },

    #[error("branch not found: {name}")]
    BranchNotFound { name: String },

    #[error("branch already exists: {name}")]
    BranchAlreadyExists { name: String },

    #[error("branch start point not found: {start_point}")]
    BranchStartpointNotFound { start_point: String },

    #[error("cannot delete current branch: {name}")]
    BranchDeleteCurrent { name: String },

    #[error("cannot delete unmerged branch: {name}")]
    BranchDeleteUnmerged { name: String },

    #[error("branch delete operation failed: {message}")]
    BranchDeleteFailed { message: String },

    #[error("branch rename operation failed: {message}")]
    BranchRenameFailed { message: String },

    #[error("failed to set upstream tracking: {message}")]
    BranchSetUpstreamFailed { message: String },

    #[error("checkout would overwrite local changes")]
    BranchCheckoutConflict,

    #[error("branch checkout failed: {message}")]
    BranchCheckoutFailed { message: String },

    #[error("branch operation timed out after {timeout_ms}ms")]
    BranchTimeout { timeout_ms: u64 },

    #[error("branch operation failed: {message}")]
    BranchFailed { message: String },

    // Commit-specific errors
    #[error("invalid commit config: {message}")]
    InvalidCommitConfig { message: String },

    #[error("no valid author identity found")]
    CommitIdentityMissing,

    #[error("no changes to commit and allow_empty is false")]
    CommitNothingToCommit { path: String },

    #[error("cannot amend without existing HEAD commit")]
    CommitAmendWithoutHead,

    #[error("amend operation failed: {message}")]
    CommitAmendFailed { message: String },

    #[error("commit operation failed: {message}")]
    CommitFailed { message: String },

    #[error("commit operation timed out after {timeout_ms}ms")]
    CommitTimeout { timeout_ms: u64 },

    // Diff-specific errors
    #[error("invalid diff config: {message}")]
    InvalidDiffConfig { message: String },

    #[error("diff reference not found: {reference}")]
    DiffRefNotFound { reference: String },

    #[error("diff HEAD not found: repository has no commits")]
    DiffHeadNotFound,

    #[error("diff operation failed: {message}")]
    DiffFailed { message: String },

    #[error("diff operation timed out after {timeout_ms}ms")]
    DiffTimeout { timeout_ms: u64 },

    // Tag-specific errors
    #[error("invalid tag config: {message}")]
    InvalidTagConfig { message: String },

    #[error("tag target not found: {target}")]
    TagTargetNotFound { target: String },

    #[error("tag identity missing")]
    TagIdentityMissing,

    #[error("tag already exists: {name}")]
    TagAlreadyExists { name: String },

    #[error("tag not found: {name}")]
    TagNotFound { name: String },

    #[error("tag delete operation failed: {message}")]
    TagDeleteFailed { message: String },

    #[error("tag list operation failed: {message}")]
    TagListFailed { message: String },

    #[error("tag create operation failed: {message}")]
    TagCreateFailed { message: String },

    #[error("tag operation timed out after {timeout_ms}ms")]
    TagTimeout { timeout_ms: u64 },

    #[error("tag operation failed: {message}")]
    TagFailed { message: String },

    // Merge-specific errors
    #[error("invalid merge config: {message}")]
    InvalidMergeConfig { message: String },

    #[error("merge from detached HEAD requires explicit target")]
    MergeDetachedHead,

    #[error("merge source not found: {0}")]
    MergeSourceNotFound(String),

    #[error("merge source is not a commit: {0}")]
    MergeSourceNotCommit(String),

    #[error("merge target branch not found: {0}")]
    MergeTargetNotFound(String),

    #[error("dirty working tree prevents merge")]
    MergeDirtyWorktree,

    #[error("non-fast-forward merge refused with ff_only=true")]
    MergeNonFastForward,

    #[error("no valid merge identity found")]
    MergeIdentityMissing,

    #[error("merge conflicts detected")]
    MergeConflict,

    #[error("merge operation failed: {message}")]
    MergeFailed { message: String },

    #[error("merge operation timed out after {timeout_ms}ms")]
    MergeTimeout { timeout_ms: u64 },

    // Rebase-specific errors
    #[error("invalid rebase config: {message}")]
    InvalidRebaseConfig { message: String },

    #[error("rebase operation already in progress")]
    RebaseInProgress,

    #[error("no rebase operation in progress")]
    RebaseNotInProgress,

    #[error("rebase from detached HEAD requires explicit branch")]
    RebaseDetachedHead,

    #[error("rebase branch not found: {branch}")]
    RebaseBranchNotFound { branch: String },

    #[error("rebase upstream not found: {upstream}")]
    RebaseUpstreamNotFound { upstream: String },

    #[error("rebase upstream is not a commit: {upstream}")]
    RebaseUpstreamNotCommit { upstream: String },

    #[error("non-fast-forward rebase refused with ff_only=true")]
    RebaseNonFastForward,

    #[error("dirty working tree prevents rebase")]
    RebaseDirtyWorktree,

    #[error("no valid rebase identity found")]
    RebaseIdentityMissing,

    #[error("rebase conflicts detected")]
    RebaseConflict,

    #[error("preserve merges option is not supported")]
    RebasePreserveMergesUnsupported,

    #[error("rebase operation failed: {message}")]
    RebaseFailed { message: String },

    #[error("rebase operation timed out after {timeout_ms}ms")]
    RebaseTimeout { timeout_ms: u64 },

    // Sync-specific errors
    #[error("invalid sync config: {message}")]
    InvalidSyncConfig { message: String },

    #[error("sync from detached HEAD state requires explicit branch")]
    SyncDetachedHead,

    #[error("sync branch not found: {branch}")]
    SyncBranchNotFound { branch: String },

    #[error("sync remote not found: {remote}")]
    SyncRemoteNotFound { remote: String },

    #[error("sync upstream not found for branch")]
    SyncUpstreamNotFound,

    #[error("dirty working tree prevents sync")]
    SyncDirtyWorktree,

    #[error("non-fast-forward sync refused with ff_only strategy")]
    SyncNonFastForward,

    #[error("sync pull failed: {message}")]
    SyncPullFailed { message: String },

    #[error("sync conflicts detected")]
    SyncConflict,

    #[error("sync push rejected: {message}")]
    SyncPushRejected { message: String },

    #[error("sync push failed: {message}")]
    SyncPushFailed { message: String },

    #[error("sync stash apply conflicts detected")]
    SyncStashApplyConflict,

    #[error("sync operation timed out after {timeout_ms}ms")]
    SyncTimeout { timeout_ms: u64 },

    #[error("sync operation failed: {message}")]
    SyncFailed { message: String },

    // Status Summary-specific errors
    #[error("invalid status summary config: {message}")]
    InvalidStatusSummaryConfig { message: String },

    #[error("status summary branch not found: {name}")]
    StatusSummaryBranchNotFound { name: String },

    #[error("status summary operation timed out after {timeout_ms}ms")]
    StatusSummaryTimeout { timeout_ms: u64 },

    #[error("status summary operation failed: {message}")]
    StatusSummaryFailed { message: String },
}

impl From<GitError> for crate::core::status::ShellError {
    fn from(err: GitError) -> Self {
        let details = match &err {
            GitError::ConnectionNotFound { alias } => {
                json!({ "alias": alias })
            }
            GitError::InvalidCloneConfig { .. } => json!({}),
            GitError::CloneFailed { .. } => json!({}),
            GitError::CloneAuthFailed { .. } => json!({}),
            GitError::CloneTimeout { timeout_ms } => {
                json!({ "timeout_ms": timeout_ms })
            }
            GitError::CloneTargetNotEmpty { path } => {
                json!({ "path": path })
            }
            GitError::CloneUnsupportedBackend => json!({}),
            GitError::InvalidPullConfig { .. } => json!({}),
            GitError::RepositoryNotFound { path } => {
                json!({ "path": path })
            }
            GitError::RemoteNotFound { remote } => {
                json!({ "remote": remote })
            }
            GitError::PullRemoteBranchNotFound { branch } => {
                json!({ "branch": branch })
            }
            GitError::PullDetachedHead => json!({}),
            GitError::PullFetchFailed { .. } => json!({}),
            GitError::PullAuthFailed { .. } => json!({}),
            GitError::PullDirtyWorktree => json!({}),
            GitError::PullNonFastForward => json!({}),
            GitError::PullConflict => json!({}),
            GitError::PullTimeout { timeout_ms } => {
                json!({ "timeout_ms": timeout_ms })
            }
            GitError::PullFailed { .. } => json!({}),
            GitError::InvalidPushConfig { .. } => json!({}),
            GitError::PushDetachedHead => json!({}),
            GitError::PushLocalBranchNotFound { branch } => {
                json!({ "branch": branch })
            }
            GitError::PushNonFastForward => json!({}),
            GitError::PushAuthFailed { .. } => json!({}),
            GitError::PushRejected { .. } => json!({}),
            GitError::PushFailed { .. } => json!({}),
            GitError::PushTimeout { timeout_ms } => {
                json!({ "timeout_ms": timeout_ms })
            }
            GitError::InvalidStatusConfig { .. } => json!({}),
            GitError::StatusTimeout { timeout_ms } => {
                json!({ "timeout_ms": timeout_ms })
            }
            GitError::StatusFailed { .. } => json!({}),
            GitError::InvalidBranchConfig { .. } => json!({}),
            GitError::BranchNotFound { name } => {
                json!({ "name": name })
            }
            GitError::BranchAlreadyExists { name } => {
                json!({ "name": name })
            }
            GitError::BranchStartpointNotFound { start_point } => {
                json!({ "start_point": start_point })
            }
            GitError::BranchDeleteCurrent { name } => {
                json!({ "name": name })
            }
            GitError::BranchDeleteUnmerged { name } => {
                json!({ "name": name })
            }
            GitError::BranchDeleteFailed { .. } => json!({}),
            GitError::BranchRenameFailed { .. } => json!({}),
            GitError::BranchSetUpstreamFailed { .. } => json!({}),
            GitError::BranchCheckoutConflict => json!({}),
            GitError::BranchCheckoutFailed { .. } => json!({}),
            GitError::BranchTimeout { timeout_ms } => {
                json!({ "timeout_ms": timeout_ms })
            }
            GitError::BranchFailed { .. } => json!({}),
            GitError::InvalidCommitConfig { .. } => json!({}),
            GitError::CommitIdentityMissing => json!({}),
            GitError::CommitNothingToCommit { path } => {
                json!({ "path": path })
            }
            GitError::CommitAmendWithoutHead => json!({}),
            GitError::CommitAmendFailed { .. } => json!({}),
            GitError::CommitFailed { .. } => json!({}),
            GitError::CommitTimeout { timeout_ms } => {
                json!({ "timeout_ms": timeout_ms })
            }
            GitError::InvalidDiffConfig { .. } => json!({}),
            GitError::DiffRefNotFound { reference } => {
                json!({ "reference": reference })
            }
            GitError::DiffHeadNotFound => json!({}),
            GitError::DiffFailed { .. } => json!({}),
            GitError::DiffTimeout { timeout_ms } => {
                json!({ "timeout_ms": timeout_ms })
            }
            GitError::InvalidTagConfig { .. } => json!({}),
            GitError::TagTargetNotFound { target } => {
                json!({ "target": target })
            }
            GitError::TagIdentityMissing => json!({}),
            GitError::TagAlreadyExists { name } => {
                json!({ "name": name })
            }
            GitError::TagNotFound { name } => {
                json!({ "name": name })
            }
            GitError::TagDeleteFailed { .. } => json!({}),
            GitError::TagListFailed { .. } => json!({}),
            GitError::TagCreateFailed { .. } => json!({}),
            GitError::TagTimeout { timeout_ms } => {
                json!({ "timeout_ms": timeout_ms })
            }
            GitError::TagFailed { .. } => json!({}),
            GitError::InvalidMergeConfig { .. } => json!({}),
            GitError::MergeDetachedHead => json!({}),
            GitError::MergeSourceNotFound(source) => {
                json!({ "source": source })
            }
            GitError::MergeSourceNotCommit(source) => {
                json!({ "source": source })
            }
            GitError::MergeTargetNotFound(target) => {
                json!({ "target": target })
            }
            GitError::MergeDirtyWorktree => json!({}),
            GitError::MergeNonFastForward => json!({}),
            GitError::MergeIdentityMissing => json!({}),
            GitError::MergeConflict => json!({}),
            GitError::MergeFailed { .. } => json!({}),
            GitError::MergeTimeout { timeout_ms } => {
                json!({ "timeout_ms": timeout_ms })
            }
            GitError::InvalidRebaseConfig { .. } => json!({}),
            GitError::RebaseInProgress => json!({}),
            GitError::RebaseNotInProgress => json!({}),
            GitError::RebaseDetachedHead => json!({}),
            GitError::RebaseBranchNotFound { branch } => {
                json!({ "branch": branch })
            }
            GitError::RebaseUpstreamNotFound { upstream } => {
                json!({ "upstream": upstream })
            }
            GitError::RebaseUpstreamNotCommit { upstream } => {
                json!({ "upstream": upstream })
            }
            GitError::RebaseNonFastForward => json!({}),
            GitError::RebaseDirtyWorktree => json!({}),
            GitError::RebaseIdentityMissing => json!({}),
            GitError::RebaseConflict => json!({}),
            GitError::RebasePreserveMergesUnsupported => json!({}),
            GitError::RebaseFailed { .. } => json!({}),
            GitError::RebaseTimeout { timeout_ms } => {
                json!({ "timeout_ms": timeout_ms })
            }
            GitError::InvalidSyncConfig { .. } => json!({}),
            GitError::SyncDetachedHead => json!({}),
            GitError::SyncBranchNotFound { branch } => {
                json!({ "branch": branch })
            }
            GitError::SyncRemoteNotFound { remote } => {
                json!({ "remote": remote })
            }
            GitError::SyncUpstreamNotFound => json!({}),
            GitError::SyncDirtyWorktree => json!({}),
            GitError::SyncNonFastForward => json!({}),
            GitError::SyncPullFailed { .. } => json!({}),
            GitError::SyncConflict => json!({}),
            GitError::SyncPushRejected { .. } => json!({}),
            GitError::SyncPushFailed { .. } => json!({}),
            GitError::SyncStashApplyConflict => json!({}),
            GitError::SyncTimeout { timeout_ms } => {
                json!({ "timeout_ms": timeout_ms })
            }
            GitError::SyncFailed { .. } => json!({}),
            // Status Summary error details
            GitError::InvalidStatusSummaryConfig { .. } => json!({}),
            GitError::StatusSummaryBranchNotFound { name } => {
                json!({ "name": name })
            }
            GitError::StatusSummaryTimeout { timeout_ms } => {
                json!({ "timeout_ms": timeout_ms })
            }
            GitError::StatusSummaryFailed { .. } => json!({}),
            // Status short error details
            GitError::InvalidStatusShortConfig { .. } => json!({}),
            GitError::StatusShortBranchNotFound { branch } => {
                json!({ "branch": branch })
            }
            GitError::StatusShortTimeout { timeout_ms } => {
                json!({ "timeout_ms": timeout_ms })
            }
            GitError::StatusShortFailed { .. } => json!({}),
        };

        let code = match err {
            GitError::ConnectionNotFound { .. } => "git.connection_not_found",
            GitError::InvalidCloneConfig { .. } => "git.invalid_clone_config",
            GitError::CloneFailed { .. } => "git.clone_failed",
            GitError::CloneAuthFailed { .. } => "git.clone_auth_failed",
            GitError::CloneTimeout { .. } => "git.clone_timeout",
            GitError::CloneTargetNotEmpty { .. } => "git.clone_target_not_empty",
            GitError::CloneUnsupportedBackend => "git.clone_unsupported_backend",
            GitError::InvalidPullConfig { .. } => "git.invalid_pull_config",
            GitError::RepositoryNotFound { .. } => "git.repository_not_found",
            GitError::RemoteNotFound { .. } => "git.remote_not_found",
            GitError::PullRemoteBranchNotFound { .. } => "git.pull_remote_branch_not_found",
            GitError::PullDetachedHead => "git.pull_detached_head",
            GitError::PullFetchFailed { .. } => "git.pull_fetch_failed",
            GitError::PullAuthFailed { .. } => "git.pull_auth_failed",
            GitError::PullDirtyWorktree => "git.pull_dirty_worktree",
            GitError::PullNonFastForward => "git.pull_non_fast_forward",
            GitError::PullConflict => "git.pull_conflict",
            GitError::PullTimeout { .. } => "git.pull_timeout",
            GitError::PullFailed { .. } => "git.pull_failed",
            GitError::InvalidPushConfig { .. } => "git.invalid_push_config",
            GitError::PushDetachedHead => "git.push_detached_head",
            GitError::PushLocalBranchNotFound { .. } => "git.push_local_branch_not_found",
            GitError::PushNonFastForward => "git.push_non_fast_forward",
            GitError::PushAuthFailed { .. } => "git.push_auth_failed",
            GitError::PushRejected { .. } => "git.push_rejected",
            GitError::PushFailed { .. } => "git.push_failed",
            GitError::PushTimeout { .. } => "git.push_timeout",
            GitError::InvalidStatusConfig { .. } => "git.invalid_status_config",
            GitError::StatusTimeout { .. } => "git.status_timeout",
            GitError::StatusFailed { .. } => "git.status_failed",
            GitError::InvalidBranchConfig { .. } => "git.invalid_branch_config",
            GitError::BranchNotFound { .. } => "git.branch_not_found",
            GitError::BranchAlreadyExists { .. } => "git.branch_already_exists",
            GitError::BranchStartpointNotFound { .. } => "git.branch_startpoint_not_found",
            GitError::BranchDeleteCurrent { .. } => "git.branch_delete_current",
            GitError::BranchDeleteUnmerged { .. } => "git.branch_delete_unmerged",
            GitError::BranchDeleteFailed { .. } => "git.branch_delete_failed",
            GitError::BranchRenameFailed { .. } => "git.branch_rename_failed",
            GitError::BranchSetUpstreamFailed { .. } => "git.branch_set_upstream_failed",
            GitError::BranchCheckoutConflict => "git.branch_checkout_conflict",
            GitError::BranchCheckoutFailed { .. } => "git.branch_checkout_failed",
            GitError::BranchTimeout { .. } => "git.branch_timeout",
            GitError::BranchFailed { .. } => "git.branch_failed",
            GitError::InvalidCommitConfig { .. } => "git.invalid_commit_config",
            GitError::CommitIdentityMissing => "git.commit_identity_missing",
            GitError::CommitNothingToCommit { .. } => "git.commit_nothing_to_commit",
            GitError::CommitAmendWithoutHead => "git.commit_amend_without_head",
            GitError::CommitAmendFailed { .. } => "git.commit_amend_failed",
            GitError::CommitFailed { .. } => "git.commit_failed",
            GitError::CommitTimeout { .. } => "git.commit_timeout",
            GitError::InvalidDiffConfig { .. } => "git.invalid_diff_config",
            GitError::DiffRefNotFound { .. } => "git.diff_ref_not_found",
            GitError::DiffHeadNotFound => "git.diff_head_not_found",
            GitError::DiffFailed { .. } => "git.diff_failed",
            GitError::DiffTimeout { .. } => "git.diff_timeout",
            GitError::InvalidTagConfig { .. } => "git.invalid_tag_config",
            GitError::TagTargetNotFound { .. } => "git.tag_target_not_found",
            GitError::TagIdentityMissing => "git.tag_identity_missing",
            GitError::TagAlreadyExists { .. } => "git.tag_already_exists",
            GitError::TagNotFound { .. } => "git.tag_not_found",
            GitError::TagDeleteFailed { .. } => "git.tag_delete_failed",
            GitError::TagListFailed { .. } => "git.tag_list_failed",
            GitError::TagCreateFailed { .. } => "git.tag_create_failed",
            GitError::TagTimeout { .. } => "git.tag_timeout",
            GitError::TagFailed { .. } => "git.tag_failed",
            GitError::InvalidMergeConfig { .. } => "git.invalid_merge_config",
            GitError::MergeDetachedHead => "git.merge_detached_head",
            GitError::MergeSourceNotFound(..) => "git.merge_source_not_found",
            GitError::MergeSourceNotCommit(..) => "git.merge_source_not_commit",
            GitError::MergeTargetNotFound(..) => "git.merge_target_not_found",
            GitError::MergeDirtyWorktree => "git.merge_dirty_worktree",
            GitError::MergeNonFastForward => "git.merge_non_fast_forward",
            GitError::MergeIdentityMissing => "git.merge_identity_missing",
            GitError::MergeConflict => "git.merge_conflict",
            GitError::MergeFailed { .. } => "git.merge_failed",
            GitError::MergeTimeout { .. } => "git.merge_timeout",
            GitError::InvalidRebaseConfig { .. } => "git.invalid_rebase_config",
            GitError::RebaseInProgress => "git.rebase_in_progress",
            GitError::RebaseNotInProgress => "git.rebase_not_in_progress",
            GitError::RebaseDetachedHead => "git.rebase_detached_head",
            GitError::RebaseBranchNotFound { .. } => "git.rebase_branch_not_found",
            GitError::RebaseUpstreamNotFound { .. } => "git.rebase_upstream_not_found",
            GitError::RebaseUpstreamNotCommit { .. } => "git.rebase_upstream_not_commit",
            GitError::RebaseNonFastForward => "git.rebase_non_fast_forward",
            GitError::RebaseDirtyWorktree => "git.rebase_dirty_worktree",
            GitError::RebaseIdentityMissing => "git.rebase_identity_missing",
            GitError::RebaseConflict => "git.rebase_conflict",
            GitError::RebasePreserveMergesUnsupported => "git.rebase_preserve_merges_unsupported",
            GitError::RebaseFailed { .. } => "git.rebase_failed",
            GitError::RebaseTimeout { .. } => "git.rebase_timeout",
            GitError::InvalidSyncConfig { .. } => "git.sync_invalid_config",
            GitError::SyncDetachedHead => "git.sync_detached_head",
            GitError::SyncBranchNotFound { .. } => "git.sync_branch_not_found",
            GitError::SyncRemoteNotFound { .. } => "git.sync_remote_not_found",
            GitError::SyncUpstreamNotFound => "git.sync_upstream_not_found",
            GitError::SyncDirtyWorktree => "git.sync_dirty_worktree",
            GitError::SyncNonFastForward => "git.sync_non_fast_forward",
            GitError::SyncPullFailed { .. } => "git.sync_pull_failed",
            GitError::SyncConflict => "git.sync_conflict",
            GitError::SyncPushRejected { .. } => "git.sync_push_rejected",
            GitError::SyncPushFailed { .. } => "git.sync_push_failed",
            GitError::SyncStashApplyConflict => "git.sync_stash_apply_conflict",
            GitError::SyncTimeout { .. } => "git.sync_timeout",
            GitError::SyncFailed { .. } => "git.sync_failed",
            // Status Summary error codes
            GitError::InvalidStatusSummaryConfig { .. } => "git.invalid_status_summary_config",
            GitError::StatusSummaryBranchNotFound { .. } => "git.status_summary_branch_not_found",
            GitError::StatusSummaryTimeout { .. } => "git.status_summary_timeout",
            GitError::StatusSummaryFailed { .. } => "git.status_summary_failed",
            // Status short error codes
            GitError::InvalidStatusShortConfig { .. } => "git.invalid_status_short_config",
            GitError::StatusShortBranchNotFound { .. } => "git.status_short_branch_not_found",
            GitError::StatusShortTimeout { .. } => "git.status_short_timeout",
            GitError::StatusShortFailed { .. } => "git.status_short_failed",
        };

        crate::core::status::ShellError::new(code, &err.to_string(), details)
    }
}

/// Convert git2::Error to GitError
impl From<git2::Error> for GitError {
    fn from(err: git2::Error) -> Self {
        GitError::StatusSummaryFailed {
            message: format!("git operation failed: {}", err)
        }
    }
}

/// Git connection registry for managing configured aliases
type GitConnectionRegistry = std::sync::LazyLock<dashmap::DashMap<String, GitConnectionProfile>>;

static GIT_CONNECTIONS: GitConnectionRegistry = std::sync::LazyLock::new(|| dashmap::DashMap::new());

impl GitHandle {
    /// Create new GitHandle from URL
    pub fn from_url(url: Url) -> Result<Self> {
        // For git:// URLs, the alias can be in the host or path
        let alias = if let Some(host) = url.host_str() {
            // If we have a host, that's our alias (git://main)
            host.to_string()
        } else if url.path() == "/" || url.path().is_empty() {
            // No host and empty path means default
            "default".to_string()
        } else {
            // Path-based alias (git:///main)
            url.path().trim_start_matches('/').to_string()
        };

        if alias.is_empty() {
            return Err(anyhow::anyhow!("git:// URLs must specify an alias"));
        }

        Ok(GitHandle { alias })
    }

    /// Clone verb implementation
    pub async fn clone(&self, args: Value) -> Result<Value, GitError> {
        log::debug!("Git clone operation for alias: {}", self.alias);

        // Parse and validate configuration
        let config = self.parse_clone_config(args)?;
        self.validate_clone_config(&config)?;

        // Load connection profile
        let profile = self.load_connection_profile()?;

        // Execute clone operation with timeout
        let timeout_ms = config.timeout_ms.unwrap_or(30000);
        let timeout_duration = Duration::from_millis(timeout_ms as u64);

        let result = tokio::time::timeout(
            timeout_duration,
            self.execute_clone(&config, &profile)
        ).await;

        match result {
            Ok(clone_result) => clone_result,
            Err(_) => Err(GitError::CloneTimeout { timeout_ms }),
        }
    }

    /// Pull verb implementation
    pub async fn pull(&self, args: Value) -> Result<Value, GitError> {
        log::debug!("Git pull operation for alias: {}", self.alias);

        // Parse and validate configuration
        let config = self.parse_pull_config(args)?;
        self.validate_pull_config(&config)?;

        // Load connection profile
        let profile = self.load_connection_profile()?;

        // Execute pull operation with timeout
        let timeout_ms = config.timeout_ms.unwrap_or(30000);
        let timeout_duration = Duration::from_millis(timeout_ms);

        let result = tokio::time::timeout(
            timeout_duration,
            self.execute_pull(&config, &profile)
        ).await;

        match result {
            Ok(pull_result) => pull_result,
            Err(_) => Err(GitError::PullTimeout { timeout_ms }),
        }
    }

    /// Push verb implementation
    pub async fn push(&self, args: Value) -> Result<Value, GitError> {
        log::debug!("Git push operation for alias: {}", self.alias);

        // Parse and validate configuration
        let config = self.parse_push_config(args)?;
        self.validate_push_config(&config)?;

        // Load connection profile
        let profile = self.load_connection_profile()?;

        // Execute push operation with timeout
        let timeout_ms = config.timeout_ms.unwrap_or(30000);
        let timeout_duration = Duration::from_millis(timeout_ms);

        let result = tokio::time::timeout(
            timeout_duration,
            self.execute_push(&config, &profile)
        ).await;

        match result {
            Ok(push_result) => push_result,
            Err(_) => Err(GitError::PushTimeout { timeout_ms }),
        }
    }

    /// Status verb implementation
    pub async fn status(&self, args: Value) -> Result<Value, GitError> {
        log::debug!("Git status operation for alias: {}", self.alias);

        // Parse and validate configuration
        let config = self.parse_status_config(args)?;
        self.validate_status_config(&config)?;

        // Load connection profile (for consistency, though status doesn't need credentials)
        let _profile = self.load_connection_profile()?;

        // Execute status operation with timeout
        let timeout_ms = config.timeout_ms.unwrap_or(5000);
        let timeout_duration = Duration::from_millis(timeout_ms);

        let result = tokio::time::timeout(
            timeout_duration,
            self.execute_status(&config)
        ).await;

        match result {
            Ok(status_result) => status_result,
            Err(_) => Err(GitError::StatusTimeout { timeout_ms }),
        }
    }

    /// Branch verb implementation
    pub async fn branch(&self, args: Value) -> Result<Value, GitError> {
        log::debug!("Git branch operation for alias: {}", self.alias);

        // Parse and validate configuration
        let config = self.parse_branch_config(args)?;
        self.validate_branch_config(&config)?;

        // Branch operations are local git operations and don't need authentication
        // No need to load connection profile for branch operations

        // Execute branch operation with timeout
        let timeout_ms = config.timeout_ms.unwrap_or(5000);
        let timeout_duration = Duration::from_millis(timeout_ms);

        let result = tokio::time::timeout(
            timeout_duration,
            self.execute_branch(&config)
        ).await;

        match result {
            Ok(branch_result) => branch_result,
            Err(_) => Err(GitError::BranchTimeout { timeout_ms }),
        }
    }

    /// Commit verb implementation
    pub async fn commit(&self, args: Value) -> Result<Value, GitError> {
        log::debug!("Git commit operation for alias: {}", self.alias);

        // Parse and validate configuration
        let config = self.parse_commit_config(args)?;
        self.validate_commit_config(&config)?;

        // Load connection profile (for author identity fallbacks)
        let profile = self.load_connection_profile()?;

        // Execute commit operation with timeout
        let timeout_ms = config.timeout_ms.unwrap_or(5000);
        let timeout_duration = Duration::from_millis(timeout_ms);

        let result = tokio::time::timeout(
            timeout_duration,
            self.execute_commit(&config, &profile)
        ).await;

        match result {
            Ok(commit_result) => commit_result,
            Err(_) => Err(GitError::CommitTimeout { timeout_ms }),
        }
    }

    /// Diff verb implementation
    pub async fn diff(&self, args: Value) -> Result<Value, GitError> {
        log::debug!("Git diff operation for alias: {}", self.alias);

        // Parse and validate configuration
        let config = self.parse_diff_config(args)?;
        self.validate_diff_config(&config)?;

        // Execute diff operation with timeout
        let timeout_ms = config.timeout_ms.unwrap_or(5000);
        let timeout_duration = Duration::from_millis(timeout_ms);

        let result = tokio::time::timeout(
            timeout_duration,
            self.execute_diff(&config)
        ).await;

        match result {
            Ok(diff_result) => diff_result,
            Err(_) => Err(GitError::DiffTimeout { timeout_ms }),
        }
    }

    /// Tag verb implementation
    pub async fn tag(&self, args: Value) -> Result<Value, GitError> {
        log::debug!("Git tag operation for alias: {}", self.alias);

        // Parse and validate configuration
        let config = self.parse_tag_config(args)?;
        self.validate_tag_config(&config)?;

        // Load connection profile for identity defaults
        let profile = self.load_connection_profile()?;

        // Execute tag operation with timeout
        let timeout_ms = config.timeout_ms.unwrap_or(5000);
        let timeout_duration = Duration::from_millis(timeout_ms);

        let result = tokio::time::timeout(
            timeout_duration,
            self.execute_tag(&config, &profile)
        ).await;

        match result {
            Ok(tag_result) => tag_result,
            Err(_) => Err(GitError::TagTimeout { timeout_ms }),
        }
    }

    /// Merge verb implementation
    pub async fn merge(&self, args: Value) -> Result<Value, GitError> {
        log::debug!("Git merge operation for alias: {}", self.alias);

        // Parse and validate configuration
        let config = self.parse_merge_config(args)?;
        self.validate_merge_config(&config)?;

        // Load connection profile for identity defaults
        let profile = self.load_connection_profile()?;

        // Execute merge operation with timeout
        let timeout_ms = config.timeout_ms.unwrap_or(10000);
        let timeout_duration = Duration::from_millis(timeout_ms);

        let result = tokio::time::timeout(
            timeout_duration,
            self.execute_merge(&config, &profile)
        ).await;

        match result {
            Ok(merge_result) => merge_result,
            Err(_) => Err(GitError::MergeTimeout { timeout_ms }),
        }
    }

    /// Rebase verb implementation
    pub async fn rebase(&self, args: Value) -> Result<Value, GitError> {
        log::debug!("Git rebase operation for alias: {}", self.alias);

        // Parse and validate configuration
        let config = self.parse_rebase_config(args)?;
        self.validate_rebase_config(&config)?;

        // Load connection profile for identity defaults
        let profile = self.load_connection_profile()?;

        // Execute rebase operation with timeout
        let timeout_ms = config.timeout_ms.unwrap_or(10000);
        let timeout_duration = Duration::from_millis(timeout_ms);

        let result = tokio::time::timeout(
            timeout_duration,
            self.execute_rebase(&config, &profile)
        ).await;

        match result {
            Ok(rebase_result) => rebase_result,
            Err(_) => Err(GitError::RebaseTimeout { timeout_ms }),
        }
    }

    /// Parse clone configuration from arguments
    fn parse_clone_config(&self, args: Value) -> Result<CloneConfig, GitError> {
        serde_json::from_value(args)
            .map_err(|e| GitError::InvalidCloneConfig {
                message: format!("failed to parse clone config: {}", e),
            })
    }

    /// Parse pull configuration from arguments
    fn parse_pull_config(&self, args: Value) -> Result<PullConfig, GitError> {
        serde_json::from_value(args)
            .map_err(|e| GitError::InvalidPullConfig {
                message: format!("failed to parse pull config: {}", e),
            })
    }

    /// Parse push configuration from arguments
    fn parse_push_config(&self, args: Value) -> Result<PushConfig, GitError> {
        serde_json::from_value(args)
            .map_err(|e| GitError::InvalidPushConfig {
                message: format!("failed to parse push config: {}", e),
            })
    }

    /// Validate clone configuration
    fn validate_clone_config(&self, config: &CloneConfig) -> Result<(), GitError> {
        // Check required fields
        if config.url.is_empty() {
            return Err(GitError::InvalidCloneConfig {
                message: "url cannot be empty".to_string(),
            });
        }

        if config.path.is_empty() {
            return Err(GitError::InvalidCloneConfig {
                message: "path cannot be empty".to_string(),
            });
        }

        // Check depth constraint
        if let Some(depth) = config.depth {
            if depth == 0 {
                return Err(GitError::InvalidCloneConfig {
                    message: "depth must be greater than 0".to_string(),
                });
            }
        }

        // Check timeout constraint
        if let Some(timeout_ms) = config.timeout_ms {
            if timeout_ms == 0 {
                return Err(GitError::InvalidCloneConfig {
                    message: "timeout_ms must be greater than 0".to_string(),
                });
            }
        }

        // Check URL format
        if !config.url.starts_with("http://") 
            && !config.url.starts_with("https://") 
            && !config.url.starts_with("git@") 
            && !config.url.starts_with("ssh://") {
            return Err(GitError::InvalidCloneConfig {
                message: "url must start with http://, https://, git@, or ssh://".to_string(),
            });
        }

        // Check for multiple auth methods
        let auth_methods = [
            config.ssh_key.is_some(),
            (config.username.is_some() && config.password.is_some()),
            config.token.is_some(),
        ];
        let auth_count = auth_methods.iter().filter(|&&x| x).count();

        if auth_count > 1 {
            return Err(GitError::InvalidCloneConfig {
                message: "multiple authentication methods specified".to_string(),
            });
        }

        Ok(())
    }

    /// Validate pull configuration
    fn validate_pull_config(&self, config: &PullConfig) -> Result<(), GitError> {
        // Check required fields
        if config.path.is_empty() {
            return Err(GitError::InvalidPullConfig {
                message: "path cannot be empty".to_string(),
            });
        }

        // Check timeout constraint
        if let Some(timeout_ms) = config.timeout_ms {
            if timeout_ms == 0 {
                return Err(GitError::InvalidPullConfig {
                    message: "timeout_ms must be greater than 0".to_string(),
                });
            }
        }

        // Check depth constraint
        if let Some(depth) = config.depth {
            if depth == 0 {
                return Err(GitError::InvalidPullConfig {
                    message: "depth must be greater than 0".to_string(),
                });
            }
        }

        // Validate remote and branch names if provided
        if let Some(ref remote) = config.remote {
            if remote.is_empty() {
                return Err(GitError::InvalidPullConfig {
                    message: "remote cannot be empty string".to_string(),
                });
            }
        }

        if let Some(ref branch) = config.branch {
            if branch.is_empty() {
                return Err(GitError::InvalidPullConfig {
                    message: "branch cannot be empty string".to_string(),
                });
            }
        }

        // Check for multiple auth methods
        let auth_methods = [
            config.ssh_key.is_some(),
            (config.username.is_some() && config.password.is_some()),
            config.token.is_some(),
        ];
        let auth_count = auth_methods.iter().filter(|&&x| x).count();

        if auth_count > 1 {
            return Err(GitError::InvalidPullConfig {
                message: "multiple authentication methods specified".to_string(),
            });
        }

        // Check path exists and is a directory
        let path = Path::new(&config.path);
        if !path.exists() {
            return Err(GitError::RepositoryNotFound {
                path: config.path.clone(),
            });
        }

        if !path.is_dir() {
            return Err(GitError::InvalidPullConfig {
                message: "path must be a directory".to_string(),
            });
        }

        Ok(())
    }

    /// Validate push configuration
    fn validate_push_config(&self, config: &PushConfig) -> Result<(), GitError> {
        // Check required fields
        if config.path.is_empty() {
            return Err(GitError::InvalidPushConfig {
                message: "path cannot be empty".to_string(),
            });
        }

        // Check timeout constraint
        if let Some(timeout_ms) = config.timeout_ms {
            if timeout_ms == 0 {
                return Err(GitError::InvalidPushConfig {
                    message: "timeout_ms must be greater than 0".to_string(),
                });
            }
        }

        // Check that both branch and branches are not provided
        if config.branch.is_some() && config.branches.is_some() {
            return Err(GitError::InvalidPushConfig {
                message: "cannot specify both branch and branches".to_string(),
            });
        }

        // Check that branches is not empty if provided
        if let Some(ref branches) = config.branches {
            if branches.is_empty() {
                return Err(GitError::InvalidPushConfig {
                    message: "branches array cannot be empty".to_string(),
                });
            }
        }

        // Check mutually exclusive force and ff_only
        if config.force.unwrap_or(false) && config.ff_only.unwrap_or(false) {
            return Err(GitError::InvalidPushConfig {
                message: "force and ff_only are mutually exclusive".to_string(),
            });
        }

        // Validate remote name if provided
        if let Some(ref remote) = config.remote {
            if remote.is_empty() {
                return Err(GitError::InvalidPushConfig {
                    message: "remote cannot be empty string".to_string(),
                });
            }
        }

        // Check for multiple auth methods
        let auth_methods = [
            config.ssh_key.is_some(),
            (config.username.is_some() && config.password.is_some()),
            config.token.is_some(),
        ];
        let auth_count = auth_methods.iter().filter(|&&x| x).count();

        if auth_count > 1 {
            return Err(GitError::InvalidPushConfig {
                message: "multiple authentication methods specified".to_string(),
            });
        }

        // Check path exists and is a directory
        let path = Path::new(&config.path);
        if !path.exists() {
            return Err(GitError::RepositoryNotFound {
                path: config.path.clone(),
            });
        }

        if !path.is_dir() {
            return Err(GitError::InvalidPushConfig {
                message: "path must be a directory".to_string(),
            });
        }

        Ok(())
    }

    /// Parse status configuration from arguments
    fn parse_status_config(&self, args: Value) -> Result<StatusConfig, GitError> {
        serde_json::from_value(args)
            .map_err(|e| GitError::InvalidStatusConfig {
                message: format!("failed to parse status config: {}", e),
            })
    }

    /// Validate status configuration
    fn validate_status_config(&self, config: &StatusConfig) -> Result<(), GitError> {
        // Check required fields
        if config.path.is_empty() {
            return Err(GitError::InvalidStatusConfig {
                message: "path cannot be empty".to_string(),
            });
        }

        // Check timeout constraint
        if let Some(timeout_ms) = config.timeout_ms {
            if timeout_ms == 0 {
                return Err(GitError::InvalidStatusConfig {
                    message: "timeout_ms must be greater than 0".to_string(),
                });
            }
        }

        // Check path exists and is a directory
        let path = Path::new(&config.path);
        if !path.exists() {
            return Err(GitError::RepositoryNotFound {
                path: config.path.clone(),
            });
        }

        if !path.is_dir() {
            return Err(GitError::InvalidStatusConfig {
                message: "path must be a directory".to_string(),
            });
        }

        Ok(())
    }

    /// Parse branch configuration from arguments
    fn parse_branch_config(&self, args: Value) -> Result<BranchConfig, GitError> {
        serde_json::from_value(args)
            .map_err(|e| GitError::InvalidBranchConfig {
                message: format!("failed to parse branch config: {}", e),
            })
    }

    /// Validate branch configuration
    fn validate_branch_config(&self, config: &BranchConfig) -> Result<(), GitError> {
        // Check required fields
        if config.path.is_empty() {
            return Err(GitError::InvalidBranchConfig {
                message: "path cannot be empty".to_string(),
            });
        }

        // Check timeout constraint
        if let Some(timeout_ms) = config.timeout_ms {
            if timeout_ms == 0 {
                return Err(GitError::InvalidBranchConfig {
                    message: "timeout_ms must be greater than 0".to_string(),
                });
            }
        }

        // Get action (default to List if not provided)
        let action = config.action.as_ref().unwrap_or(&BranchAction::List);

        // Validate list action flags
        if matches!(action, BranchAction::List) {
            let local_only = config.local_only.unwrap_or(true);
            let remote_only = config.remote_only.unwrap_or(false);
            let all = config.all.unwrap_or(false);

            // Exactly one of the following must be true:
            // all == true, OR (local_only == true and remote_only == false), OR (remote_only == true and local_only == false)
            let valid_combination = all || 
                (local_only && !remote_only) || 
                (remote_only && !local_only);
            
            if !valid_combination {
                return Err(GitError::InvalidBranchConfig {
                    message: "invalid list flags combination: exactly one of 'all=true', 'local_only=true', or 'remote_only=true' must be set".to_string(),
                });
            }
        }

        // Action-specific validation
        match action {
            BranchAction::Create => {
                if config.name.is_none() || config.name.as_ref().unwrap().is_empty() {
                    return Err(GitError::InvalidBranchConfig {
                        message: "name is required for create action".to_string(),
                    });
                }
            }
            BranchAction::Delete => {
                if config.name.is_none() || config.name.as_ref().unwrap().is_empty() {
                    return Err(GitError::InvalidBranchConfig {
                        message: "name is required for delete action".to_string(),
                    });
                }
            }
            BranchAction::Rename => {
                if config.name.is_none() || config.name.as_ref().unwrap().is_empty() {
                    return Err(GitError::InvalidBranchConfig {
                        message: "name is required for rename action".to_string(),
                    });
                }
                if config.new_name.is_none() || config.new_name.as_ref().unwrap().is_empty() {
                    return Err(GitError::InvalidBranchConfig {
                        message: "new_name is required for rename action".to_string(),
                    });
                }
                if config.name == config.new_name {
                    return Err(GitError::InvalidBranchConfig {
                        message: "name and new_name cannot be the same".to_string(),
                    });
                }
            }
            BranchAction::Checkout => {
                if config.name.is_none() || config.name.as_ref().unwrap().is_empty() {
                    return Err(GitError::InvalidBranchConfig {
                        message: "name is required for checkout action".to_string(),
                    });
                }
            }
            BranchAction::List => {
                // Already validated above
            }
        }

        // Check path exists and is a directory
        let path = Path::new(&config.path);
        if !path.exists() {
            return Err(GitError::RepositoryNotFound {
                path: config.path.clone(),
            });
        }

        if !path.is_dir() {
            return Err(GitError::InvalidBranchConfig {
                message: "path must be a directory".to_string(),
            });
        }

        Ok(())
    }

    /// Parse commit configuration from arguments
    fn parse_commit_config(&self, args: Value) -> Result<CommitConfig, GitError> {
        serde_json::from_value(args)
            .map_err(|e| GitError::InvalidCommitConfig {
                message: format!("failed to parse commit config: {}", e),
            })
    }

    /// Parse diff configuration from arguments
    fn parse_diff_config(&self, args: Value) -> Result<DiffConfig, GitError> {
        // Handle both direct JSON and CLI string arguments
        if let Some(args_obj) = args.as_object() {
            let mut config = DiffConfig {
                path: String::new(),
                mode: None,
                from: None,
                to: None,
                paths: None,
                unified: None,
                ignore_whitespace: None,
                ignore_whitespace_change: None,
                ignore_whitespace_eol: None,
                detect_renames: None,
                rename_threshold: None,
                binary: None,
                max_files: None,
                max_hunks: None,
                timeout_ms: None,
            };

            for (key, value) in args_obj {
                match key.as_str() {
                    "path" => {
                        config.path = value.as_str().unwrap_or("").to_string();
                    }
                    "mode" => {
                        if let Some(mode_str) = value.as_str() {
                            let mode = match mode_str {
                                "workdir_vs_index" => DiffMode::WorkdirVsIndex,
                                "index_vs_head" => DiffMode::IndexVsHead,
                                "head_vs_workdir" => DiffMode::HeadVsWorkdir,
                                "commit_vs_commit" => DiffMode::CommitVsCommit,
                                "commit_vs_workdir" => DiffMode::CommitVsWorkdir,
                                "commit_vs_index" => DiffMode::CommitVsIndex,
                                _ => return Err(GitError::InvalidDiffConfig {
                                    message: format!("invalid mode: {}", mode_str),
                                }),
                            };
                            config.mode = Some(mode);
                        }
                    }
                    "from" => {
                        if let Some(val_str) = value.as_str() {
                            config.from = Some(val_str.to_string());
                        }
                    }
                    "to" => {
                        if let Some(val_str) = value.as_str() {
                            config.to = Some(val_str.to_string());
                        }
                    }
                    "unified" => {
                        if let Some(val_str) = value.as_str() {
                            config.unified = Some(val_str.parse().map_err(|_| {
                                GitError::InvalidDiffConfig {
                                    message: format!("invalid unified value: {}", val_str),
                                }
                            })?);
                        } else if let Some(val_num) = value.as_i64() {
                            config.unified = Some(val_num as i32);
                        }
                    }
                    "ignore_whitespace" => {
                        if let Some(val_str) = value.as_str() {
                            config.ignore_whitespace = Some(val_str.parse().map_err(|_| {
                                GitError::InvalidDiffConfig {
                                    message: format!("invalid ignore_whitespace value: {}", val_str),
                                }
                            })?);
                        } else if let Some(val_bool) = value.as_bool() {
                            config.ignore_whitespace = Some(val_bool);
                        }
                    }
                    "ignore_whitespace_change" => {
                        if let Some(val_str) = value.as_str() {
                            config.ignore_whitespace_change = Some(val_str.parse().map_err(|_| {
                                GitError::InvalidDiffConfig {
                                    message: format!("invalid ignore_whitespace_change value: {}", val_str),
                                }
                            })?);
                        } else if let Some(val_bool) = value.as_bool() {
                            config.ignore_whitespace_change = Some(val_bool);
                        }
                    }
                    "ignore_whitespace_eol" => {
                        if let Some(val_str) = value.as_str() {
                            config.ignore_whitespace_eol = Some(val_str.parse().map_err(|_| {
                                GitError::InvalidDiffConfig {
                                    message: format!("invalid ignore_whitespace_eol value: {}", val_str),
                                }
                            })?);
                        } else if let Some(val_bool) = value.as_bool() {
                            config.ignore_whitespace_eol = Some(val_bool);
                        }
                    }
                    "detect_renames" => {
                        if let Some(val_str) = value.as_str() {
                            config.detect_renames = Some(val_str.parse().map_err(|_| {
                                GitError::InvalidDiffConfig {
                                    message: format!("invalid detect_renames value: {}", val_str),
                                }
                            })?);
                        } else if let Some(val_bool) = value.as_bool() {
                            config.detect_renames = Some(val_bool);
                        }
                    }
                    "rename_threshold" => {
                        if let Some(val_str) = value.as_str() {
                            config.rename_threshold = Some(val_str.parse().map_err(|_| {
                                GitError::InvalidDiffConfig {
                                    message: format!("invalid rename_threshold value: {}", val_str),
                                }
                            })?);
                        } else if let Some(val_num) = value.as_u64() {
                            config.rename_threshold = Some(val_num as u8);
                        }
                    }
                    "binary" => {
                        if let Some(val_str) = value.as_str() {
                            config.binary = Some(val_str.parse().map_err(|_| {
                                GitError::InvalidDiffConfig {
                                    message: format!("invalid binary value: {}", val_str),
                                }
                            })?);
                        } else if let Some(val_bool) = value.as_bool() {
                            config.binary = Some(val_bool);
                        }
                    }
                    "max_files" => {
                        if let Some(val_str) = value.as_str() {
                            config.max_files = Some(val_str.parse().map_err(|_| {
                                GitError::InvalidDiffConfig {
                                    message: format!("invalid max_files value: {}", val_str),
                                }
                            })?);
                        } else if let Some(val_num) = value.as_u64() {
                            config.max_files = Some(val_num as u32);
                        }
                    }
                    "max_hunks" => {
                        if let Some(val_str) = value.as_str() {
                            config.max_hunks = Some(val_str.parse().map_err(|_| {
                                GitError::InvalidDiffConfig {
                                    message: format!("invalid max_hunks value: {}", val_str),
                                }
                            })?);
                        } else if let Some(val_num) = value.as_u64() {
                            config.max_hunks = Some(val_num as u32);
                        }
                    }
                    "paths" => {
                        if let Some(val_str) = value.as_str() {
                            // Parse JSON array string
                            let paths: Vec<String> = serde_json::from_str(val_str).map_err(|_| {
                                GitError::InvalidDiffConfig {
                                    message: format!("invalid paths value: {}", val_str),
                                }
                            })?;
                            config.paths = Some(paths);
                        } else if let Some(val_arr) = value.as_array() {
                            let mut paths = Vec::new();
                            for path_val in val_arr {
                                if let Some(path_str) = path_val.as_str() {
                                    paths.push(path_str.to_string());
                                }
                            }
                            config.paths = Some(paths);
                        }
                    }
                    "timeout_ms" => {
                        if let Some(val_str) = value.as_str() {
                            config.timeout_ms = Some(val_str.parse().map_err(|_| {
                                GitError::InvalidDiffConfig {
                                    message: format!("invalid timeout_ms value: {}", val_str),
                                }
                            })?);
                        } else if let Some(val_num) = value.as_u64() {
                            config.timeout_ms = Some(val_num);
                        }
                    }
                    _ => {
                        log::warn!("Unknown diff config parameter: {}", key);
                    }
                }
            }

            Ok(config)
        } else {
            // Fallback to direct deserialization for backwards compatibility
            serde_json::from_value(args)
                .map_err(|e| GitError::InvalidDiffConfig {
                    message: format!("failed to parse diff config: {}", e),
                })
        }
    }

    /// Parse tag configuration from arguments
    fn parse_tag_config(&self, args: Value) -> Result<TagConfig, GitError> {
        // Handle both direct JSON and CLI string arguments
        if let Some(args_obj) = args.as_object() {
            let mut config = TagConfig {
                path: String::new(),
                action: None,
                name: None,
                names: None,
                pattern: None,
                sort: None,
                annotated: None,
                message: None,
                target: None,
                force: None,
                author_name: None,
                author_email: None,
                timestamp: None,
                timeout_ms: None,
            };

            for (key, value) in args_obj {
                match key.as_str() {
                    "path" => {
                        if let Some(val_str) = value.as_str() {
                            config.path = val_str.to_string();
                        }
                    }
                    "action" => {
                        if let Some(val_str) = value.as_str() {
                            config.action = Some(match val_str {
                                "list" => TagAction::List,
                                "create" => TagAction::Create,
                                "delete" => TagAction::Delete,
                                _ => return Err(GitError::InvalidTagConfig {
                                    message: format!("invalid action: {}", val_str),
                                }),
                            });
                        }
                    }
                    "name" => {
                        if let Some(val_str) = value.as_str() {
                            config.name = Some(val_str.to_string());
                        }
                    }
                    "names" => {
                        if let Some(arr) = value.as_array() {
                            let names: Result<Vec<_>, _> = arr.iter()
                                .map(|v| v.as_str().ok_or_else(|| GitError::InvalidTagConfig {
                                    message: "names array must contain strings".to_string(),
                                }))
                                .collect::<Result<Vec<_>, _>>()
                                .map(|vec| vec.into_iter().map(String::from).collect());
                            config.names = Some(names?);
                        }
                    }
                    "pattern" => {
                        if let Some(val_str) = value.as_str() {
                            config.pattern = Some(val_str.to_string());
                        }
                    }
                    "sort" => {
                        if let Some(val_str) = value.as_str() {
                            config.sort = Some(match val_str {
                                "name" => TagSort::Name,
                                "version" => TagSort::Version,
                                "taggerdate" => TagSort::TaggerDate,
                                "committerdate" => TagSort::CommitterDate,
                                _ => return Err(GitError::InvalidTagConfig {
                                    message: format!("invalid sort: {}", val_str),
                                }),
                            });
                        }
                    }
                    "annotated" => {
                        if let Some(val_bool) = value.as_bool() {
                            config.annotated = Some(val_bool);
                        } else if let Some(val_str) = value.as_str() {
                            config.annotated = Some(val_str.parse().map_err(|_| {
                                GitError::InvalidTagConfig {
                                    message: format!("invalid annotated value: {}", val_str),
                                }
                            })?);
                        }
                    }
                    "message" => {
                        if let Some(val_str) = value.as_str() {
                            config.message = Some(val_str.to_string());
                        }
                    }
                    "target" => {
                        if let Some(val_str) = value.as_str() {
                            config.target = Some(val_str.to_string());
                        }
                    }
                    "force" => {
                        if let Some(val_bool) = value.as_bool() {
                            config.force = Some(val_bool);
                        } else if let Some(val_str) = value.as_str() {
                            config.force = Some(val_str.parse().map_err(|_| {
                                GitError::InvalidTagConfig {
                                    message: format!("invalid force value: {}", val_str),
                                }
                            })?);
                        }
                    }
                    "author_name" => {
                        if let Some(val_str) = value.as_str() {
                            config.author_name = Some(val_str.to_string());
                        }
                    }
                    "author_email" => {
                        if let Some(val_str) = value.as_str() {
                            config.author_email = Some(val_str.to_string());
                        }
                    }
                    "timestamp" => {
                        if let Some(val_str) = value.as_str() {
                            config.timestamp = Some(TagTimestamp::Iso8601(val_str.to_string()));
                        } else if let Some(val_num) = value.as_u64() {
                            config.timestamp = Some(TagTimestamp::UnixSeconds(val_num));
                        }
                    }
                    "timeout_ms" => {
                        if let Some(val_str) = value.as_str() {
                            config.timeout_ms = Some(val_str.parse().map_err(|_| {
                                GitError::InvalidTagConfig {
                                    message: format!("invalid timeout_ms value: {}", val_str),
                                }
                            })?);
                        } else if let Some(val_num) = value.as_u64() {
                            config.timeout_ms = Some(val_num);
                        }
                    }
                    _ => {
                        log::warn!("Unknown tag config parameter: {}", key);
                    }
                }
            }

            Ok(config)
        } else {
            // Fallback to direct deserialization for backwards compatibility
            serde_json::from_value(args)
                .map_err(|e| GitError::InvalidTagConfig {
                    message: format!("failed to parse tag config: {}", e),
                })
        }
    }

    /// Validate tag configuration
    fn validate_tag_config(&self, config: &TagConfig) -> Result<(), GitError> {
        // Validate required fields
        if config.path.is_empty() {
            return Err(GitError::InvalidTagConfig {
                message: "path is required".to_string(),
            });
        }

        if let Some(timeout_ms) = config.timeout_ms {
            if timeout_ms == 0 {
                return Err(GitError::InvalidTagConfig {
                    message: "timeout_ms must be greater than 0".to_string(),
                });
            }
        }

        let action = config.action.as_ref().unwrap_or(&TagAction::List);

        match action {
            TagAction::List => {
                // No additional validation needed for list
            }
            TagAction::Create => {
                if config.name.is_none() || config.name.as_ref().unwrap().is_empty() {
                    return Err(GitError::InvalidTagConfig {
                        message: "name is required for create action".to_string(),
                    });
                }

                let annotated = config.annotated.unwrap_or(false);
                if annotated && (config.message.is_none() || config.message.as_ref().unwrap().is_empty()) {
                    return Err(GitError::InvalidTagConfig {
                        message: "message is required for annotated tags".to_string(),
                    });
                }
            }
            TagAction::Delete => {
                let has_name = config.name.is_some() && !config.name.as_ref().unwrap().is_empty();
                let has_names = config.names.is_some() && !config.names.as_ref().unwrap().is_empty();

                if !has_name && !has_names {
                    return Err(GitError::InvalidTagConfig {
                        message: "either name or names is required for delete action".to_string(),
                    });
                }

                if has_names && config.names.as_ref().unwrap().is_empty() {
                    return Err(GitError::InvalidTagConfig {
                        message: "names array cannot be empty".to_string(),
                    });
                }
            }
        }

        Ok(())
    }

    /// Parse merge configuration from arguments
    fn parse_merge_config(&self, args: Value) -> Result<MergeConfig, GitError> {
        // Handle both direct JSON and CLI string arguments
        if let Some(args_obj) = args.as_object() {
            let mut config = MergeConfig {
                path: String::new(),
                source: String::new(),
                target: None,
                ff_only: None,
                no_ff: None,
                squash: None,
                commit_message: None,
                author_name: None,
                author_email: None,
                committer_name: None,
                committer_email: None,
                allow_uncommitted: None,
                abort_on_conflict: None,
                timeout_ms: None,
            };

            for (key, value) in args_obj {
                match key.as_str() {
                    "path" => {
                        if let Some(path_str) = value.as_str() {
                            config.path = path_str.to_string();
                        }
                    }
                    "source" => {
                        if let Some(source_str) = value.as_str() {
                            config.source = source_str.to_string();
                        }
                    }
                    "target" => {
                        if let Some(target_str) = value.as_str() {
                            config.target = Some(target_str.to_string());
                        }
                    }
                    "ff_only" => {
                        if let Some(ff_only_bool) = value.as_bool() {
                            config.ff_only = Some(ff_only_bool);
                        }
                    }
                    "no_ff" => {
                        if let Some(no_ff_bool) = value.as_bool() {
                            config.no_ff = Some(no_ff_bool);
                        }
                    }
                    "squash" => {
                        if let Some(squash_bool) = value.as_bool() {
                            config.squash = Some(squash_bool);
                        }
                    }
                    "commit_message" => {
                        if let Some(message_str) = value.as_str() {
                            config.commit_message = Some(message_str.to_string());
                        }
                    }
                    "author_name" => {
                        if let Some(author_str) = value.as_str() {
                            config.author_name = Some(author_str.to_string());
                        }
                    }
                    "author_email" => {
                        if let Some(email_str) = value.as_str() {
                            config.author_email = Some(email_str.to_string());
                        }
                    }
                    "committer_name" => {
                        if let Some(committer_str) = value.as_str() {
                            config.committer_name = Some(committer_str.to_string());
                        }
                    }
                    "committer_email" => {
                        if let Some(email_str) = value.as_str() {
                            config.committer_email = Some(email_str.to_string());
                        }
                    }
                    "allow_uncommitted" => {
                        if let Some(allow_bool) = value.as_bool() {
                            config.allow_uncommitted = Some(allow_bool);
                        }
                    }
                    "abort_on_conflict" => {
                        if let Some(abort_bool) = value.as_bool() {
                            config.abort_on_conflict = Some(abort_bool);
                        }
                    }
                    "timeout_ms" => {
                        if let Some(timeout_num) = value.as_u64() {
                            config.timeout_ms = Some(timeout_num);
                        }
                    }
                    _ => {
                        log::debug!("Unknown merge config key: {}", key);
                    }
                }
            }

            Ok(config)
        } else {
            // Try to parse as direct JSON
            serde_json::from_value(args)
                .map_err(|e| GitError::InvalidMergeConfig {
                    message: format!("failed to parse merge config: {}", e),
                })
        }
    }

    /// Validate merge configuration
    fn validate_merge_config(&self, config: &MergeConfig) -> Result<(), GitError> {
        // Validate required fields
        if config.path.is_empty() {
            return Err(GitError::InvalidMergeConfig {
                message: "path is required".to_string(),
            });
        }

        if config.source.is_empty() {
            return Err(GitError::InvalidMergeConfig {
                message: "source is required".to_string(),
            });
        }

        // Check timeout constraint
        if let Some(timeout_ms) = config.timeout_ms {
            if timeout_ms == 0 {
                return Err(GitError::InvalidMergeConfig {
                    message: "timeout_ms must be greater than 0".to_string(),
                });
            }
        }

        // Check mutually exclusive options
        let ff_only = config.ff_only.unwrap_or(false);
        let no_ff = config.no_ff.unwrap_or(false);

        if ff_only && no_ff {
            return Err(GitError::InvalidMergeConfig {
                message: "ff_only and no_ff cannot both be true".to_string(),
            });
        }

        // Validate target if provided
        if let Some(target) = &config.target {
            if target.is_empty() {
                return Err(GitError::InvalidMergeConfig {
                    message: "target cannot be empty string".to_string(),
                });
            }
        }

        // Validate identity fields if provided
        if let Some(name) = &config.author_name {
            if name.is_empty() {
                return Err(GitError::InvalidMergeConfig {
                    message: "author_name cannot be empty string".to_string(),
                });
            }
        }

        if let Some(email) = &config.author_email {
            if email.is_empty() {
                return Err(GitError::InvalidMergeConfig {
                    message: "author_email cannot be empty string".to_string(),
                });
            }
        }

        if let Some(name) = &config.committer_name {
            if name.is_empty() {
                return Err(GitError::InvalidMergeConfig {
                    message: "committer_name cannot be empty string".to_string(),
                });
            }
        }

        if let Some(email) = &config.committer_email {
            if email.is_empty() {
                return Err(GitError::InvalidMergeConfig {
                    message: "committer_email cannot be empty string".to_string(),
                });
            }
        }

        Ok(())
    }

    /// Parse rebase configuration from arguments
    fn parse_rebase_config(&self, args: Value) -> Result<RebaseConfig, GitError> {
        // Handle both direct JSON and CLI string arguments
        if let Some(args_obj) = args.as_object() {
            let mut config = RebaseConfig {
                path: String::new(),
                operation: None,
                branch: None,
                upstream: None,
                ff_only: None,
                preserve_merges: None,
                autosquash: None,
                allow_uncommitted: None,
                abort_on_conflict: None,
                author_name: None,
                author_email: None,
                committer_name: None,
                committer_email: None,
                timeout_ms: None,
            };

            for (key, value) in args_obj {
                match key.as_str() {
                    "path" => {
                        if let Some(path_str) = value.as_str() {
                            config.path = path_str.to_string();
                        }
                    }
                    "operation" => {
                        if let Some(op_str) = value.as_str() {
                            match op_str.to_lowercase().as_str() {
                                "start" => config.operation = Some(RebaseOperation::Start),
                                "continue" => config.operation = Some(RebaseOperation::Continue),
                                "abort" => config.operation = Some(RebaseOperation::Abort),
                                _ => log::debug!("Unknown rebase operation: {}", op_str),
                            }
                        }
                    }
                    "branch" => {
                        if let Some(branch_str) = value.as_str() {
                            config.branch = Some(branch_str.to_string());
                        }
                    }
                    "upstream" => {
                        if let Some(upstream_str) = value.as_str() {
                            config.upstream = Some(upstream_str.to_string());
                        }
                    }
                    "ff_only" => {
                        if let Some(ff_only_bool) = value.as_bool() {
                            config.ff_only = Some(ff_only_bool);
                        }
                    }
                    "preserve_merges" => {
                        if let Some(preserve_bool) = value.as_bool() {
                            config.preserve_merges = Some(preserve_bool);
                        }
                    }
                    "autosquash" => {
                        if let Some(autosquash_bool) = value.as_bool() {
                            config.autosquash = Some(autosquash_bool);
                        }
                    }
                    "allow_uncommitted" => {
                        if let Some(allow_bool) = value.as_bool() {
                            config.allow_uncommitted = Some(allow_bool);
                        }
                    }
                    "abort_on_conflict" => {
                        if let Some(abort_bool) = value.as_bool() {
                            config.abort_on_conflict = Some(abort_bool);
                        }
                    }
                    "author_name" => {
                        if let Some(author_str) = value.as_str() {
                            config.author_name = Some(author_str.to_string());
                        }
                    }
                    "author_email" => {
                        if let Some(email_str) = value.as_str() {
                            config.author_email = Some(email_str.to_string());
                        }
                    }
                    "committer_name" => {
                        if let Some(committer_str) = value.as_str() {
                            config.committer_name = Some(committer_str.to_string());
                        }
                    }
                    "committer_email" => {
                        if let Some(email_str) = value.as_str() {
                            config.committer_email = Some(email_str.to_string());
                        }
                    }
                    "timeout_ms" => {
                        if let Some(timeout_num) = value.as_u64() {
                            config.timeout_ms = Some(timeout_num);
                        }
                    }
                    _ => {
                        log::debug!("Unknown rebase config key: {}", key);
                    }
                }
            }

            Ok(config)
        } else {
            // Try to parse as direct JSON
            serde_json::from_value(args)
                .map_err(|e| GitError::InvalidRebaseConfig {
                    message: format!("failed to parse rebase config: {}", e),
                })
        }
    }

    /// Validate rebase configuration
    fn validate_rebase_config(&self, config: &RebaseConfig) -> Result<(), GitError> {
        // Validate required fields
        if config.path.is_empty() {
            return Err(GitError::InvalidRebaseConfig {
                message: "path is required".to_string(),
            });
        }

        // Check timeout constraint
        if let Some(timeout_ms) = config.timeout_ms {
            if timeout_ms == 0 {
                return Err(GitError::InvalidRebaseConfig {
                    message: "timeout_ms must be greater than 0".to_string(),
                });
            }
        }

        // Validate operation-specific requirements
        let operation = config.operation.as_ref().unwrap_or(&RebaseOperation::Start);
        match operation {
            RebaseOperation::Start => {
                // For start operation, upstream is required
                if config.upstream.is_none() || config.upstream.as_ref().unwrap().is_empty() {
                    return Err(GitError::InvalidRebaseConfig {
                        message: "upstream is required for start operation".to_string(),
                    });
                }
            }
            RebaseOperation::Continue | RebaseOperation::Abort => {
                // For continue/abort, upstream is ignored but operation should be valid
            }
        }

        // Validate branch name if provided
        if let Some(ref branch) = config.branch {
            if branch.is_empty() {
                return Err(GitError::InvalidRebaseConfig {
                    message: "branch cannot be empty string".to_string(),
                });
            }
        }

        // Validate identity fields if provided
        if let Some(ref name) = config.author_name {
            if name.is_empty() {
                return Err(GitError::InvalidRebaseConfig {
                    message: "author_name cannot be empty string".to_string(),
                });
            }
        }

        if let Some(ref email) = config.author_email {
            if email.is_empty() {
                return Err(GitError::InvalidRebaseConfig {
                    message: "author_email cannot be empty string".to_string(),
                });
            }
        }

        if let Some(ref name) = config.committer_name {
            if name.is_empty() {
                return Err(GitError::InvalidRebaseConfig {
                    message: "committer_name cannot be empty string".to_string(),
                });
            }
        }

        if let Some(ref email) = config.committer_email {
            if email.is_empty() {
                return Err(GitError::InvalidRebaseConfig {
                    message: "committer_email cannot be empty string".to_string(),
                });
            }
        }

        // Validate mutually exclusive options
        if config.ff_only == Some(true) && config.preserve_merges == Some(true) {
            return Err(GitError::InvalidRebaseConfig {
                message: "ff_only and preserve_merges are mutually exclusive".to_string(),
            });
        }

        // Warn about unsupported advanced features
        if config.preserve_merges == Some(true) {
            log::warn!("preserve_merges option is not fully supported by git2, falling back to normal rebase");
        }
        
        if config.autosquash == Some(true) {
            log::warn!("autosquash option is not fully supported by git2, falling back to normal rebase");
        }

        Ok(())
    }

    /// Validate commit configuration
    fn validate_commit_config(&self, config: &CommitConfig) -> Result<(), GitError> {
        // Check required fields
        if config.path.is_empty() {
            return Err(GitError::InvalidCommitConfig {
                message: "path cannot be empty".to_string(),
            });
        }

        // Check timeout constraint
        if let Some(timeout_ms) = config.timeout_ms {
            if timeout_ms == 0 {
                return Err(GitError::InvalidCommitConfig {
                    message: "timeout_ms must be greater than 0".to_string(),
                });
            }
        }

        // Check message requirement based on amend and no_edit flags
        let amend = config.amend.unwrap_or(false);
        let no_edit = config.no_edit.unwrap_or(false);
        
        if no_edit && !amend {
            return Err(GitError::InvalidCommitConfig {
                message: "no_edit can only be used with amend=true".to_string(),
            });
        }

        if !(amend && no_edit) && (config.message.is_none() || config.message.as_ref().unwrap().is_empty()) {
            return Err(GitError::InvalidCommitConfig {
                message: "message cannot be empty unless amend=true and no_edit=true".to_string(),
            });
        }

        // Check paths is not empty if provided
        if let Some(ref paths) = config.paths {
            if paths.is_empty() {
                return Err(GitError::InvalidCommitConfig {
                    message: "paths cannot be an empty array".to_string(),
                });
            }
        }

        // Validate timestamp format if provided
        if let Some(ref timestamp) = config.timestamp {
            match timestamp {
                CommitTimestamp::Iso8601(iso) => {
                    if chrono::DateTime::parse_from_rfc3339(iso).is_err() {
                        return Err(GitError::InvalidCommitConfig {
                            message: format!("invalid ISO8601 timestamp: {}", iso),
                        });
                    }
                },
                CommitTimestamp::UnixSeconds(_) => {
                    // Unix timestamps are always valid as u64
                }
            }
        }

        // Check path exists and is a directory
        let path = Path::new(&config.path);
        if !path.exists() {
            return Err(GitError::RepositoryNotFound {
                path: config.path.clone(),
            });
        }

        if !path.is_dir() {
            return Err(GitError::InvalidCommitConfig {
                message: "path must be a directory".to_string(),
            });
        }

        Ok(())
    }

    /// Validate diff configuration
    fn validate_diff_config(&self, config: &DiffConfig) -> Result<(), GitError> {
        // Check required fields
        if config.path.is_empty() {
            return Err(GitError::InvalidDiffConfig {
                message: "path cannot be empty".to_string(),
            });
        }

        // Check timeout constraint
        if let Some(timeout_ms) = config.timeout_ms {
            if timeout_ms == 0 {
                return Err(GitError::InvalidDiffConfig {
                    message: "timeout_ms must be greater than 0".to_string(),
                });
            }
        }

        // Check unified context lines
        if let Some(unified) = config.unified {
            if unified < 0 {
                return Err(GitError::InvalidDiffConfig {
                    message: "unified context lines cannot be negative".to_string(),
                });
            }
        }

        // Check rename threshold
        if let Some(threshold) = config.rename_threshold {
            if threshold > 100 {
                return Err(GitError::InvalidDiffConfig {
                    message: "rename_threshold cannot exceed 100".to_string(),
                });
            }
        }

        // Check max_files and max_hunks
        if let Some(max_files) = config.max_files {
            if max_files == 0 {
                return Err(GitError::InvalidDiffConfig {
                    message: "max_files must be greater than 0".to_string(),
                });
            }
        }

        if let Some(max_hunks) = config.max_hunks {
            if max_hunks == 0 {
                return Err(GitError::InvalidDiffConfig {
                    message: "max_hunks must be greater than 0".to_string(),
                });
            }
        }

        // Check mode and from/to requirements
        let mode = config.mode.as_ref().unwrap_or(&DiffMode::WorkdirVsIndex);
        match mode {
            DiffMode::CommitVsCommit => {
                if config.from.is_none() {
                    return Err(GitError::InvalidDiffConfig {
                        message: "from is required for commit_vs_commit mode".to_string(),
                    });
                }
                if config.to.is_none() {
                    return Err(GitError::InvalidDiffConfig {
                        message: "to is required for commit_vs_commit mode".to_string(),
                    });
                }
            }
            DiffMode::CommitVsWorkdir | DiffMode::CommitVsIndex => {
                if config.from.is_none() {
                    return Err(GitError::InvalidDiffConfig {
                        message: "from is required for commit-based modes".to_string(),
                    });
                }
            }
            _ => {} // Other modes don't require from/to
        }

        // Check paths is not empty if provided
        if let Some(ref paths) = config.paths {
            if paths.is_empty() {
                return Err(GitError::InvalidDiffConfig {
                    message: "paths cannot be an empty array".to_string(),
                });
            }
        }

        // Check path exists and is a directory
        let path = Path::new(&config.path);
        if !path.exists() {
            return Err(GitError::RepositoryNotFound {
                path: config.path.clone(),
            });
        }

        if !path.is_dir() {
            return Err(GitError::InvalidDiffConfig {
                message: "path must be a directory".to_string(),
            });
        }

        Ok(())
    }

    /// Stage files based on 'all' flag and 'paths' list
    fn stage_commit_files(&self, repo: &Repository, config: &CommitConfig) -> Result<usize, GitError> {
        let mut index = repo.index().map_err(|e| GitError::CommitFailed {
            message: format!("failed to get repository index: {}", e),
        })?;

        let mut staged_count = 0;

        // Stage files based on 'all' flag
        if config.all.unwrap_or(false) {
            staged_count += self.stage_all_tracked_changes(repo, &mut index)?;
        }

        // Stage specific paths if provided
        if let Some(ref paths) = config.paths {
            for path in paths {
                staged_count += self.stage_specific_path(repo, &mut index, path)?;
            }
        }

        // Write the index
        index.write().map_err(|e| GitError::CommitFailed {
            message: format!("failed to write index: {}", e),
        })?;

        Ok(staged_count)
    }

    /// Stage all tracked modified/deleted files (equivalent to git commit -a)
    fn stage_all_tracked_changes(&self, repo: &Repository, index: &mut Index) -> Result<usize, GitError> {
        let statuses = repo.statuses(None).map_err(|e| GitError::CommitFailed {
            message: format!("failed to get repository status: {}", e),
        })?;

        let mut staged_count = 0;

        for status_entry in statuses.iter() {
            let status = status_entry.status();
            let path = status_entry.path().ok_or_else(|| GitError::CommitFailed {
                message: "invalid file path in status".to_string(),
            })?;

            // Only stage tracked files that have working tree changes
            if status.contains(GitStatus::WT_MODIFIED) || status.contains(GitStatus::WT_DELETED) {
                if status.contains(GitStatus::WT_DELETED) {
                    // Remove deleted file from index
                    index.remove_path(Path::new(path)).map_err(|e| GitError::CommitFailed {
                        message: format!("failed to remove path from index: {}", e),
                    })?;
                } else {
                    // Add modified file to index
                    index.add_path(Path::new(path)).map_err(|e| GitError::CommitFailed {
                        message: format!("failed to add path to index: {}", e),
                    })?;
                }
                staged_count += 1;
            }
        }

        Ok(staged_count)
    }

    /// Stage a specific path
    fn stage_specific_path(&self, _repo: &Repository, index: &mut Index, path: &str) -> Result<usize, GitError> {
        let path_buf = Path::new(path);
        
        // Check if path exists in working tree
        if path_buf.exists() {
            // Add the file to index
            index.add_path(path_buf).map_err(|e| GitError::CommitFailed {
                message: format!("failed to add path '{}' to index: {}", path, e),
            })?;
            Ok(1)
        } else {
            // File might be deleted, try to remove from index
            match index.remove_path(path_buf) {
                Ok(_) => Ok(1),
                Err(e) => Err(GitError::CommitFailed {
                    message: format!("failed to stage path '{}': {}", path, e),
                }),
            }
        }
    }

    /// Check if there are changes to commit by comparing index with HEAD
    fn has_changes_to_commit(&self, repo: &Repository, allow_empty: bool) -> Result<bool, GitError> {
        if allow_empty {
            return Ok(true);
        }

        let mut index = repo.index().map_err(|e| GitError::CommitFailed {
            message: format!("failed to get repository index: {}", e),
        })?;

        // Write index tree to get current staged state
        let index_tree_oid = index.write_tree().map_err(|e| GitError::CommitFailed {
            message: format!("failed to write index tree: {}", e),
        })?;

        // Compare with HEAD tree if it exists
        match repo.head() {
            Ok(head_ref) => {
                // HEAD exists, compare trees
                let head_commit = head_ref.peel_to_commit().map_err(|e| GitError::CommitFailed {
                    message: format!("failed to get HEAD commit: {}", e),
                })?;
                let head_tree_oid = head_commit.tree_id();
                
                Ok(index_tree_oid != head_tree_oid)
            }
            Err(_) => {
                // No HEAD (empty repository), check if index has any entries
                Ok(index.len() > 0)
            }
        }
    }

    /// Resolve commit author identity with fallback chain
    fn resolve_commit_author(&self, repo: &Repository, config: &CommitConfig, profile: &GitConnectionProfile) -> Result<(String, String), GitError> {
        // Priority: config fields -> alias profile -> git config
        
        let name = config.author_name.clone()
            .or_else(|| profile.username.clone())
            .or_else(|| self.get_git_config_value(repo, "user.name"))
            .ok_or(GitError::CommitIdentityMissing)?;
            
        let email = config.author_email.clone()
            .or_else(|| self.get_git_config_value(repo, "user.email"))
            .ok_or(GitError::CommitIdentityMissing)?;

        Ok((name, email))
    }

    /// Resolve commit committer identity with fallback to author
    fn resolve_commit_committer(&self, repo: &Repository, config: &CommitConfig, profile: &GitConnectionProfile, author: &(String, String)) -> Result<(String, String), GitError> {
        // Priority: config fields -> author identity
        
        let name = config.committer_name.clone()
            .or_else(|| config.author_name.clone())
            .or_else(|| profile.username.clone())
            .or_else(|| self.get_git_config_value(repo, "user.name"))
            .unwrap_or_else(|| author.0.clone());
            
        let email = config.committer_email.clone()
            .or_else(|| config.author_email.clone())
            .or_else(|| self.get_git_config_value(repo, "user.email"))
            .unwrap_or_else(|| author.1.clone());

        Ok((name, email))
    }

    /// Get a value from Git configuration
    fn get_git_config_value(&self, repo: &Repository, key: &str) -> Option<String> {
        repo.config()
            .and_then(|config| config.get_string(key))
            .ok()
    }

    /// Create a Git signature from name, email and timestamp
    fn create_signature(&self, name: &str, email: &str, config: &CommitConfig) -> Result<Signature, GitError> {
        match &config.timestamp {
            Some(CommitTimestamp::Iso8601(iso)) => {
                let dt = chrono::DateTime::parse_from_rfc3339(iso)
                    .map_err(|e| GitError::InvalidCommitConfig {
                        message: format!("invalid ISO8601 timestamp: {}", e),
                    })?;
                let timestamp = dt.timestamp() as i64;
                let offset = dt.offset().local_minus_utc() / 60; // offset in minutes

                Signature::new(name, email, &Time::new(timestamp, offset))
                    .map_err(|e| GitError::CommitFailed {
                        message: format!("failed to create signature: {}", e),
                    })
            }
            Some(CommitTimestamp::UnixSeconds(secs)) => {
                let timestamp = *secs as i64;
                Signature::new(name, email, &Time::new(timestamp, 0))
                    .map_err(|e| GitError::CommitFailed {
                        message: format!("failed to create signature: {}", e),
                    })
            }
            None => {
                Signature::now(name, email)
                    .map_err(|e| GitError::CommitFailed {
                        message: format!("failed to create signature: {}", e),
                    })
            }
        }
    }

    /// Build final commit message with signoff logic
    fn build_commit_message(&self, repo: &Repository, config: &CommitConfig, author: &(String, String)) -> Result<String, GitError> {
        let base_message = if config.amend.unwrap_or(false) && config.no_edit.unwrap_or(false) {
            // Use existing HEAD commit message
            match repo.head() {
                Ok(head_ref) => {
                    let head_commit = head_ref.peel_to_commit().map_err(|e| GitError::CommitAmendFailed {
                        message: format!("failed to get HEAD commit: {}", e),
                    })?;
                    head_commit.message().unwrap_or("").to_string()
                }
                Err(_) => return Err(GitError::CommitAmendWithoutHead),
            }
        } else {
            config.message.clone().unwrap_or_default()
        };

        let mut final_message = base_message;

        // Add signoff if requested
        if config.signoff.unwrap_or(false) {
            let signoff_line = format!("Signed-off-by: {} <{}>", author.0, author.1);
            
            // Check if signoff already exists to avoid duplicates
            if !final_message.contains(&signoff_line) {
                if !final_message.ends_with('\n') {
                    final_message.push('\n');
                }
                if !final_message.is_empty() {
                    final_message.push('\n');
                }
                final_message.push_str(&signoff_line);
            }
        }

        Ok(final_message)
    }

    /// Load connection profile for the alias
    fn load_connection_profile(&self) -> Result<GitConnectionProfile, GitError> {
        // Check if connection is registered
        if let Some(profile) = GIT_CONNECTIONS.get(&self.alias) {
            return Ok(profile.clone());
        }

        // For local operations like commit, status, branch - return a default profile
        // This allows these operations to work without explicit connection configuration
        Ok(GitConnectionProfile {
            ssh_key_path: None,
            known_hosts_path: None,
            username: None,
            password: None,
            token: None,
        })
    }

    /// Execute the actual clone operation
    async fn execute_clone(
        &self,
        config: &CloneConfig,
        profile: &GitConnectionProfile,
    ) -> Result<Value, GitError> {
        let path = Path::new(&config.path);

        // Check if target directory exists and is not empty
        if path.exists() && path.read_dir().map_err(|e| GitError::CloneFailed {
            message: format!("failed to check target directory: {}", e),
        })?.next().is_some() {
            return Err(GitError::CloneTargetNotEmpty {
                path: config.path.clone(),
            });
        }

        // Create parent directories if needed
        if let Some(parent) = path.parent() {
            std::fs::create_dir_all(parent).map_err(|e| GitError::CloneFailed {
                message: format!("failed to create parent directories: {}", e),
            })?;
        }

        // Setup authentication callbacks
        let mut fetch_options = FetchOptions::new();
        let mut callbacks = RemoteCallbacks::new();
        
        self.setup_authentication_callbacks(&mut callbacks, config, profile)?;
        fetch_options.remote_callbacks(callbacks);

        // Configure clone options
        let mut builder = git2::build::RepoBuilder::new();
        builder.fetch_options(fetch_options);

        if let Some(branch) = &config.branch {
            builder.branch(branch);
        }

        if let Some(depth) = config.depth {
            // Git2 doesn't directly support shallow clones, but we can set fetch options
            // This is a limitation of libgit2
            log::warn!("Shallow clone depth={} requested but not fully supported by libgit2", depth);
        }

        // Execute the clone
        let repo = builder.clone(&config.url, path).map_err(|e| {
            let message = format!("git clone failed: {}", e);
            if e.to_string().contains("authentication") {
                GitError::CloneAuthFailed { message }
            } else {
                GitError::CloneFailed { message }
            }
        })?;

        // Handle recursive submodules
        if config.recursive.unwrap_or(false) {
            self.update_submodules(&repo)?;
        }

        // Validate the result
        self.validate_clone_result(&repo, path)?;

        // Return success result
        let result = CloneResult {
            backend: "git".to_string(),
            alias: self.alias.clone(),
            url: config.url.clone(),
            path: config.path.clone(),
            branch: config.branch.clone(),
            depth: config.depth,
            recursive: config.recursive.unwrap_or(false),
            status: "cloned".to_string(),
        };

        log::info!("Successfully cloned {} to {}", config.url, config.path);
        Ok(serde_json::to_value(result).unwrap())
    }

    /// Execute the actual pull operation
    async fn execute_pull(
        &self,
        config: &PullConfig,
        profile: &GitConnectionProfile,
    ) -> Result<Value, GitError> {
        let path = Path::new(&config.path);

        // Open the existing repository
        let repo = Repository::open(path).map_err(|e| {
            if e.code() == git2::ErrorCode::NotFound {
                GitError::RepositoryNotFound {
                    path: config.path.clone(),
                }
            } else {
                GitError::PullFailed {
                    message: format!("failed to open repository: {}", e),
                }
            }
        })?;

        // Determine the target branch
        let target_branch = if let Some(ref branch) = config.branch {
            branch.clone()
        } else {
            // Get current branch from HEAD
            let head = repo.head().map_err(|e| GitError::PullFailed {
                message: format!("failed to get HEAD: {}", e),
            })?;
            
            if !head.is_branch() {
                return Err(GitError::PullDetachedHead);
            }
            
            head.shorthand().unwrap_or("main").to_string()
        };

        // Resolve remote name
        let remote_name = config.remote.as_deref().unwrap_or("origin");

        // Verify remote exists
        let mut remote = repo.find_remote(remote_name).map_err(|_| GitError::RemoteNotFound {
            remote: remote_name.to_string(),
        })?;

        // Setup authentication callbacks for fetch
        let mut fetch_options = FetchOptions::new();
        let mut callbacks = RemoteCallbacks::new();
        
        self.setup_pull_authentication_callbacks(&mut callbacks, config, profile)?;
        fetch_options.remote_callbacks(callbacks);

        // Configure fetch options
        if config.prune.unwrap_or(false) {
            // Enable pruning of remote-tracking branches
            // This is handled by the fetch refspec
        }

        // Fetch from remote
        log::debug!("Fetching from remote '{}' for branch '{}'", remote_name, target_branch);
        
        let refspecs = remote.fetch_refspecs().map_err(|e| GitError::PullFetchFailed {
            message: format!("failed to get refspecs: {}", e),
        })?;
        
        // Convert StringArray to Vec<&str> for fetch
        let refspecs_vec: Vec<&str> = refspecs.iter().flatten().collect();
        
        remote.fetch(&refspecs_vec, Some(&mut fetch_options), None).map_err(|e| {
            let message = format!("fetch failed: {}", e);
            if e.to_string().contains("authentication") {
                GitError::PullAuthFailed { message }
            } else {
                GitError::PullFetchFailed { message }
            }
        })?;

        // Find the local and remote tracking branch references
        let local_ref_name = format!("refs/heads/{}", target_branch);
        let remote_ref_name = format!("refs/remotes/{}/{}", remote_name, target_branch);

        let local_ref = repo.find_reference(&local_ref_name).map_err(|_| GitError::PullFailed {
            message: format!("local branch '{}' not found", target_branch),
        })?;

        let remote_ref = repo.find_reference(&remote_ref_name).map_err(|_| GitError::PullRemoteBranchNotFound {
            branch: format!("{}/{}", remote_name, target_branch),
        })?;

        let local_oid = local_ref.target().ok_or_else(|| GitError::PullFailed {
            message: "local reference has no target".to_string(),
        })?;

        let remote_oid = remote_ref.target().ok_or_else(|| GitError::PullFailed {
            message: "remote reference has no target".to_string(),
        })?;

        // Check if already up-to-date
        if local_oid == remote_oid {
            log::info!("Repository at {} is already up-to-date", config.path);
            let result = PullResult {
                backend: "git".to_string(),
                alias: self.alias.clone(),
                path: config.path.clone(),
                remote: remote_name.to_string(),
                branch: target_branch,
                status: "up_to_date".to_string(),
                rebase: config.rebase.unwrap_or(false),
                ff_only: config.ff_only.unwrap_or(false),
                ahead_by: Some(0),
                behind_by: Some(0),
                commits_fetched: Some(0),
            };
            return Ok(serde_json::to_value(result).unwrap());
        }

        // Compute ahead/behind counts
        let (ahead, behind) = repo.graph_ahead_behind(local_oid, remote_oid).map_err(|e| GitError::PullFailed {
            message: format!("failed to compute ahead/behind: {}", e),
        })?;

        log::debug!("Local is {} ahead, {} behind remote", ahead, behind);

        // Check working directory status if needed
        if config.ff_only.unwrap_or(false) && ahead > 0 && behind > 0 {
            // Non-fast-forward case with ff_only
            return Err(GitError::PullNonFastForward);
        }

        // Determine merge strategy
        if behind == 0 {
            // Already ahead or equal, no need to pull
            let result = PullResult {
                backend: "git".to_string(),
                alias: self.alias.clone(),
                path: config.path.clone(),
                remote: remote_name.to_string(),
                branch: target_branch,
                status: "up_to_date".to_string(),
                rebase: config.rebase.unwrap_or(false),
                ff_only: config.ff_only.unwrap_or(false),
                ahead_by: Some(ahead),
                behind_by: Some(0),
                commits_fetched: Some(0),
            };
            return Ok(serde_json::to_value(result).unwrap());
        }

        // Perform the merge/rebase
        if ahead == 0 {
            // Fast-forward case
            self.do_fast_forward(&repo, &local_ref, remote_oid, &target_branch)?;
        } else if config.rebase.unwrap_or(false) {
            // Rebase case
            return Err(GitError::PullFailed {
                message: "rebase operation not yet implemented".to_string(),
            });
        } else {
            // Merge case
            return Err(GitError::PullFailed {
                message: "merge operation not yet implemented".to_string(),
            });
        }

        log::info!("Successfully pulled {} commits from {}/{}", behind, remote_name, target_branch);
        
        let result = PullResult {
            backend: "git".to_string(),
            alias: self.alias.clone(),
            path: config.path.clone(),
            remote: remote_name.to_string(),
            branch: target_branch,
            status: "updated".to_string(),
            rebase: config.rebase.unwrap_or(false),
            ff_only: config.ff_only.unwrap_or(false),
            ahead_by: Some(ahead),
            behind_by: Some(behind),
            commits_fetched: Some(behind),
        };

        Ok(serde_json::to_value(result).unwrap())
    }

    /// Setup authentication callbacks for pull operations
    fn setup_pull_authentication_callbacks(
        &self,
        callbacks: &mut RemoteCallbacks,
        config: &PullConfig,
        profile: &GitConnectionProfile,
    ) -> Result<(), GitError> {
        // Clone all auth values for the closure
        let ssh_key_clone = config.ssh_key.clone().or_else(|| 
            profile.ssh_key_path.as_ref().map(|p| p.to_string_lossy().to_string())
        );
        let username_clone = config.username.clone().or_else(|| profile.username.clone());
        let password_clone = config.password.clone().or_else(|| profile.password.clone());
        let token_clone = config.token.clone().or_else(|| profile.token.clone());

        callbacks.credentials(move |_url, username_from_url, allowed_types| {
            log::debug!("Git authentication requested for pull, allowed_types: {:?}", allowed_types);

            if allowed_types.contains(CredentialType::SSH_KEY) {
                if let Some(ref key_path) = ssh_key_clone {
                    let username = username_from_url.unwrap_or("git");
                    return git2::Cred::ssh_key(
                        username,
                        None, // public key path - let git2 figure it out
                        Path::new(key_path),
                        None, // passphrase
                    );
                }
            }

            if allowed_types.contains(CredentialType::USER_PASS_PLAINTEXT) {
                if let (Some(user), Some(pass)) = (&username_clone, &password_clone) {
                    return git2::Cred::userpass_plaintext(user, pass);
                }
                if let Some(ref token) = token_clone {
                    // Use token as password with empty username for HTTPS
                    return git2::Cred::userpass_plaintext("", token);
                }
            }

            if allowed_types.contains(CredentialType::DEFAULT) {
                return git2::Cred::default();
            }

            Err(git2::Error::from_str("no authentication method available"))
        });

        Ok(())
    }

    /// Perform a fast-forward merge
    fn do_fast_forward(
        &self,
        repo: &Repository,
        local_ref: &git2::Reference,
        remote_oid: git2::Oid,
        branch_name: &str,
    ) -> Result<(), GitError> {
        // Update the local branch reference to point to the remote commit
        let mut local_ref_mut = repo.find_reference(&local_ref.name().unwrap()).map_err(|e| GitError::PullFailed {
            message: format!("failed to find local reference: {}", e),
        })?;

        local_ref_mut.set_target(remote_oid, &format!("fast-forward to {}", remote_oid)).map_err(|e| GitError::PullFailed {
            message: format!("failed to update local branch: {}", e),
        })?;

        // Update HEAD if we're on this branch
        let head = repo.head().map_err(|e| GitError::PullFailed {
            message: format!("failed to get HEAD: {}", e),
        })?;

        if head.is_branch() && head.shorthand() == Some(branch_name) {
            // Checkout the new commit to update working tree
            let commit = repo.find_commit(remote_oid).map_err(|e| GitError::PullFailed {
                message: format!("failed to find commit: {}", e),
            })?;

            let tree = commit.tree().map_err(|e| GitError::PullFailed {
                message: format!("failed to get tree: {}", e),
            })?;

            repo.checkout_tree(tree.as_object(), Some(
                git2::build::CheckoutBuilder::new()
                    .force() // Force checkout to update working tree
            )).map_err(|e| GitError::PullFailed {
                message: format!("failed to checkout tree: {}", e),
            })?;

            // Update HEAD to point to new commit
            repo.set_head(&format!("refs/heads/{}", branch_name)).map_err(|e| GitError::PullFailed {
                message: format!("failed to update HEAD: {}", e),
            })?;
        }

        Ok(())
    }

    /// Setup authentication callbacks based on configuration
    fn setup_authentication_callbacks(
        &self,
        callbacks: &mut RemoteCallbacks,
        config: &CloneConfig,
        profile: &GitConnectionProfile,
    ) -> Result<(), GitError> {
        // Clone all auth values for the closure
        let ssh_key_clone = config.ssh_key.clone().or_else(|| 
            profile.ssh_key_path.as_ref().map(|p| p.to_string_lossy().to_string())
        );
        let username_clone = config.username.clone().or_else(|| profile.username.clone());
        let password_clone = config.password.clone().or_else(|| profile.password.clone());
        let token_clone = config.token.clone().or_else(|| profile.token.clone());

        callbacks.credentials(move |_url, username_from_url, allowed_types| {
            log::debug!("Git authentication requested, allowed_types: {:?}", allowed_types);

            if allowed_types.contains(CredentialType::SSH_KEY) {
                if let Some(ref key_path) = ssh_key_clone {
                    let username = username_from_url.unwrap_or("git");
                    return git2::Cred::ssh_key(
                        username,
                        None, // public key path - let git2 figure it out
                        Path::new(key_path),
                        None, // passphrase
                    );
                }
            }

            if allowed_types.contains(CredentialType::USER_PASS_PLAINTEXT) {
                if let (Some(user), Some(pass)) = (&username_clone, &password_clone) {
                    return git2::Cred::userpass_plaintext(user, pass);
                }
                if let Some(ref token) = token_clone {
                    // Use token as password with empty username for HTTPS
                    return git2::Cred::userpass_plaintext("", token);
                }
            }

            if allowed_types.contains(CredentialType::DEFAULT) {
                return git2::Cred::default();
            }

            Err(git2::Error::from_str("no authentication method available"))
        });

        Ok(())
    }

    /// Update submodules recursively
    fn update_submodules(&self, _repo: &Repository) -> Result<(), GitError> {
        // Submodule handling is complex in git2 and would require significant additional code
        // For now, we'll log a warning and continue
        log::warn!("Recursive submodule cloning not yet implemented");
        Ok(())
    }

    /// Validate that the clone was successful
    fn validate_clone_result(&self, repo: &Repository, path: &Path) -> Result<(), GitError> {
        // Check that repository exists at path
        if !path.exists() {
            return Err(GitError::CloneFailed {
                message: "clone target directory does not exist".to_string(),
            });
        }

        // Check that HEAD resolves
        repo.head().map_err(|e| GitError::CloneFailed {
            message: format!("cloned repository HEAD does not resolve: {}", e),
        })?;

        Ok(())
    }

    /// Execute the actual push operation
    async fn execute_push(
        &self,
        config: &PushConfig,
        profile: &GitConnectionProfile,
    ) -> Result<Value, GitError> {
        let path = Path::new(&config.path);

        // Open the existing repository
        let repo = Repository::open(path).map_err(|e| {
            if e.code() == git2::ErrorCode::NotFound {
                GitError::RepositoryNotFound {
                    path: config.path.clone(),
                }
            } else {
                GitError::PushFailed {
                    message: format!("failed to open repository: {}", e),
                }
            }
        })?;

        // Resolve remote name
        let remote_name = config.remote.as_deref().unwrap_or("origin");

        // Verify remote exists
        let mut remote = repo.find_remote(remote_name).map_err(|_| GitError::RemoteNotFound {
            remote: remote_name.to_string(),
        })?;

        // Resolve branches to push
        let branches_to_push = self.resolve_push_branches(&repo, config)?;

        // Compute ahead/behind counts for each branch (for ff_only check and reporting)
        let mut branch_statuses = Vec::new();
        for branch_name in &branches_to_push {
            let (ahead_by, behind_by) = self.compute_ahead_behind(&repo, branch_name, remote_name)?;
            
            // Check ff_only constraints
            if config.ff_only.unwrap_or(false) && behind_by > 0 {
                return Err(GitError::PushNonFastForward);
            }

            branch_statuses.push((branch_name.clone(), ahead_by, behind_by));
        }

        // Setup authentication callbacks for push
        let mut callbacks = RemoteCallbacks::new();
        self.setup_push_authentication_callbacks(&mut callbacks, config, profile)?;

        // Build refspecs for branches
        let mut refspecs = Vec::new();
        let force = config.force.unwrap_or(false);
        
        for branch_name in &branches_to_push {
            let refspec = if force {
                format!("+refs/heads/{}:refs/heads/{}", branch_name, branch_name)
            } else {
                format!("refs/heads/{}:refs/heads/{}", branch_name, branch_name)
            };
            refspecs.push(refspec);
        }

        // Add tags refspec if requested
        let tags_pushed = if config.tags.unwrap_or(false) {
            let tag_refspec = if force {
                "+refs/tags/*:refs/tags/*".to_string()
            } else {
                "refs/tags/*:refs/tags/*".to_string()
            };
            refspecs.push(tag_refspec);
            true
        } else {
            false
        };

        // Convert refspecs to string slices
        let refspec_strs: Vec<&str> = refspecs.iter().map(|s| s.as_str()).collect();

        // Setup push options
        let mut push_options = git2::PushOptions::new();
        push_options.remote_callbacks(callbacks);

        // Perform the push
        log::debug!("Pushing {} branches and tags={} to remote '{}'", 
                   branches_to_push.len(), tags_pushed, remote_name);
        
        remote.push(&refspec_strs, Some(&mut push_options)).map_err(|e| {
            let message = format!("push failed: {}", e);
            if e.to_string().contains("authentication") {
                GitError::PushAuthFailed { message }
            } else if e.to_string().contains("non-fast-forward") || e.to_string().contains("rejected") {
                GitError::PushRejected { message }
            } else {
                GitError::PushFailed { message }
            }
        })?;

        // Set upstream if requested
        if config.set_upstream.unwrap_or(false) {
            self.set_upstream_branches(&repo, &branches_to_push, remote_name)?;
        }

        // Build result with status for each branch
        let mut result_branches = Vec::new();
        for (branch_name, ahead_by, behind_by) in branch_statuses {
            let status = if ahead_by == 0 {
                "up_to_date".to_string()
            } else {
                "pushed".to_string()
            };
            
            result_branches.push(PushBranchStatus {
                name: branch_name,
                status,
                ahead_by,
                behind_by,
            });
        }

        log::info!("Successfully pushed {} branches to {}", result_branches.len(), remote_name);
        
        let result = PushResult {
            backend: "git".to_string(),
            alias: self.alias.clone(),
            path: config.path.clone(),
            remote: remote_name.to_string(),
            branches: result_branches,
            tags_pushed,
        };

        Ok(serde_json::to_value(result).unwrap())
    }

    /// Execute the actual status operation
    async fn execute_status(&self, config: &StatusConfig) -> Result<Value, GitError> {
        let path = Path::new(&config.path);

        // Open the repository
        let repo = Repository::open(path).map_err(|e| {
            if e.code() == git2::ErrorCode::NotFound {
                GitError::RepositoryNotFound {
                    path: config.path.clone(),
                }
            } else {
                GitError::StatusFailed {
                    message: format!("failed to open repository: {}", e),
                }
            }
        })?;

        // Get branch information
        let branch = if config.include_branch.unwrap_or(true) {
            Some(self.get_branch_info(&repo, config.include_remote.unwrap_or(true))?)
        } else {
            None
        };

        // Get working tree status
        let working_tree = self.get_working_tree_status(&repo, config)?;

        // Get in-progress operation flags
        let in_progress = self.get_in_progress_flags(&repo)?;

        let result = StatusResult {
            backend: "git".to_string(),
            alias: self.alias.clone(),
            path: config.path.clone(),
            branch,
            working_tree,
            in_progress,
        };

        log::info!("Successfully retrieved status for repository at {}", config.path);
        Ok(serde_json::to_value(result).unwrap())
    }

    /// Execute the actual branch operation
    async fn execute_branch(&self, config: &BranchConfig) -> Result<Value, GitError> {
        let path = Path::new(&config.path);

        // Open the repository
        let repo = Repository::open(path).map_err(|e| {
            if e.code() == git2::ErrorCode::NotFound {
                GitError::RepositoryNotFound {
                    path: config.path.clone(),
                }
            } else {
                GitError::BranchFailed {
                    message: format!("failed to open repository: {}", e),
                }
            }
        })?;

        // Get action (default to List if not provided)
        let action = config.action.as_ref().unwrap_or(&BranchAction::List);

        // Dispatch to appropriate operation
        match action {
            BranchAction::List => self.list_branches(&repo, config).await,
            BranchAction::Create => self.create_branch(&repo, config).await,
            BranchAction::Delete => self.delete_branch(&repo, config).await,
            BranchAction::Rename => self.rename_branch(&repo, config).await,
            BranchAction::Checkout => self.checkout_branch(&repo, config).await,
        }
    }

    /// Execute the actual commit operation
    async fn execute_commit(&self, config: &CommitConfig, profile: &GitConnectionProfile) -> Result<Value, GitError> {
        let path = Path::new(&config.path);

        // Open the repository
        let repo = Repository::open(path).map_err(|e| {
            if e.code() == git2::ErrorCode::NotFound {
                GitError::RepositoryNotFound {
                    path: config.path.clone(),
                }
            } else {
                GitError::CommitFailed {
                    message: format!("failed to open repository: {}", e),
                }
            }
        })?;

        // Check for amend without HEAD
        if config.amend.unwrap_or(false) {
            if repo.head().is_err() {
                return Err(GitError::CommitAmendWithoutHead);
            }
        }

        // Stage files based on config
        let staged_files = self.stage_commit_files(&repo, config)?;

        // Check if there are changes to commit
        let allow_empty = config.allow_empty.unwrap_or(false);
        if !self.has_changes_to_commit(&repo, allow_empty)? {
            return Err(GitError::CommitNothingToCommit {
                path: config.path.clone(),
            });
        }

        // Resolve author and committer identity
        let author = self.resolve_commit_author(&repo, config, profile)?;
        let committer = self.resolve_commit_committer(&repo, config, profile, &author)?;

        // Build final commit message
        let message = self.build_commit_message(&repo, config, &author)?;

        // Create signatures
        let author_sig = self.create_signature(&author.0, &author.1, config)?;
        let committer_sig = self.create_signature(&committer.0, &committer.1, config)?;

        // Create or amend commit
        let commit_oid = if config.amend.unwrap_or(false) {
            self.amend_commit(&repo, &message, &author_sig, &committer_sig)?
        } else {
            self.create_new_commit(&repo, &message, &author_sig, &committer_sig)?
        };

        // Build and return result
        let result = CommitResult {
            backend: "git".to_string(),
            alias: self.alias.clone(),
            path: config.path.clone(),
            action: "commit".to_string(),
            commit: CommitInfo {
                oid: commit_oid.to_string(),
                message: message.clone(),
                author: CommitIdentity {
                    name: author.0,
                    email: author.1,
                },
                committer: CommitIdentity {
                    name: committer.0,
                    email: committer.1,
                },
                amend: config.amend.unwrap_or(false),
                allow_empty,
            },
            stats: CommitStats {
                staged_files,
                insertions: None, // Optional: could be computed from diff
                deletions: None,  // Optional: could be computed from diff
            },
        };

        log::info!("Successfully created commit {} in repository {}", commit_oid, config.path);
        Ok(serde_json::to_value(result).unwrap())
    }

    /// Execute diff operation
    async fn execute_diff(&self, config: &DiffConfig) -> Result<Value, GitError> {
        let path = Path::new(&config.path);

        // Open the repository
        let repo = Repository::open(path).map_err(|e| {
            if e.code() == git2::ErrorCode::NotFound {
                GitError::RepositoryNotFound {
                    path: config.path.clone(),
                }
            } else {
                GitError::DiffFailed {
                    message: format!("failed to open repository: {}", e),
                }
            }
        })?;

        let mode = config.mode.as_ref().unwrap_or(&DiffMode::WorkdirVsIndex);

        // Build diff options
        let mut diff_opts = git2::DiffOptions::new();
        if let Some(unified) = config.unified {
            diff_opts.context_lines(unified as u32);
        } else {
            diff_opts.context_lines(3);
        }

        // Set whitespace flags
        if config.ignore_whitespace.unwrap_or(false) {
            diff_opts.ignore_whitespace(true);
        }
        if config.ignore_whitespace_change.unwrap_or(false) {
            diff_opts.ignore_whitespace_change(true);
        }
        if config.ignore_whitespace_eol.unwrap_or(false) {
            diff_opts.ignore_whitespace_eol(true);
        }

        // Set path filters
        if let Some(ref paths) = config.paths {
            for path in paths {
                diff_opts.pathspec(path.as_str());
            }
        }

        // Create diff based on mode
        let mut diff = match mode {
            DiffMode::WorkdirVsIndex => {
                let index = repo.index().map_err(|e| GitError::DiffFailed {
                    message: format!("failed to get index: {}", e),
                })?;
                repo.diff_index_to_workdir(Some(&index), Some(&mut diff_opts))
                    .map_err(|e| GitError::DiffFailed {
                        message: format!("failed to create workdir vs index diff: {}", e),
                    })?
            }
            DiffMode::IndexVsHead => {
                let head_tree = self.get_head_tree(&repo)?;
                repo.diff_tree_to_index(Some(&head_tree), None, Some(&mut diff_opts))
                    .map_err(|e| GitError::DiffFailed {
                        message: format!("failed to create index vs HEAD diff: {}", e),
                    })?
            }
            DiffMode::HeadVsWorkdir => {
                let head_tree = self.get_head_tree(&repo)?;
                repo.diff_tree_to_workdir_with_index(Some(&head_tree), Some(&mut diff_opts))
                    .map_err(|e| GitError::DiffFailed {
                        message: format!("failed to create HEAD vs workdir diff: {}", e),
                    })?
            }
            DiffMode::CommitVsCommit => {
                let from_tree = self.resolve_commit_tree(&repo, config.from.as_ref().unwrap())?;
                let to_tree = self.resolve_commit_tree(&repo, config.to.as_ref().unwrap())?;
                repo.diff_tree_to_tree(Some(&from_tree), Some(&to_tree), Some(&mut diff_opts))
                    .map_err(|e| GitError::DiffFailed {
                        message: format!("failed to create commit vs commit diff: {}", e),
                    })?
            }
            DiffMode::CommitVsWorkdir => {
                let from_tree = self.resolve_commit_tree(&repo, config.from.as_ref().unwrap())?;
                repo.diff_tree_to_workdir_with_index(Some(&from_tree), Some(&mut diff_opts))
                    .map_err(|e| GitError::DiffFailed {
                        message: format!("failed to create commit vs workdir diff: {}", e),
                    })?
            }
            DiffMode::CommitVsIndex => {
                let from_tree = self.resolve_commit_tree(&repo, config.from.as_ref().unwrap())?;
                repo.diff_tree_to_index(Some(&from_tree), None, Some(&mut diff_opts))
                    .map_err(|e| GitError::DiffFailed {
                        message: format!("failed to create commit vs index diff: {}", e),
                    })?
            }
        };

        // Enable rename detection if requested
        if config.detect_renames.unwrap_or(true) {
            let threshold = config.rename_threshold.unwrap_or(50);
            let mut find_opts = git2::DiffFindOptions::new();
            find_opts.rename_threshold(threshold as u16);
            diff.find_similar(Some(&mut find_opts))
                .map_err(|e| GitError::DiffFailed {
                    message: format!("failed to detect renames: {}", e),
                })?;
        }

        // Parse diff and build result
        let max_files = config.max_files.unwrap_or(1000);
        let max_hunks = config.max_hunks.unwrap_or(10000);
        self.parse_diff_to_json(&diff, config, max_files, max_hunks).await
    }

    /// Execute tag operations (list, create, delete)
    async fn execute_tag(&self, config: &TagConfig, profile: &GitConnectionProfile) -> Result<Value, GitError> {
        let path = Path::new(&config.path);

        // Open the repository
        let repo = Repository::open(path).map_err(|e| {
            if e.code() == git2::ErrorCode::NotFound {
                GitError::RepositoryNotFound {
                    path: config.path.clone(),
                }
            } else {
                GitError::TagFailed {
                    message: format!("failed to open repository: {}", e),
                }
            }
        })?;

        let action = config.action.as_ref().unwrap_or(&TagAction::List);

        match action {
            TagAction::List => self.list_tags(&repo, config).await,
            TagAction::Create => self.create_tag(&repo, config, profile).await,
            TagAction::Delete => self.delete_tags(&repo, config).await,
        }
    }

    /// List tags operation
    async fn list_tags(&self, repo: &Repository, config: &TagConfig) -> Result<Value, GitError> {
        let pattern = config.pattern.as_ref().map(|p| p.as_str());
        
        // Get tag names from repository
        let tag_names = repo.tag_names(pattern).map_err(|e| GitError::TagListFailed {
            message: format!("failed to list tags: {}", e),
        })?;

        let mut tags = Vec::new();

        // Process each tag
        for i in 0..tag_names.len() {
            if let Some(name) = tag_names.get(i) {
                match self.get_tag_info(&repo, name) {
                    Ok(tag_entry) => tags.push(tag_entry),
                    Err(e) => {
                        log::warn!("Failed to get info for tag '{}': {}", name, e);
                        continue;
                    }
                }
            }
        }

        // Sort tags
        let sort = config.sort.as_ref().unwrap_or(&TagSort::Name);
        self.sort_tags(&mut tags, sort);

        let result = TagListResult {
            backend: "git".to_string(),
            alias: self.alias.clone(),
            path: config.path.clone(),
            action: "list".to_string(),
            pattern: config.pattern.clone(),
            sort: format!("{:?}", sort).to_lowercase(),
            count: tags.len(),
            tags,
        };

        Ok(serde_json::to_value(result).unwrap())
    }

    /// Create tag operation
    async fn create_tag(&self, repo: &Repository, config: &TagConfig, profile: &GitConnectionProfile) -> Result<Value, GitError> {
        let name = config.name.as_ref().unwrap(); // Already validated
        let default_target = "HEAD".to_string();
        let target_str = config.target.as_ref().unwrap_or(&default_target);
        let force = config.force.unwrap_or(false);
        let annotated = config.annotated.unwrap_or(false);

        // Resolve target object
        let target = repo.revparse_single(target_str).map_err(|_| {
            GitError::TagTargetNotFound {
                target: target_str.clone(),
            }
        })?;

        // Check if tag already exists
        if !force {
            if repo.find_reference(&format!("refs/tags/{}", name)).is_ok() {
                return Err(GitError::TagAlreadyExists {
                    name: name.clone(),
                });
            }
        }

        let _tag_oid = if annotated {
            // Create annotated tag
            let message = config.message.as_ref().unwrap(); // Already validated
            let tagger = self.resolve_tag_identity(config, profile, repo)?;

            repo.tag(name, &target, &tagger, message, force).map_err(|e| {
                GitError::TagCreateFailed {
                    message: format!("failed to create annotated tag: {}", e),
                }
            })?
        } else {
            // Create lightweight tag
            repo.tag_lightweight(name, &target, force).map_err(|e| {
                GitError::TagCreateFailed {
                    message: format!("failed to create lightweight tag: {}", e),
                }
            })?
        };

        // Get the created tag info
        let tag_entry = self.get_tag_info(&repo, name)?;

        let status = if force && repo.find_reference(&format!("refs/tags/{}", name)).is_ok() {
            "overwritten"
        } else {
            "created"
        };

        let result = TagCreateResult {
            backend: "git".to_string(),
            alias: self.alias.clone(),
            path: config.path.clone(),
            action: "create".to_string(),
            tag: tag_entry,
            status: status.to_string(),
            force,
        };

        Ok(serde_json::to_value(result).unwrap())
    }

    /// Delete tags operation
    async fn delete_tags(&self, repo: &Repository, config: &TagConfig) -> Result<Value, GitError> {
        let force = config.force.unwrap_or(false);
        
        // Determine which tags to delete
        let names_to_delete = if let Some(names) = &config.names {
            names.clone()
        } else if let Some(name) = &config.name {
            vec![name.clone()]
        } else {
            return Err(GitError::InvalidTagConfig {
                message: "either name or names must be provided for delete".to_string(),
            });
        };

        let mut deleted = Vec::new();
        let mut missing = Vec::new();

        for name in &names_to_delete {
            let refname = format!("refs/tags/{}", name);
            match repo.find_reference(&refname) {
                Ok(mut tag_ref) => {
                    match tag_ref.delete() {
                        Ok(_) => deleted.push(name.clone()),
                        Err(e) => {
                            return Err(GitError::TagDeleteFailed {
                                message: format!("failed to delete tag '{}': {}", name, e),
                            });
                        }
                    }
                }
                Err(_) => {
                    if force {
                        missing.push(name.clone());
                    } else {
                        return Err(GitError::TagNotFound {
                            name: name.clone(),
                        });
                    }
                }
            }
        }

        let result = TagDeleteResult {
            backend: "git".to_string(),
            alias: self.alias.clone(),
            path: config.path.clone(),
            action: "delete".to_string(),
            requested: names_to_delete,
            deleted,
            missing,
            force,
        };

        Ok(serde_json::to_value(result).unwrap())
    }

    /// Get detailed information about a specific tag
    fn get_tag_info(&self, repo: &Repository, name: &str) -> Result<TagEntry, GitError> {
        let refname = format!("refs/tags/{}", name);
        
        // First try to find it as an annotated tag by finding the tag object
        if let Ok(oid) = repo.refname_to_id(&refname) {
            if let Ok(obj) = repo.find_object(oid, None) {
                match obj.kind().unwrap() {
                    git2::ObjectType::Tag => {
                        // This is an annotated tag
                        let tag = obj.as_tag().unwrap();
                        let target_obj = tag.target().map_err(|e| GitError::TagFailed {
                            message: format!("failed to get tag target: {}", e),
                        })?;

                        let tagger = if let Some(sig) = tag.tagger() {
                            Some(TagTagger {
                                name: sig.name().unwrap_or("").to_string(),
                                email: sig.email().unwrap_or("").to_string(),
                                timestamp: self.format_time(&sig.when()),
                            })
                        } else {
                            None
                        };

                        return Ok(TagEntry {
                            name: name.to_string(),
                            annotated: true,
                            message: Some(tag.message().unwrap_or("").to_string()),
                            target: TagTarget {
                                oid: target_obj.id().to_string(),
                                object_type: match target_obj.kind().unwrap() {
                                    git2::ObjectType::Commit => "commit".to_string(),
                                    git2::ObjectType::Tag => "tag".to_string(),
                                    git2::ObjectType::Tree => "tree".to_string(),
                                    git2::ObjectType::Blob => "blob".to_string(),
                                    _ => "unknown".to_string(),
                                },
                            },
                            tagger,
                        });
                    }
                    _ => {
                        // This is a lightweight tag pointing directly to an object
                        return Ok(TagEntry {
                            name: name.to_string(),
                            annotated: false,
                            message: None,
                            target: TagTarget {
                                oid: obj.id().to_string(),
                                object_type: match obj.kind().unwrap() {
                                    git2::ObjectType::Commit => "commit".to_string(),
                                    git2::ObjectType::Tag => "tag".to_string(),
                                    git2::ObjectType::Tree => "tree".to_string(),
                                    git2::ObjectType::Blob => "blob".to_string(),
                                    _ => "unknown".to_string(),
                                },
                            },
                            tagger: None,
                        });
                    }
                }
            }
        }

        Err(GitError::TagNotFound {
            name: name.to_string(),
        })
    }

    /// Sort tags according to the specified sort method
    fn sort_tags(&self, tags: &mut Vec<TagEntry>, sort: &TagSort) {
        match sort {
            TagSort::Name => {
                tags.sort_by(|a, b| a.name.cmp(&b.name));
            }
            TagSort::Version => {
                tags.sort_by(|a, b| self.compare_versions(&a.name, &b.name));
            }
            TagSort::TaggerDate => {
                tags.sort_by(|a, b| {
                    let a_time = a.tagger.as_ref().map(|t| &t.timestamp);
                    let b_time = b.tagger.as_ref().map(|t| &t.timestamp);
                    a_time.cmp(&b_time)
                });
            }
            TagSort::CommitterDate => {
                // For commit dates, we would need to resolve the target commits
                // For now, fall back to name sorting
                tags.sort_by(|a, b| a.name.cmp(&b.name));
            }
        }
    }

    /// Compare version strings for semantic version sorting
    fn compare_versions(&self, a: &str, b: &str) -> std::cmp::Ordering {
        use std::cmp::Ordering;
        
        // Extract numeric parts from version strings
        let extract_version_parts = |s: &str| -> Vec<u32> {
            // Remove common prefixes like 'v' and extract numbers
            let clean = s.strip_prefix('v').unwrap_or(s);
            clean.split('.')
                .filter_map(|part| part.parse::<u32>().ok())
                .collect()
        };

        let a_parts = extract_version_parts(a);
        let b_parts = extract_version_parts(b);

        // Compare version parts
        let max_len = a_parts.len().max(b_parts.len());
        for i in 0..max_len {
            let a_part = a_parts.get(i).unwrap_or(&0);
            let b_part = b_parts.get(i).unwrap_or(&0);
            
            match a_part.cmp(b_part) {
                std::cmp::Ordering::Equal => continue,
                other => return other,
            }
        }

        // If all numeric parts are equal, fall back to string comparison
        a.cmp(b)
    }

    /// Resolve tag identity (author/tagger) from config, profile, and repo config
    fn resolve_tag_identity(&self, config: &TagConfig, profile: &GitConnectionProfile, repo: &Repository) -> Result<Signature, GitError> {
        let name = if let Some(name) = &config.author_name {
            name.clone()
        } else if let Some(name) = &profile.username {
            name.clone()
        } else {
            // Try to get from git config
            self.get_repo_config_string(repo, "user.name")
                .or_else(|| self.get_global_config_string("user.name"))
                .ok_or_else(|| GitError::TagIdentityMissing)?
        };

        let email = if let Some(email) = &config.author_email {
            email.clone()
        } else {
            // Try to get from git config
            self.get_repo_config_string(repo, "user.email")
                .or_else(|| self.get_global_config_string("user.email"))
                .ok_or_else(|| GitError::TagIdentityMissing)?
        };

        let time = if let Some(timestamp) = &config.timestamp {
            match timestamp {
                TagTimestamp::Iso8601(iso_str) => {
                    // Parse ISO8601 timestamp
                    chrono::DateTime::parse_from_rfc3339(iso_str)
                        .map(|dt| Time::new(dt.timestamp(), 0))
                        .map_err(|_| GitError::InvalidTagConfig {
                            message: format!("invalid ISO8601 timestamp: {}", iso_str),
                        })?
                }
                TagTimestamp::UnixSeconds(unix_secs) => {
                    Time::new(*unix_secs as i64, 0)
                }
            }
        } else {
            // Use current time
            let now = std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_secs() as i64;
            Time::new(now, 0)
        };

        Signature::new(&name, &email, &time).map_err(|_| GitError::TagIdentityMissing)
    }

    /// Format git time to ISO8601 string
    fn format_time(&self, time: &Time) -> String {
        let dt = chrono::DateTime::<chrono::Utc>::from_timestamp(time.seconds(), 0)
            .unwrap_or_else(|| chrono::Utc::now());
        dt.to_rfc3339()
    }

    /// Get string value from repository config
    fn get_repo_config_string(&self, repo: &Repository, key: &str) -> Option<String> {
        repo.config().ok()
            .and_then(|config| config.get_string(key).ok())
    }

    /// Get string value from global git config
    fn get_global_config_string(&self, key: &str) -> Option<String> {
        git2::Config::open_default().ok()
            .and_then(|config| config.get_string(key).ok())
    }

    /// Get HEAD tree for diff operations
    fn get_head_tree<'a>(&self, repo: &'a Repository) -> Result<git2::Tree<'a>, GitError> {
        let head = repo.head().map_err(|_| GitError::DiffHeadNotFound)?;
        let commit = head.peel_to_commit().map_err(|_| GitError::DiffHeadNotFound)?;
        commit.tree().map_err(|e| GitError::DiffFailed {
            message: format!("failed to get HEAD tree: {}", e),
        })
    }

    /// Resolve commit-ish string to tree
    fn resolve_commit_tree<'a>(&self, repo: &'a Repository, commit_ish: &str) -> Result<git2::Tree<'a>, GitError> {
        let object = repo.revparse_single(commit_ish).map_err(|_| GitError::DiffRefNotFound {
            reference: commit_ish.to_string(),
        })?;
        
        let commit = object.peel_to_commit().map_err(|_| GitError::DiffRefNotFound {
            reference: commit_ish.to_string(),
        })?;
        
        commit.tree().map_err(|e| GitError::DiffFailed {
            message: format!("failed to get tree for {}: {}", commit_ish, e),
        })
    }

    /// Parse libgit2 diff to JSON structure
    async fn parse_diff_to_json(&self, diff: &git2::Diff<'_>, config: &DiffConfig, max_files: u32, max_hunks: u32) -> Result<Value, GitError> {
        let mut files = Vec::new();
        let mut total_insertions = 0u32;
        let mut total_deletions = 0u32;
        let mut file_count = 0u32;
        let mut hunk_count = 0u32;
        let mut truncated = false;

        // Process each file in the diff
        let num_deltas = diff.deltas().count();
        for (delta_idx, delta) in diff.deltas().enumerate() {
            if file_count >= max_files {
                truncated = true;
                break;
            }

            let old_path = delta.old_file().path().map(|p: &std::path::Path| p.to_string_lossy().to_string());
            let new_path = delta.new_file().path().map(|p: &std::path::Path| p.to_string_lossy().to_string());

            let status = match delta.status() {
                git2::Delta::Added => "added",
                git2::Delta::Deleted => "deleted", 
                git2::Delta::Modified => "modified",
                git2::Delta::Renamed => "renamed",
                git2::Delta::Copied => "copied",
                git2::Delta::Typechange => "typechange",
                _ => "modified", // Default fallback
            };

            let is_binary = delta.old_file().is_binary() || delta.new_file().is_binary();
            
            let mut hunks = Vec::new();
            let mut actual_is_binary = is_binary;

            // Process hunks for non-binary files or if binary is enabled
            if !is_binary || config.binary.unwrap_or(false) {
                let patch = git2::Patch::from_diff(diff, delta_idx).map_err(|e| GitError::DiffFailed {
                    message: format!("failed to create patch: {}", e),
                })?;

                if let Some(patch) = patch {
                    // Check if the patch itself indicates binary content
                    if patch.num_hunks() == 0 && !is_binary {
                        // This might be a binary file that git2 didn't detect as binary
                        // Try to read the file content to check for null bytes
                        if let Some(new_file_path) = new_path.as_ref() {
                            if let Ok(content) = std::fs::read(Path::new(&config.path).join(new_file_path)) {
                                actual_is_binary = content.contains(&0);
                            }
                        } else if let Some(old_file_path) = old_path.as_ref() {
                            if let Ok(content) = std::fs::read(Path::new(&config.path).join(old_file_path)) {
                                actual_is_binary = content.contains(&0);
                            }
                        }
                    }
                    
                    if !actual_is_binary {
                        for hunk_idx in 0..patch.num_hunks() {
                            if hunk_count >= max_hunks {
                                truncated = true;
                                break;
                            }

                            let (hunk, _) = patch.hunk(hunk_idx).map_err(|e| GitError::DiffFailed {
                                message: format!("failed to get hunk: {}", e),
                            })?;

                            let mut lines = Vec::new();
                            let num_lines = patch.num_lines_in_hunk(hunk_idx).map_err(|e| GitError::DiffFailed {
                                message: format!("failed to get hunk line count: {}", e),
                            })?;

                            for line_idx in 0..num_lines {
                                let line = patch.line_in_hunk(hunk_idx, line_idx).map_err(|e| GitError::DiffFailed {
                                    message: format!("failed to get line: {}", e),
                                })?;

                                let line_type = match line.origin() {
                                    '+' => "add",
                                '-' => "delete",
                                ' ' => "context",
                                _ => "context", // Default fallback
                            };

                            // Remove trailing newline from content
                            let content = String::from_utf8_lossy(line.content());
                            let content = content.trim_end_matches('\n').to_string();

                            lines.push(DiffLine {
                                line_type: line_type.to_string(),
                                content,
                            });

                            // Count insertions/deletions
                            match line.origin() {
                                '+' => total_insertions += 1,
                                '-' => total_deletions += 1,
                                _ => {}
                            }
                        }

                        hunks.push(DiffHunk {
                            old_start: hunk.old_start(),
                            old_lines: hunk.old_lines(),
                            new_start: hunk.new_start(),
                            new_lines: hunk.new_lines(),
                            lines,
                        });

                        hunk_count += 1;
                    }
                    }
                }
            }

            files.push(DiffFile {
                old_path,
                new_path,
                status: status.to_string(),
                is_binary: actual_is_binary,
                hunks,
            });

            file_count += 1;
        }

        // Determine from/to strings for result
        let mode = config.mode.as_ref().unwrap_or(&DiffMode::WorkdirVsIndex);
        let (from_str, to_str) = match mode {
            DiffMode::WorkdirVsIndex => ("INDEX".to_string(), "WORKDIR".to_string()),
            DiffMode::IndexVsHead => ("HEAD".to_string(), "INDEX".to_string()),
            DiffMode::HeadVsWorkdir => ("HEAD".to_string(), "WORKDIR".to_string()),
            DiffMode::CommitVsCommit => (
                config.from.clone().unwrap_or_default(),
                config.to.clone().unwrap_or_default(),
            ),
            DiffMode::CommitVsWorkdir => (
                config.from.clone().unwrap_or_default(),
                "WORKDIR".to_string(),
            ),
            DiffMode::CommitVsIndex => (
                config.from.clone().unwrap_or_default(),
                "INDEX".to_string(),
            ),
        };

        let mode_string = match mode {
            DiffMode::WorkdirVsIndex => "workdir_vs_index",
            DiffMode::IndexVsHead => "index_vs_head",
            DiffMode::HeadVsWorkdir => "head_vs_workdir",
            DiffMode::CommitVsCommit => "commit_vs_commit",
            DiffMode::CommitVsWorkdir => "commit_vs_workdir",
            DiffMode::CommitVsIndex => "commit_vs_index",
        };

        let result = DiffResult {
            backend: "git".to_string(),
            alias: self.alias.clone(),
            path: config.path.clone(),
            mode: mode_string.to_string(),
            from: from_str,
            to: to_str,
            summary: DiffSummary {
                files_changed: file_count,
                insertions: total_insertions,
                deletions: total_deletions,
                truncated,
            },
            files,
        };

        Ok(serde_json::to_value(result).unwrap())
    }

    /// Create a new commit
    fn create_new_commit(&self, repo: &Repository, message: &str, author: &Signature, committer: &Signature) -> Result<Oid, GitError> {
        let mut index = repo.index().map_err(|e| GitError::CommitFailed {
            message: format!("failed to get index: {}", e),
        })?;

        let tree_oid = index.write_tree().map_err(|e| GitError::CommitFailed {
            message: format!("failed to write tree: {}", e),
        })?;

        let tree = repo.find_tree(tree_oid).map_err(|e| GitError::CommitFailed {
            message: format!("failed to find tree: {}", e),
        })?;

        // Determine parents
        let parents: Vec<Commit> = match repo.head() {
            Ok(head_ref) => {
                vec![head_ref.peel_to_commit().map_err(|e| GitError::CommitFailed {
                    message: format!("failed to get HEAD commit: {}", e),
                })?]
            }
            Err(_) => vec![], // No parents for initial commit
        };

        let parent_refs: Vec<&Commit> = parents.iter().collect();

        // Create commit
        let commit_oid = repo.commit(
            Some("HEAD"),
            author,
            committer,
            message,
            &tree,
            &parent_refs,
        ).map_err(|e| GitError::CommitFailed {
            message: format!("failed to create commit: {}", e),
        })?;

        Ok(commit_oid)
    }

    /// Amend the existing HEAD commit
    fn amend_commit(&self, repo: &Repository, message: &str, author: &Signature, committer: &Signature) -> Result<Oid, GitError> {
        let mut index = repo.index().map_err(|e| GitError::CommitAmendFailed {
            message: format!("failed to get index: {}", e),
        })?;

        let tree_oid = index.write_tree().map_err(|e| GitError::CommitAmendFailed {
            message: format!("failed to write tree: {}", e),
        })?;

        let tree = repo.find_tree(tree_oid).map_err(|e| GitError::CommitAmendFailed {
            message: format!("failed to find tree: {}", e),
        })?;

        // Get current HEAD commit
        let head_commit = repo.head().and_then(|head_ref| head_ref.peel_to_commit())
            .map_err(|e| GitError::CommitAmendFailed {
                message: format!("failed to get HEAD commit: {}", e),
            })?;

        // Keep the same parents as the original commit
        let parents: Vec<Commit> = head_commit.parents().collect();
        let parent_refs: Vec<&Commit> = parents.iter().collect();

        // Create amended commit
        let commit_oid = repo.commit(
            Some("HEAD"),
            author,
            committer,
            message,
            &tree,
            &parent_refs,
        ).map_err(|e| GitError::CommitAmendFailed {
            message: format!("failed to amend commit: {}", e),
        })?;

        Ok(commit_oid)
    }

    /// Resolve which branches to push based on configuration
    fn resolve_push_branches(&self, repo: &Repository, config: &PushConfig) -> Result<Vec<String>, GitError> {
        if let Some(ref branches) = config.branches {
            // Use provided branches list
            for branch_name in branches {
                // Verify branch exists
                let branch_ref_name = format!("refs/heads/{}", branch_name);
                repo.find_reference(&branch_ref_name).map_err(|_| GitError::PushLocalBranchNotFound {
                    branch: branch_name.clone(),
                })?;
            }
            Ok(branches.clone())
        } else if let Some(ref branch) = config.branch {
            // Use single branch
            let branch_ref_name = format!("refs/heads/{}", branch);
            repo.find_reference(&branch_ref_name).map_err(|_| GitError::PushLocalBranchNotFound {
                branch: branch.clone(),
            })?;
            Ok(vec![branch.clone()])
        } else {
            // Use current branch
            let head = repo.head().map_err(|e| GitError::PushFailed {
                message: format!("failed to get HEAD: {}", e),
            })?;

            if !head.is_branch() {
                return Err(GitError::PushDetachedHead);
            }

            let branch_name = head.shorthand().unwrap_or("main").to_string();
            Ok(vec![branch_name])
        }
    }

    /// List branches operation
    async fn list_branches(&self, repo: &Repository, config: &BranchConfig) -> Result<Value, GitError> {
        use git2::{BranchType, Branch};

        let local_only = config.local_only.unwrap_or(true);
        let remote_only = config.remote_only.unwrap_or(false);
        let all = config.all.unwrap_or(false);

        let mut branches = Vec::new();

        // Determine which branch types to list
        let branch_types = if all {
            vec![BranchType::Local, BranchType::Remote]
        } else if remote_only {
            vec![BranchType::Remote]
        } else {
            vec![BranchType::Local] // local_only is default
        };

        // Get current branch for comparison
        let current_branch_name = match repo.head() {
            Ok(head) if head.is_branch() => head.shorthand().map(|s| s.to_string()),
            _ => None,
        };

        for branch_type in branch_types {
            let branch_iter = repo.branches(Some(branch_type)).map_err(|e| {
                GitError::BranchFailed {
                    message: format!("failed to list branches: {}", e),
                }
            })?;

            for branch_result in branch_iter {
                let (branch, _branch_type) = branch_result.map_err(|e| {
                    GitError::BranchFailed {
                        message: format!("failed to iterate branches: {}", e),
                    }
                })?;

                let branch_info = self.extract_branch_info(&branch, &current_branch_name)?;
                branches.push(branch_info);
            }
        }

        let result = BranchListResult {
            backend: "git".to_string(),
            alias: self.alias.clone(),
            path: config.path.clone(),
            action: "list".to_string(),
            branches,
        };

        log::info!("Successfully listed {} branches", result.branches.len());
        Ok(serde_json::to_value(result).unwrap())
    }

    /// Create branch operation
    async fn create_branch(&self, repo: &Repository, config: &BranchConfig) -> Result<Value, GitError> {
        let name = config.name.as_ref().unwrap();
        let start_point = config.start_point.as_deref().unwrap_or("HEAD");

        // Check if branch already exists
        if repo.find_branch(name, git2::BranchType::Local).is_ok() {
            return Err(GitError::BranchAlreadyExists {
                name: name.clone(),
            });
        }

        // Resolve start point to a commit
        let target_commit = self.resolve_start_point(repo, start_point)?;

        // Create the branch
        let mut branch = repo.branch(name, &target_commit, false).map_err(|e| {
            GitError::BranchFailed {
                message: format!("failed to create branch '{}': {}", name, e),
            }
        })?;

        // Set upstream tracking if requested
        let tracked_remote = if config.track.unwrap_or(false) {
            let remote_name = config.remote.as_deref().unwrap_or("origin");
            match self.set_branch_upstream(&mut branch, remote_name, name) {
                Ok(upstream) => Some(upstream),
                Err(e) => {
                    log::warn!("Failed to set upstream tracking: {}", e);
                    return Err(e);
                }
            }
        } else {
            None
        };

        let branch_data = json!({
            "name": name,
            "start_point": start_point,
            "tracked_remote": tracked_remote
        });

        let result = BranchOpResult {
            backend: "git".to_string(),
            alias: self.alias.clone(),
            path: config.path.clone(),
            action: "create".to_string(),
            status: "created".to_string(),
            branch: branch_data,
        };

        log::info!("Successfully created branch '{}'", name);
        Ok(serde_json::to_value(result).unwrap())
    }

    /// Delete branch operation
    async fn delete_branch(&self, repo: &Repository, config: &BranchConfig) -> Result<Value, GitError> {
        let name = config.name.as_ref().unwrap();

        // Find the branch
        let mut branch = repo.find_branch(name, git2::BranchType::Local).map_err(|_| {
            GitError::BranchNotFound {
                name: name.clone(),
            }
        })?;

        // Check if it's the current branch
        if branch.is_head() && !config.force.unwrap_or(false) {
            return Err(GitError::BranchDeleteCurrent {
                name: name.clone(),
            });
        }

        // Check if branch is merged (simplified check - we could make this more sophisticated)
        if !config.force.unwrap_or(false) {
            // For safety, we skip the unmerged check for now and rely on force flag
            // A full implementation would check if the branch is merged into its upstream or main
        }

        // Delete the branch
        branch.delete().map_err(|e| {
            GitError::BranchDeleteFailed {
                message: format!("failed to delete branch '{}': {}", name, e),
            }
        })?;

        let branch_data = json!({
            "name": name
        });

        let result = BranchOpResult {
            backend: "git".to_string(),
            alias: self.alias.clone(),
            path: config.path.clone(),
            action: "delete".to_string(),
            status: "deleted".to_string(),
            branch: branch_data,
        };

        log::info!("Successfully deleted branch '{}'", name);
        Ok(serde_json::to_value(result).unwrap())
    }

    /// Rename branch operation
    async fn rename_branch(&self, repo: &Repository, config: &BranchConfig) -> Result<Value, GitError> {
        let old_name = config.name.as_ref().unwrap();
        let new_name = config.new_name.as_ref().unwrap();

        // Find the old branch
        let mut branch = repo.find_branch(old_name, git2::BranchType::Local).map_err(|_| {
            GitError::BranchNotFound {
                name: old_name.clone(),
            }
        })?;

        // Check if target name already exists
        if !config.force.unwrap_or(false) && repo.find_branch(new_name, git2::BranchType::Local).is_ok() {
            return Err(GitError::BranchAlreadyExists {
                name: new_name.clone(),
            });
        }

        // Rename the branch
        branch.rename(new_name, config.force.unwrap_or(false)).map_err(|e| {
            GitError::BranchRenameFailed {
                message: format!("failed to rename branch '{}' to '{}': {}", old_name, new_name, e),
            }
        })?;

        let branch_data = json!({
            "old_name": old_name,
            "new_name": new_name
        });

        let result = BranchOpResult {
            backend: "git".to_string(),
            alias: self.alias.clone(),
            path: config.path.clone(),
            action: "rename".to_string(),
            status: "renamed".to_string(),
            branch: branch_data,
        };

        log::info!("Successfully renamed branch '{}' to '{}'", old_name, new_name);
        Ok(serde_json::to_value(result).unwrap())
    }

    /// Checkout branch operation
    async fn checkout_branch(&self, repo: &Repository, config: &BranchConfig) -> Result<Value, GitError> {
        let name = config.name.as_ref().unwrap();

        // Find the branch
        let branch = repo.find_branch(name, git2::BranchType::Local).map_err(|_| {
            GitError::BranchNotFound {
                name: name.clone(),
            }
        })?;

        // Check if already current
        let was_current = branch.is_head();

        if !was_current {
            // Check working directory status if force is not set
            if !config.force.unwrap_or(false) {
                let statuses = repo.statuses(None).map_err(|e| {
                    GitError::BranchCheckoutFailed {
                        message: format!("failed to check repository status: {}", e),
                    }
                })?;

                // Check for uncommitted changes that would conflict
                let has_changes = statuses.iter().any(|entry| {
                    let flags = entry.status();
                    flags.is_wt_modified() || flags.is_wt_deleted() || flags.is_wt_new()
                });

                if has_changes {
                    return Err(GitError::BranchCheckoutConflict);
                }
            }

            // Get the branch reference
            let branch_ref = branch.get();
            
            // Set HEAD to point to the branch
            repo.set_head(branch_ref.name().unwrap()).map_err(|e| {
                GitError::BranchCheckoutFailed {
                    message: format!("failed to set HEAD: {}", e),
                }
            })?;

            // Update working directory
            let mut checkout_opts = git2::build::CheckoutBuilder::default();
            if config.force.unwrap_or(false) {
                checkout_opts.force();
            }
            
            repo.checkout_head(Some(&mut checkout_opts)).map_err(|e| {
                GitError::BranchCheckoutFailed {
                    message: format!("failed to checkout working directory: {}", e),
                }
            })?;
        }

        let branch_data = json!({
            "name": name,
            "was_current": was_current
        });

        let result = BranchOpResult {
            backend: "git".to_string(),
            alias: self.alias.clone(),
            path: config.path.clone(),
            action: "checkout".to_string(),
            status: "checked_out".to_string(),
            branch: branch_data,
        };

        log::info!("Successfully checked out branch '{}'", name);
        Ok(serde_json::to_value(result).unwrap())
    }

    /// Extract branch information for list operation
    fn extract_branch_info(&self, branch: &git2::Branch, current_branch_name: &Option<String>) -> Result<BranchListEntry, GitError> {
        let branch_ref = branch.get();
        let name = branch.name().map_err(|e| {
            GitError::BranchFailed {
                message: format!("failed to get branch name: {}", e),
            }
        })?.unwrap_or("").to_string();

        let full_ref = branch_ref.name().unwrap_or("").to_string();
        let is_remote = branch_ref.is_remote();
        let is_current = if let Some(current) = current_branch_name {
            &name == current
        } else {
            false
        };

        // Get commit SHA
        let head = branch_ref.target().map(|oid| oid.to_string()).unwrap_or_else(|| "".to_string());

        // Get upstream information for local branches
        let upstream = if !is_remote {
            match branch.upstream() {
                Ok(upstream_branch) => {
                    let upstream_ref = upstream_branch.get();
                    let upstream_name = upstream_branch.name().unwrap_or(None).unwrap_or("").to_string();
                    let upstream_full_ref = upstream_ref.name().unwrap_or("").to_string();
                    
                    // Extract remote name from upstream reference
                    let remote_name = if upstream_full_ref.starts_with("refs/remotes/") {
                        upstream_full_ref.strip_prefix("refs/remotes/")
                            .and_then(|s| s.split('/').next())
                            .unwrap_or("origin")
                            .to_string()
                    } else {
                        "origin".to_string()
                    };

                    Some(BranchUpstreamInfo {
                        remote: remote_name,
                        name: upstream_name,
                        full_ref: upstream_full_ref,
                    })
                }
                Err(_) => None,
            }
        } else {
            None
        };

        Ok(BranchListEntry {
            name,
            full_ref,
            is_remote,
            is_current,
            upstream,
            head,
        })
    }

    /// Resolve start point to a commit
    fn resolve_start_point<'a>(&self, repo: &'a Repository, start_point: &str) -> Result<git2::Commit<'a>, GitError> {
        // Try to resolve as reference, tag, or commit SHA
        let obj = repo.revparse_single(start_point).map_err(|_| {
            GitError::BranchStartpointNotFound {
                start_point: start_point.to_string(),
            }
        })?;

        // Convert to commit
        let commit = obj.peel_to_commit().map_err(|_| {
            GitError::BranchStartpointNotFound {
                start_point: start_point.to_string(),
            }
        })?;

        Ok(commit)
    }

    /// Set upstream tracking for a branch
    fn set_branch_upstream(&self, branch: &mut git2::Branch, remote_name: &str, branch_name: &str) -> Result<String, GitError> {
        let upstream_ref = format!("refs/remotes/{}/{}", remote_name, branch_name);
        
        // Set upstream reference
        branch.set_upstream(Some(&upstream_ref)).map_err(|e| {
            GitError::BranchSetUpstreamFailed {
                message: format!("failed to set upstream '{}': {}", upstream_ref, e),
            }
        })?;

        Ok(format!("{}/{}", remote_name, branch_name))
    }

    /// Compute ahead/behind counts for a local branch against its remote tracking branch
    fn compute_ahead_behind(&self, repo: &Repository, branch_name: &str, remote_name: &str) -> Result<(usize, usize), GitError> {
        let local_ref_name = format!("refs/heads/{}", branch_name);
        let remote_ref_name = format!("refs/remotes/{}/{}", remote_name, branch_name);

        let local_ref = repo.find_reference(&local_ref_name).map_err(|_| GitError::PushLocalBranchNotFound {
            branch: branch_name.to_string(),
        })?;

        let local_oid = local_ref.target().ok_or_else(|| GitError::PushFailed {
            message: "local reference has no target".to_string(),
        })?;

        // Try to find remote tracking branch
        let remote_oid = match repo.find_reference(&remote_ref_name) {
            Ok(remote_ref) => remote_ref.target().ok_or_else(|| GitError::PushFailed {
                message: "remote reference has no target".to_string(),
            })?,
            Err(_) => {
                // Remote tracking branch doesn't exist - this is ok for first push
                // Return 1 ahead (local has commits), 0 behind
                return Ok((1, 0));
            }
        };

        // Compute ahead/behind counts
        let (ahead, behind) = repo.graph_ahead_behind(local_oid, remote_oid).map_err(|e| GitError::PushFailed {
            message: format!("failed to compute ahead/behind: {}", e),
        })?;

        Ok((ahead, behind))
    }

    /// Setup authentication callbacks for push operations
    fn setup_push_authentication_callbacks(
        &self,
        callbacks: &mut RemoteCallbacks,
        config: &PushConfig,
        profile: &GitConnectionProfile,
    ) -> Result<(), GitError> {
        // Clone all auth values for the closure
        let ssh_key_clone = config.ssh_key.clone().or_else(|| 
            profile.ssh_key_path.as_ref().map(|p| p.to_string_lossy().to_string())
        );
        let username_clone = config.username.clone().or_else(|| profile.username.clone());
        let password_clone = config.password.clone().or_else(|| profile.password.clone());
        let token_clone = config.token.clone().or_else(|| profile.token.clone());

        callbacks.credentials(move |_url, username_from_url, allowed_types| {
            log::debug!("Git authentication requested for push, allowed_types: {:?}", allowed_types);

            if allowed_types.contains(CredentialType::SSH_KEY) {
                if let Some(ref key_path) = ssh_key_clone {
                    let username = username_from_url.unwrap_or("git");
                    return git2::Cred::ssh_key(
                        username,
                        None, // public key path - let git2 figure it out
                        Path::new(key_path),
                        None, // passphrase
                    );
                }
            }

            if allowed_types.contains(CredentialType::USER_PASS_PLAINTEXT) {
                if let (Some(user), Some(pass)) = (&username_clone, &password_clone) {
                    return git2::Cred::userpass_plaintext(user, pass);
                }
                if let Some(ref token) = token_clone {
                    // Use token as password with empty username for HTTPS
                    return git2::Cred::userpass_plaintext("", token);
                }
            }

            if allowed_types.contains(CredentialType::DEFAULT) {
                return git2::Cred::default();
            }

            Err(git2::Error::from_str("no authentication method available"))
        });

        Ok(())
    }

    /// Set upstream configuration for branches
    fn set_upstream_branches(&self, repo: &Repository, branches: &[String], remote_name: &str) -> Result<(), GitError> {
        for branch_name in branches {
            // This is a simplified implementation - in a real implementation you'd use
            // git2's config API to set branch.<name>.remote and branch.<name>.merge
            log::debug!("Setting upstream for branch '{}' to '{}/{}'", branch_name, remote_name, branch_name);
            
            // For now, just log - proper implementation would use:
            // let mut config = repo.config()?;
            // config.set_str(&format!("branch.{}.remote", branch_name), remote_name)?;
            // config.set_str(&format!("branch.{}.merge", branch_name), &format!("refs/heads/{}", branch_name))?;
        }
        Ok(())
    }

    /// Get branch information for status operation
    fn get_branch_info(&self, repo: &Repository, include_remote: bool) -> Result<BranchInfo, GitError> {
        let head = repo.head().map_err(|e| GitError::StatusFailed {
            message: format!("failed to get HEAD: {}", e),
        })?;

        let (name, detached) = if head.is_branch() {
            let name = head.shorthand().map(|s| s.to_string());
            (name, false)
        } else {
            (None, true)
        };

        let head_oid = head.target().ok_or_else(|| GitError::StatusFailed {
            message: "HEAD has no target".to_string(),
        })?;

        let upstream = if include_remote && !detached {
            if let Some(branch_name) = &name {
                self.get_upstream_info(repo, branch_name)?
            } else {
                None
            }
        } else {
            None
        };

        Ok(BranchInfo {
            name,
            detached,
            head: head_oid.to_string(),
            upstream,
        })
    }

    /// Get upstream information for a branch
    fn get_upstream_info(&self, repo: &Repository, branch_name: &str) -> Result<Option<UpstreamInfo>, GitError> {
        let local_branch = match repo.find_branch(branch_name, git2::BranchType::Local) {
            Ok(branch) => branch,
            Err(_) => return Ok(None),
        };

        let upstream_branch = match local_branch.upstream() {
            Ok(branch) => branch,
            Err(_) => return Ok(None),
        };

        let upstream_name = upstream_branch.name().map_err(|e| GitError::StatusFailed {
            message: format!("failed to get upstream branch name: {}", e),
        })?.unwrap_or("unknown");

        // Extract remote name from upstream reference
        let remote_name = if let Some(upstream_ref) = upstream_branch.get().name() {
            if upstream_ref.starts_with("refs/remotes/") {
                let parts: Vec<&str> = upstream_ref["refs/remotes/".len()..].splitn(2, '/').collect();
                if parts.len() == 2 {
                    parts[0].to_string()
                } else {
                    "origin".to_string()
                }
            } else {
                "origin".to_string()
            }
        } else {
            "origin".to_string()
        };

        // Calculate ahead/behind counts
        let (ahead_by, behind_by) = if let (Ok(local_oid), Ok(upstream_oid)) = (
            local_branch.get().target().ok_or("no local target"),
            upstream_branch.get().target().ok_or("no upstream target")
        ) {
            repo.graph_ahead_behind(local_oid, upstream_oid)
                .map_err(|e| GitError::StatusFailed {
                    message: format!("failed to calculate ahead/behind counts: {}", e),
                })?
        } else {
            (0, 0)
        };

        Ok(Some(UpstreamInfo {
            name: upstream_name.to_string(),
            remote: remote_name,
            ahead_by,
            behind_by,
        }))
    }

    /// Get working tree status for status operation
    fn get_working_tree_status(&self, repo: &Repository, config: &StatusConfig) -> Result<WorkingTreeStatus, GitError> {
        let mut opts = git2::StatusOptions::new();
        
        if config.include_untracked.unwrap_or(true) {
            opts.include_untracked(true);
        }
        
        if config.include_ignored.unwrap_or(false) {
            opts.include_ignored(true);
        }

        let statuses = repo.statuses(Some(&mut opts)).map_err(|e| GitError::StatusFailed {
            message: format!("failed to get repository status: {}", e),
        })?;

        let mut staged = Vec::new();
        let mut unstaged = Vec::new();
        let mut untracked = Vec::new();
        let mut ignored = Vec::new();
        let mut conflicts = Vec::new();

        for entry in statuses.iter() {
            let path = entry.path().unwrap_or("unknown").to_string();
            let status_flags = entry.status();

            if status_flags.contains(git2::Status::CONFLICTED) {
                conflicts.push(FileStatus {
                    path: path.clone(),
                    status: "conflicted".to_string(),
                });
            }

            if config.include_staged.unwrap_or(true) {
                if status_flags.intersects(git2::Status::INDEX_NEW | git2::Status::INDEX_MODIFIED | 
                                           git2::Status::INDEX_DELETED | git2::Status::INDEX_RENAMED | 
                                           git2::Status::INDEX_TYPECHANGE) {
                    let status_name = if status_flags.contains(git2::Status::INDEX_NEW) {
                        "added"
                    } else if status_flags.contains(git2::Status::INDEX_MODIFIED) {
                        "modified"
                    } else if status_flags.contains(git2::Status::INDEX_DELETED) {
                        "deleted"
                    } else if status_flags.contains(git2::Status::INDEX_RENAMED) {
                        "renamed"
                    } else if status_flags.contains(git2::Status::INDEX_TYPECHANGE) {
                        "typechange"
                    } else {
                        "unknown"
                    };

                    staged.push(FileStatus {
                        path: path.clone(),
                        status: status_name.to_string(),
                    });
                }
            }

            if status_flags.intersects(git2::Status::WT_MODIFIED | git2::Status::WT_DELETED | 
                                       git2::Status::WT_TYPECHANGE | git2::Status::WT_RENAMED) {
                let status_name = if status_flags.contains(git2::Status::WT_MODIFIED) {
                    "modified"
                } else if status_flags.contains(git2::Status::WT_DELETED) {
                    "deleted"
                } else if status_flags.contains(git2::Status::WT_RENAMED) {
                    "renamed"
                } else if status_flags.contains(git2::Status::WT_TYPECHANGE) {
                    "typechange"
                } else {
                    "unknown"
                };

                unstaged.push(FileStatus {
                    path: path.clone(),
                    status: status_name.to_string(),
                });
            }

            if config.include_untracked.unwrap_or(true) && status_flags.contains(git2::Status::WT_NEW) {
                untracked.push(FileStatus {
                    path: path.clone(),
                    status: "untracked".to_string(),
                });
            }

            if config.include_ignored.unwrap_or(false) && status_flags.contains(git2::Status::IGNORED) {
                ignored.push(FileStatus {
                    path: path.clone(),
                    status: "ignored".to_string(),
                });
            }
        }

        let clean = staged.is_empty() && unstaged.is_empty() && untracked.is_empty() && conflicts.is_empty();

        Ok(WorkingTreeStatus {
            clean,
            staged,
            unstaged,
            untracked,
            ignored,
            conflicts,
        })
    }

    /// Get in-progress operation flags for status operation
    fn get_in_progress_flags(&self, repo: &Repository) -> Result<InProgressFlags, GitError> {
        let git_dir = repo.path();

        let merge = git_dir.join("MERGE_HEAD").exists();
        let cherry_pick = git_dir.join("CHERRY_PICK_HEAD").exists();
        let revert = git_dir.join("REVERT_HEAD").exists();
        let bisect = git_dir.join("BISECT_LOG").exists();
        
        // Check for rebase (multiple possible locations)
        let rebase = git_dir.join("rebase-apply").exists() || 
                     git_dir.join("rebase-merge").exists();

        Ok(InProgressFlags {
            merge,
            rebase,
            cherry_pick,
            revert,
            bisect,
        })
    }

    /// Register a git connection profile
    pub fn register_connection(alias: String, profile: GitConnectionProfile) {
        GIT_CONNECTIONS.insert(alias, profile);
    }

    /// Execute merge operation
    async fn execute_merge(&self, config: &MergeConfig, profile: &GitConnectionProfile) -> Result<Value, GitError> {
        let path = Path::new(&config.path);

        // Open the repository
        let repo = Repository::open(path).map_err(|e| {
            if e.code() == git2::ErrorCode::NotFound {
                GitError::RepositoryNotFound {
                    path: config.path.clone(),
                }
            } else {
                GitError::MergeFailed {
                    message: format!("failed to open repository: {}", e),
                }
            }
        })?;

        // Save current HEAD OID for potential abort
        let head_ref = repo.head().map_err(|e| {
            if e.code() == git2::ErrorCode::UnbornBranch {
                GitError::MergeFailed {
                    message: "repository has no commits".to_string(),
                }
            } else {
                GitError::MergeFailed {
                    message: format!("failed to get HEAD: {}", e),
                }
            }
        })?;

        let head_commit_oid = head_ref.target().ok_or_else(|| GitError::MergeFailed {
            message: "HEAD is not a direct reference".to_string(),
        })?;

        // Resolve target branch
        let (target_branch_name, _target_commit) = self.resolve_target_branch(&repo, config)?;

        // Check for dirty working tree if required
        if !config.allow_uncommitted.unwrap_or(false) {
            self.check_working_tree_clean(&repo)?;
        }

        // Resolve source commit
        let source_commit = self.resolve_source_commit(&repo, config)?;

        // Create annotated commit for merge analysis
        let source_annotated = repo.find_annotated_commit(source_commit.id()).map_err(|e| {
            GitError::MergeFailed {
                message: format!("failed to create annotated commit: {}", e),
            }
        })?;

        // Perform merge analysis
        let merge_analysis = repo.merge_analysis(&[&source_annotated]).map_err(|e| {
            GitError::MergeFailed {
                message: format!("merge analysis failed: {}", e),
            }
        })?;

        let ff_only = config.ff_only.unwrap_or(false);
        let no_ff = config.no_ff.unwrap_or(false);
        let squash = config.squash.unwrap_or(false);
        let abort_on_conflict = config.abort_on_conflict.unwrap_or(true);

        // Handle different merge scenarios
        if merge_analysis.0.is_up_to_date() {
            // Already up to date
            return Ok(json!({
                "backend": "git",
                "alias": self.alias,
                "path": config.path,
                "action": "merge",
                "source": config.source,
                "target": target_branch_name,
                "mode": "up_to_date",
                "status": "up_to_date",
                "ff_only": ff_only,
                "no_ff": no_ff,
                "squash": squash,
                "commit": null
            }));
        } else if merge_analysis.0.is_fast_forward() && !no_ff && !squash {
            // Fast-forward merge
            return self.perform_fast_forward_merge(&repo, &source_commit, config, &target_branch_name).await;
        } else if merge_analysis.0.is_normal() || no_ff {
            // Normal merge or forced non-fast-forward
            if ff_only {
                return Err(GitError::MergeNonFastForward);
            }

            if squash {
                return self.perform_squash_merge(&repo, &source_commit, config, profile, &target_branch_name).await;
            } else {
                return self.perform_normal_merge(&repo, &source_commit, config, profile, &target_branch_name, head_commit_oid, abort_on_conflict).await;
            }
        } else {
            return Err(GitError::MergeFailed {
                message: "unsupported merge analysis result".to_string(),
            });
        }
    }

    /// Execute rebase operation
    async fn execute_rebase(&self, config: &RebaseConfig, profile: &GitConnectionProfile) -> Result<Value, GitError> {
        let path = Path::new(&config.path);
        
        // Open the repository
        let repo = Repository::open(path).map_err(|e| {
            if e.code() == git2::ErrorCode::NotFound {
                GitError::RepositoryNotFound {
                    path: config.path.clone(),
                }
            } else {
                GitError::RebaseFailed {
                    message: format!("failed to open repository: {}", e),
                }
            }
        })?;

        let operation = config.operation.as_ref().unwrap_or(&RebaseOperation::Start);

        // Check for existing rebase state
        let rebase_in_progress = self.is_rebase_in_progress(&repo)?;

        match operation {
            RebaseOperation::Start => {
                if rebase_in_progress {
                    return Err(GitError::RebaseInProgress);
                }
                self.execute_rebase_start(&repo, config, profile).await
            }
            RebaseOperation::Continue => {
                if !rebase_in_progress {
                    return Err(GitError::RebaseNotInProgress);
                }
                self.execute_rebase_continue(&repo, config, profile).await
            }
            RebaseOperation::Abort => {
                if !rebase_in_progress {
                    return Err(GitError::RebaseNotInProgress);
                }
                self.execute_rebase_abort(&repo, config).await
            }
        }
    }

    /// Check if a rebase operation is currently in progress
    fn is_rebase_in_progress(&self, repo: &Repository) -> Result<bool, GitError> {
        let git_dir = repo.path();
        
        // Check for rebase-apply directory (used by git am and git rebase)
        let rebase_apply = git_dir.join("rebase-apply");
        if rebase_apply.exists() {
            log::debug!("Found rebase-apply directory, rebase in progress");
            return Ok(true);
        }
        
        // Check for rebase-merge directory (used by interactive rebase)
        let rebase_merge = git_dir.join("rebase-merge");
        if rebase_merge.exists() {
            log::debug!("Found rebase-merge directory, rebase in progress");
            return Ok(true);
        }
        
        // Also check repository state
        let repo_state = repo.state();
        match repo_state {
            git2::RepositoryState::Rebase | 
            git2::RepositoryState::RebaseInteractive | 
            git2::RepositoryState::RebaseMerge => {
                log::debug!("Repository state indicates rebase in progress: {:?}", repo_state);
                Ok(true)
            }
            _ => Ok(false)
        }
    }

    /// Execute rebase start operation
    async fn execute_rebase_start(&self, repo: &Repository, config: &RebaseConfig, profile: &GitConnectionProfile) -> Result<Value, GitError> {
        // Handle advanced features with warnings
        if config.preserve_merges.unwrap_or(false) {
            log::warn!("preserve_merges option requested but not supported by git2 library, proceeding with standard rebase");
        }
        
        if config.autosquash.unwrap_or(false) {
            log::warn!("autosquash option requested but not supported by git2 library, proceeding with standard rebase");
        }

        // Resolve branch (source) and upstream
        let (branch_name, branch_commit) = self.resolve_rebase_branch(repo, config)?;
        let upstream_commit = self.resolve_rebase_upstream(repo, config)?;

        // Check for clean working tree if required
        if !config.allow_uncommitted.unwrap_or(false) {
            self.check_working_tree_clean(repo)?;
        }

        // Check for fast-forward scenario
        if config.ff_only.unwrap_or(false) {
            return self.handle_fast_forward_rebase(repo, &branch_commit, &upstream_commit, config, &branch_name);
        }

        // Start the actual rebase operation
        let abort_on_conflict = config.abort_on_conflict.unwrap_or(true);
        
        // Use git2 rebase API
        let branch_annotated = repo.find_annotated_commit(branch_commit.id()).map_err(|e| {
            GitError::RebaseFailed {
                message: format!("failed to create annotated commit for branch: {}", e),
            }
        })?;

        let upstream_annotated = repo.find_annotated_commit(upstream_commit.id()).map_err(|e| {
            GitError::RebaseFailed {
                message: format!("failed to create annotated commit for upstream: {}", e),
            }
        })?;

        // Initialize rebase
        let mut rebase = repo.rebase(
            Some(&branch_annotated),
            Some(&upstream_annotated), 
            None, // onto (same as upstream)
            None  // options
        ).map_err(|e| {
            GitError::RebaseFailed {
                message: format!("failed to start rebase: {}", e),
            }
        })?;

        let mut commits_rebased = 0;
        let old_base = branch_commit.id().to_string();

        // Process each rebase operation
        loop {
            match rebase.next() {
                Some(Ok(op)) => {
                    log::debug!("Processing rebase operation for commit: {:?}", op.id());
                    
                    // Apply the operation to the working tree and index
                    // The git2 library handles this automatically when we call next()
                    
                    // Check if there are any conflicts after applying the operation
                    let index = repo.index().map_err(|e| {
                        GitError::RebaseFailed {
                            message: format!("failed to get repository index: {}", e),
                        }
                    })?;
                    
                    if index.has_conflicts() {
                        log::warn!("Conflicts detected during rebase operation");
                        if abort_on_conflict {
                            // Abort the rebase
                            rebase.abort().map_err(|e| {
                                GitError::RebaseFailed {
                                    message: format!("failed to abort rebase: {}", e),
                                }
                            })?;
                            return Err(GitError::RebaseConflict);
                        } else {
                            // Leave in conflicted state for manual resolution
                            return Err(GitError::RebaseConflict);
                        }
                    }
                    
                    // Commit the rebased changes
                    let committer_sig = self.resolve_rebase_committer_signature(config, profile)?;
                    rebase.commit(None, &committer_sig, None).map_err(|e| {
                        GitError::RebaseFailed {
                            message: format!("failed to commit during rebase: {}", e),
                        }
                    })?;
                    
                    commits_rebased += 1;
                }
                Some(Err(e)) => {
                    return Err(GitError::RebaseFailed {
                        message: format!("rebase operation failed: {}", e),
                    });
                }
                None => {
                    // No more operations, rebase is complete
                    break;
                }
            }
        }

        // Finish the rebase
        let committer_sig = self.resolve_rebase_committer_signature(config, profile)?;
        rebase.finish(Some(&committer_sig)).map_err(|e| {
            GitError::RebaseFailed {
                message: format!("failed to finish rebase: {}", e),
            }
        })?;

        // Get new HEAD
        let new_head = repo.head().map_err(|e| {
            GitError::RebaseFailed {
                message: format!("failed to get new HEAD after rebase: {}", e),
            }
        })?;
        let new_base = new_head.target().unwrap().to_string();

        Ok(json!({
            "backend": "git",
            "alias": self.alias,
            "path": config.path,
            "action": "rebase",
            "operation": "start",
            "branch": branch_name,
            "upstream": config.upstream.as_ref().unwrap(),
            "status": "rebased",
            "mode": "normal",
            "ff_only": config.ff_only.unwrap_or(false),
            "preserve_merges": config.preserve_merges.unwrap_or(false),
            "autosquash": config.autosquash.unwrap_or(false),
            "summary": {
                "commits_rebased": commits_rebased,
                "old_base": old_base,
                "new_base": new_base
            }
        }))
    }

    /// Execute rebase continue operation
    async fn execute_rebase_continue(&self, repo: &Repository, config: &RebaseConfig, profile: &GitConnectionProfile) -> Result<Value, GitError> {
        let abort_on_conflict = config.abort_on_conflict.unwrap_or(true);
        let committer_sig = self.resolve_rebase_committer_signature(config, profile)?;
        
        // Open the existing rebase - git2 can resume from rebase state files
        let mut rebase = repo.rebase(
            None, // branch - will be read from state
            None, // upstream - will be read from state  
            None, // onto - will be read from state
            None  // options
        ).map_err(|e| {
            GitError::RebaseFailed {
                message: format!("failed to open existing rebase: {}", e),
            }
        })?;

        let mut commits_rebased = 0;

        // Continue processing rebase operations from where we left off
        loop {
            match rebase.next() {
                Some(Ok(op)) => {
                    log::debug!("Continuing rebase operation for commit: {:?}", op.id());
                    
                    // Check if there are any conflicts after applying the operation
                    let index = repo.index().map_err(|e| {
                        GitError::RebaseFailed {
                            message: format!("failed to get repository index: {}", e),
                        }
                    })?;
                    
                    if index.has_conflicts() {
                        log::warn!("Conflicts detected during rebase continue");
                        if abort_on_conflict {
                            // Abort the rebase
                            rebase.abort().map_err(|e| {
                                GitError::RebaseFailed {
                                    message: format!("failed to abort rebase: {}", e),
                                }
                            })?;
                            return Err(GitError::RebaseConflict);
                        } else {
                            // Leave in conflicted state for manual resolution
                            return Err(GitError::RebaseConflict);
                        }
                    }
                    
                    // Commit the rebased changes
                    rebase.commit(None, &committer_sig, None).map_err(|e| {
                        GitError::RebaseFailed {
                            message: format!("failed to commit during rebase continue: {}", e),
                        }
                    })?;
                    
                    commits_rebased += 1;
                }
                Some(Err(e)) => {
                    return Err(GitError::RebaseFailed {
                        message: format!("rebase continue operation failed: {}", e),
                    });
                }
                None => {
                    // No more operations, rebase is complete
                    break;
                }
            }
        }
        
        // Finish the rebase
        rebase.finish(Some(&committer_sig)).map_err(|e| {
            GitError::RebaseFailed {
                message: format!("failed to finish rebase: {}", e),
            }
        })?;

        Ok(json!({
            "backend": "git",
            "alias": self.alias,
            "path": config.path,
            "action": "rebase",
            "operation": "continue",
            "status": "rebased",
            "summary": {
                "commits_rebased": commits_rebased
            }
        }))
    }

    /// Execute rebase abort operation  
    async fn execute_rebase_abort(&self, repo: &Repository, config: &RebaseConfig) -> Result<Value, GitError> {
        // Open the existing rebase to access its state
        let mut rebase = repo.rebase(
            None, // branch - will be read from state
            None, // upstream - will be read from state  
            None, // onto - will be read from state
            None  // options
        ).map_err(|e| {
            GitError::RebaseFailed {
                message: format!("failed to open existing rebase for abort: {}", e),
            }
        })?;

        // Abort the rebase - this restores the repository to its pre-rebase state
        rebase.abort().map_err(|e| {
            GitError::RebaseFailed {
                message: format!("failed to abort rebase: {}", e),
            }
        })?;

        log::info!("Rebase aborted, repository restored to original state");

        Ok(json!({
            "backend": "git",
            "alias": self.alias,
            "path": config.path,
            "action": "rebase",
            "operation": "abort",
            "status": "aborted"
        }))
    }

    /// Resolve the branch to be rebased
    fn resolve_rebase_branch<'a>(&self, repo: &'a Repository, config: &RebaseConfig) -> Result<(String, Commit<'a>), GitError> {
        if let Some(ref branch_name) = config.branch {
            // Use specified branch
            let branch = repo.find_branch(branch_name, BranchType::Local).map_err(|_| {
                GitError::RebaseBranchNotFound {
                    branch: branch_name.clone(),
                }
            })?;
            
            let commit = branch.get().peel_to_commit().map_err(|e| {
                GitError::RebaseFailed {
                    message: format!("failed to get commit from branch '{}': {}", branch_name, e),
                }
            })?;

            Ok((branch_name.clone(), commit))
        } else {
            // Use current HEAD
            let head_ref = repo.head().map_err(|e| {
                if e.code() == git2::ErrorCode::UnbornBranch {
                    GitError::RebaseFailed {
                        message: "repository has no commits".to_string(),
                    }
                } else {
                    GitError::RebaseFailed {
                        message: format!("failed to get HEAD: {}", e),
                    }
                }
            })?;

            if head_ref.is_branch() {
                let branch_name = head_ref.shorthand().unwrap_or("HEAD").to_string();
                let commit = head_ref.peel_to_commit().map_err(|e| {
                    GitError::RebaseFailed {
                        message: format!("failed to get commit from HEAD: {}", e),
                    }
                })?;
                Ok((branch_name, commit))
            } else {
                Err(GitError::RebaseDetachedHead)
            }
        }
    }

    /// Resolve the upstream commit for rebase
    fn resolve_rebase_upstream<'a>(&self, repo: &'a Repository, config: &RebaseConfig) -> Result<Commit<'a>, GitError> {
        let upstream_spec = config.upstream.as_ref().unwrap(); // Should be validated already

        let upstream_obj = repo.revparse_single(upstream_spec).map_err(|_| {
            GitError::RebaseUpstreamNotFound {
                upstream: upstream_spec.clone(),
            }
        })?;

        let upstream_commit = upstream_obj.peel_to_commit().map_err(|_| {
            GitError::RebaseUpstreamNotCommit {
                upstream: upstream_spec.clone(),
            }
        })?;

        Ok(upstream_commit)
    }

    /// Handle fast-forward only rebase
    fn handle_fast_forward_rebase(&self, repo: &Repository, branch_commit: &Commit, upstream_commit: &Commit, config: &RebaseConfig, branch_name: &str) -> Result<Value, GitError> {
        // Check if branch can be fast-forwarded to upstream
        let upstream_annotated = repo.find_annotated_commit(upstream_commit.id()).map_err(|e| {
            GitError::RebaseFailed {
                message: format!("failed to create annotated commit for merge analysis: {}", e),
            }
        })?;

        let merge_analysis = repo.merge_analysis(&[&upstream_annotated]).map_err(|e| {
            GitError::RebaseFailed {
                message: format!("merge analysis failed: {}", e),
            }
        })?;

        if merge_analysis.0.is_up_to_date() {
            Ok(json!({
                "backend": "git",
                "alias": self.alias,
                "path": config.path,
                "action": "rebase",
                "operation": "start",
                "branch": branch_name,
                "upstream": config.upstream.as_ref().unwrap(),
                "status": "rebased",
                "mode": "up_to_date",
                "ff_only": true,
                "preserve_merges": config.preserve_merges.unwrap_or(false),
                "autosquash": config.autosquash.unwrap_or(false),
                "summary": {
                    "commits_rebased": 0,
                    "old_base": branch_commit.id().to_string(),
                    "new_base": branch_commit.id().to_string()
                }
            }))
        } else if merge_analysis.0.is_fast_forward() {
            // Perform fast-forward
            let mut reference = repo.head().map_err(|e| {
                GitError::RebaseFailed {
                    message: format!("failed to get HEAD reference: {}", e),
                }
            })?;

            reference.set_target(upstream_commit.id(), "Fast-forward rebase").map_err(|e| {
                GitError::RebaseFailed {
                    message: format!("failed to fast-forward HEAD: {}", e),
                }
            })?;

            // Update working directory
            repo.checkout_head(Some(
                git2::build::CheckoutBuilder::new()
                    .force()
            )).map_err(|e| {
                GitError::RebaseFailed {
                    message: format!("failed to checkout after fast-forward: {}", e),
                }
            })?;

            Ok(json!({
                "backend": "git",
                "alias": self.alias,
                "path": config.path,
                "action": "rebase",
                "operation": "start",
                "branch": branch_name,
                "upstream": config.upstream.as_ref().unwrap(),
                "status": "rebased",
                "mode": "fast_forward",
                "ff_only": true,
                "preserve_merges": config.preserve_merges.unwrap_or(false),
                "autosquash": config.autosquash.unwrap_or(false),
                "summary": {
                    "commits_rebased": 0,
                    "old_base": branch_commit.id().to_string(),
                    "new_base": upstream_commit.id().to_string()
                }
            }))
        } else {
            Err(GitError::RebaseNonFastForward)
        }
    }

    /// Resolve committer signature for rebase operations
    fn resolve_rebase_committer_signature(&self, config: &RebaseConfig, profile: &GitConnectionProfile) -> Result<Signature, GitError> {
        // Get environment variables for fallback identity
        let git_committer_name = std::env::var("GIT_COMMITTER_NAME").ok();
        let git_committer_email = std::env::var("GIT_COMMITTER_EMAIL").ok();
        let user_name = std::env::var("USER").ok();
        let user_email = std::env::var("EMAIL").ok();

        // Resolve committer identity
        let committer_name = config.committer_name.as_ref()
            .or(profile.username.as_ref())
            .or(git_committer_name.as_ref())
            .or(user_name.as_ref())
            .ok_or(GitError::RebaseIdentityMissing)?;

        let committer_email = config.committer_email.as_ref()
            .or(git_committer_email.as_ref())
            .or(user_email.as_ref())
            .ok_or(GitError::RebaseIdentityMissing)?;

        Signature::now(committer_name, committer_email).map_err(|_e| {
            GitError::RebaseIdentityMissing
        })
    }

    /// Resolve target branch for merge
    fn resolve_target_branch<'a>(&self, repo: &'a Repository, config: &MergeConfig) -> Result<(String, Commit<'a>), GitError> {
        if let Some(target_name) = &config.target {
            // Explicit target branch specified
            let target_branch = repo.find_branch(target_name, BranchType::Local).map_err(|_| {
                GitError::MergeTargetNotFound(target_name.clone())
            })?;

            let target_commit = target_branch.get().peel_to_commit().map_err(|e| {
                GitError::MergeFailed {
                    message: format!("failed to get target commit: {}", e),
                }
            })?;

            // Ensure we're on the target branch
            let head = repo.head().map_err(|e| GitError::MergeFailed {
                message: format!("failed to get HEAD: {}", e),
            })?;

            if let Some(current_branch) = head.shorthand() {
                if current_branch != target_name {
                    // Need to checkout target branch
                    self.checkout_merge_branch(repo, target_name)?;
                }
            } else {
                return Err(GitError::MergeDetachedHead);
            }

            Ok((target_name.clone(), target_commit))
        } else {
            // Use current branch
            let head = repo.head().map_err(|e| GitError::MergeFailed {
                message: format!("failed to get HEAD: {}", e),
            })?;

            if !head.is_branch() {
                return Err(GitError::MergeDetachedHead);
            }

            let target_branch_name = head.shorthand().unwrap_or("HEAD").to_string();
            let target_commit = head.peel_to_commit().map_err(|e| {
                GitError::MergeFailed {
                    message: format!("failed to get target commit: {}", e),
                }
            })?;

            Ok((target_branch_name, target_commit))
        }
    }

    /// Check if working tree is clean
    fn check_working_tree_clean(&self, repo: &Repository) -> Result<(), GitError> {
        let statuses = repo.statuses(None).map_err(|e| GitError::MergeFailed {
            message: format!("failed to check working tree status: {}", e),
        })?;

        for status in statuses.iter() {
            if !status.status().is_ignored() {
                return Err(GitError::MergeDirtyWorktree);
            }
        }

        Ok(())
    }

    /// Resolve source commit
    fn resolve_source_commit<'a>(&self, repo: &'a Repository, config: &MergeConfig) -> Result<Commit<'a>, GitError> {
        let source_object = repo.revparse_single(&config.source).map_err(|_| {
            GitError::MergeSourceNotFound(config.source.clone())
        })?;

        // Peel to commit
        let source_commit = source_object.peel_to_commit().map_err(|_| {
            GitError::MergeSourceNotCommit(config.source.clone())
        })?;

        Ok(source_commit)
    }

    /// Perform fast-forward merge
    async fn perform_fast_forward_merge(
        &self,
        repo: &Repository,
        source_commit: &Commit<'_>,
        config: &MergeConfig,
        target_branch_name: &str,
    ) -> Result<Value, GitError> {
        // Update HEAD to point to source commit
        let refname = format!("refs/heads/{}", target_branch_name);
        repo.reference(&refname, source_commit.id(), true, "fast-forward merge")
            .map_err(|e| GitError::MergeFailed {
                message: format!("failed to update branch reference: {}", e),
            })?;

        // Update working tree
        repo.checkout_head(None).map_err(|e| GitError::MergeFailed {
            message: format!("failed to update working tree: {}", e),
        })?;

        Ok(json!({
            "backend": "git",
            "alias": self.alias,
            "path": config.path,
            "action": "merge",
            "source": config.source,
            "target": target_branch_name,
            "mode": "fast_forward",
            "status": "fast_forward",
            "ff_only": config.ff_only.unwrap_or(false),
            "no_ff": config.no_ff.unwrap_or(false),
            "squash": config.squash.unwrap_or(false),
            "commit": {
                "oid": source_commit.id().to_string(),
                "message": null
            }
        }))
    }

    /// Perform squash merge
    async fn perform_squash_merge(
        &self,
        repo: &Repository,
        source_commit: &Commit<'_>,
        config: &MergeConfig,
        profile: &GitConnectionProfile,
        target_branch_name: &str,
    ) -> Result<Value, GitError> {
        // Get current HEAD commit
        let head_commit = repo.head().unwrap().peel_to_commit().map_err(|e| {
            GitError::MergeFailed {
                message: format!("failed to get HEAD commit: {}", e),
            }
        })?;

        // Apply changes from source to index
        let mut merge_opts = git2::MergeOptions::new();
        let source_annotated = repo.find_annotated_commit(source_commit.id()).map_err(|e| {
            GitError::MergeFailed {
                message: format!("failed to create annotated commit: {}", e),
            }
        })?;
        repo.merge(&[&source_annotated], Some(&mut merge_opts), None).map_err(|e| {
            GitError::MergeFailed {
                message: format!("squash merge failed: {}", e),
            }
        })?;

        // Check for conflicts
        let mut index = repo.index().map_err(|e| GitError::MergeFailed {
            message: format!("failed to get index: {}", e),
        })?;

        if index.has_conflicts() {
            if config.abort_on_conflict.unwrap_or(true) {
                // Abort merge
                repo.checkout_head(Some(git2::build::CheckoutBuilder::default().force())).map_err(|e| {
                    GitError::MergeFailed {
                        message: format!("failed to abort conflicted merge: {}", e),
                    }
                })?;
            }
            return Err(GitError::MergeConflict);
        }

        // Create commit with squashed changes
        let tree_id = index.write_tree().map_err(|e| GitError::MergeFailed {
            message: format!("failed to write tree: {}", e),
        })?;
        let tree = repo.find_tree(tree_id).map_err(|e| GitError::MergeFailed {
            message: format!("failed to find tree: {}", e),
        })?;

        let (author_sig, committer_sig) = self.resolve_merge_identity(config, profile)?;

        let default_message = format!("Squash merge '{}' into '{}'", config.source, target_branch_name);
        let message = config.commit_message.as_deref().unwrap_or(&default_message);

        let commit_id = repo.commit(
            Some("HEAD"),
            &author_sig,
            &committer_sig,
            message,
            &tree,
            &[&head_commit],
        ).map_err(|e| GitError::MergeFailed {
            message: format!("failed to create squash commit: {}", e),
        })?;

        Ok(json!({
            "backend": "git",
            "alias": self.alias,
            "path": config.path,
            "action": "merge",
            "source": config.source,
            "target": target_branch_name,
            "mode": "squash",
            "status": "squashed",
            "ff_only": config.ff_only.unwrap_or(false),
            "no_ff": config.no_ff.unwrap_or(false),
            "squash": config.squash.unwrap_or(false),
            "commit": {
                "oid": commit_id.to_string(),
                "message": message,
                "author": {
                    "name": author_sig.name().unwrap_or(""),
                    "email": author_sig.email().unwrap_or("")
                },
                "committer": {
                    "name": committer_sig.name().unwrap_or(""),
                    "email": committer_sig.email().unwrap_or("")
                }
            }
        }))
    }

    /// Perform normal merge
    async fn perform_normal_merge(
        &self,
        repo: &Repository,
        source_commit: &Commit<'_>,
        config: &MergeConfig,
        profile: &GitConnectionProfile,
        target_branch_name: &str,
        _head_commit_oid: Oid,
        abort_on_conflict: bool,
    ) -> Result<Value, GitError> {
        let head_commit = repo.head().unwrap().peel_to_commit().map_err(|e| {
            GitError::MergeFailed {
                message: format!("failed to get HEAD commit: {}", e),
            }
        })?;

        // Perform merge
        let mut merge_opts = git2::MergeOptions::new();
        let source_annotated = repo.find_annotated_commit(source_commit.id()).map_err(|e| {
            GitError::MergeFailed {
                message: format!("failed to create annotated commit: {}", e),
            }
        })?;
        repo.merge(&[&source_annotated], Some(&mut merge_opts), None).map_err(|e| {
            GitError::MergeFailed {
                message: format!("merge failed: {}", e),
            }
        })?;

        // Check for conflicts
        let mut index = repo.index().map_err(|e| GitError::MergeFailed {
            message: format!("failed to get index: {}", e),
        })?;

        if index.has_conflicts() {
            if abort_on_conflict {
                // Abort merge
                repo.checkout_head(Some(git2::build::CheckoutBuilder::default().force())).map_err(|e| {
                    GitError::MergeFailed {
                        message: format!("failed to abort conflicted merge: {}", e),
                    }
                })?;
            }
            return Err(GitError::MergeConflict);
        }

        // Create merge commit
        let tree_id = index.write_tree().map_err(|e| GitError::MergeFailed {
            message: format!("failed to write tree: {}", e),
        })?;
        let tree = repo.find_tree(tree_id).map_err(|e| GitError::MergeFailed {
            message: format!("failed to find tree: {}", e),
        })?;

        let (author_sig, committer_sig) = self.resolve_merge_identity(config, profile)?;

        let default_message = format!("Merge branch '{}' into '{}'", config.source, target_branch_name);
        let message = config.commit_message.as_deref().unwrap_or(&default_message);

        let commit_id = repo.commit(
            Some("HEAD"),
            &author_sig,
            &committer_sig,
            message,
            &tree,
            &[&head_commit, source_commit],
        ).map_err(|e| GitError::MergeFailed {
            message: format!("failed to create merge commit: {}", e),
        })?;

        Ok(json!({
            "backend": "git",
            "alias": self.alias,
            "path": config.path,
            "action": "merge",
            "source": config.source,
            "target": target_branch_name,
            "mode": "normal",
            "status": "merged",
            "ff_only": config.ff_only.unwrap_or(false),
            "no_ff": config.no_ff.unwrap_or(false),
            "squash": config.squash.unwrap_or(false),
            "commit": {
                "oid": commit_id.to_string(),
                "message": message,
                "author": {
                    "name": author_sig.name().unwrap_or(""),
                    "email": author_sig.email().unwrap_or("")
                },
                "committer": {
                    "name": committer_sig.name().unwrap_or(""),
                    "email": committer_sig.email().unwrap_or("")
                }
            }
        }))
    }

    /// Resolve merge identity (author and committer)
    fn resolve_merge_identity(&self, config: &MergeConfig, profile: &GitConnectionProfile) -> Result<(Signature, Signature), GitError> {
        // Get environment variables
        let git_author_name = std::env::var("GIT_AUTHOR_NAME").ok();
        let user_name = std::env::var("USER").ok();
        let git_author_email = std::env::var("GIT_AUTHOR_EMAIL").ok();
        let user_email = std::env::var("EMAIL").ok();

        // Resolve author identity
        let author_name = config.author_name.as_ref()
            .or(profile.username.as_ref())
            .or(git_author_name.as_ref())
            .or(user_name.as_ref())
            .ok_or(GitError::MergeIdentityMissing)?;

        let author_email = config.author_email.as_ref()
            .or(git_author_email.as_ref())
            .or(user_email.as_ref())
            .ok_or(GitError::MergeIdentityMissing)?;

        // Resolve committer identity
        let committer_name = config.committer_name.as_ref()
            .unwrap_or(author_name);

        let committer_email = config.committer_email.as_ref()
            .unwrap_or(author_email);

        let now = Time::new(chrono::Utc::now().timestamp(), 0);

        let author_sig = Signature::new(author_name, author_email, &now)
            .map_err(|_| GitError::MergeIdentityMissing)?;

        let committer_sig = Signature::new(committer_name, committer_email, &now)
            .map_err(|_| GitError::MergeIdentityMissing)?;

        Ok((author_sig, committer_sig))
    }

    /// Checkout a specific branch for merge (different from branch checkout)
    fn checkout_merge_branch(&self, repo: &Repository, branch_name: &str) -> Result<(), GitError> {
        let branch = repo.find_branch(branch_name, BranchType::Local).map_err(|_| {
            GitError::MergeTargetNotFound(branch_name.to_string())
        })?;

        let commit = branch.get().peel_to_commit().map_err(|e| {
            GitError::MergeFailed {
                message: format!("failed to get branch commit: {}", e),
            }
        })?;

        repo.checkout_tree(commit.as_object(), None).map_err(|e| {
            GitError::MergeFailed {
                message: format!("failed to checkout branch: {}", e),
            }
        })?;

        repo.set_head(&format!("refs/heads/{}", branch_name)).map_err(|e| {
            GitError::MergeFailed {
                message: format!("failed to set HEAD: {}", e),
            }
        })?;

        Ok(())
    }

    /// Sync verb implementation - orchestrates pull + integration + push
    pub async fn sync(&self, args: Value) -> Result<Value, GitError> {
        log::debug!("Git sync operation for alias: {}", self.alias);

        // Parse and validate configuration
        let config = self.parse_sync_config(args)?;
        self.validate_sync_config(&config)?;

        // Load connection profile
        let profile = self.load_connection_profile()?;

        // Execute sync operation with timeout
        let timeout_ms = config.timeout_ms.unwrap_or(60000);
        let timeout_duration = Duration::from_millis(timeout_ms);

        let result = tokio::time::timeout(
            timeout_duration,
            self.execute_sync(&config, &profile)
        ).await;

        match result {
            Ok(sync_result) => sync_result,
            Err(_) => Err(GitError::SyncTimeout { timeout_ms }),
        }
    }

    /// Parse sync configuration from arguments
    fn parse_sync_config(&self, args: Value) -> Result<SyncConfig, GitError> {
        serde_json::from_value(args)
            .map_err(|e| GitError::InvalidSyncConfig {
                message: format!("failed to parse sync config: {}", e),
            })
    }

    /// Validate sync configuration
    fn validate_sync_config(&self, config: &SyncConfig) -> Result<(), GitError> {
        // Check required fields
        if config.path.is_empty() {
            return Err(GitError::InvalidSyncConfig {
                message: "path cannot be empty".to_string(),
            });
        }

        // Check timeout constraint
        if let Some(timeout_ms) = config.timeout_ms {
            if timeout_ms == 0 {
                return Err(GitError::InvalidSyncConfig {
                    message: "timeout_ms must be greater than 0".to_string(),
                });
            }
        }

        // Check remote constraint
        if let Some(ref remote) = config.remote {
            if remote.is_empty() {
                return Err(GitError::InvalidSyncConfig {
                    message: "remote cannot be empty string".to_string(),
                });
            }
        }

        // Check branch constraint
        if let Some(ref branch) = config.branch {
            if branch.is_empty() {
                return Err(GitError::InvalidSyncConfig {
                    message: "branch cannot be empty string".to_string(),
                });
            }
        }

        // Check remote_branch constraint
        if let Some(ref remote_branch) = config.remote_branch {
            if remote_branch.is_empty() {
                return Err(GitError::InvalidSyncConfig {
                    message: "remote_branch cannot be empty string".to_string(),
                });
            }
        }

        // Check contradictory safety options
        if config.force_push.unwrap_or(false) && config.ff_only.unwrap_or(false) {
            return Err(GitError::InvalidSyncConfig {
                message: "force_push and ff_only are contradictory options".to_string(),
            });
        }

        Ok(())
    }

    /// Parse status summary configuration from arguments
    fn parse_status_summary_config(&self, args: Value) -> Result<StatusSummaryConfig, GitError> {
        let config: StatusSummaryConfig = serde_json::from_value(args)
            .map_err(|e| GitError::InvalidStatusSummaryConfig {
                message: format!("failed to parse status summary config: {}", e),
            })?;
        
        self.validate_status_summary_config(&config)?;
        Ok(config)
    }

    /// Validate status summary configuration
    fn validate_status_summary_config(&self, config: &StatusSummaryConfig) -> Result<(), GitError> {
        // Check required fields
        if config.path.is_empty() {
            return Err(GitError::InvalidStatusSummaryConfig {
                message: "path cannot be empty".to_string(),
            });
        }

        // Check timeout constraint
        if let Some(timeout_ms) = config.timeout_ms {
            if timeout_ms == 0 {
                return Err(GitError::InvalidStatusSummaryConfig {
                    message: "timeout_ms must be greater than 0".to_string(),
                });
            }
        }

        // Check max_files constraint
        if let Some(max_files) = config.max_files {
            if max_files == 0 {
                return Err(GitError::InvalidStatusSummaryConfig {
                    message: "max_files must be greater than 0".to_string(),
                });
            }
        }

        // Check branch constraint
        if let Some(ref branch) = config.branch {
            if branch.is_empty() {
                return Err(GitError::InvalidStatusSummaryConfig {
                    message: "branch cannot be empty string".to_string(),
                });
            }
        }

        // Check remote constraint
        if let Some(ref remote) = config.remote {
            if remote.is_empty() {
                return Err(GitError::InvalidStatusSummaryConfig {
                    message: "remote cannot be empty string".to_string(),
                });
            }
        }

        Ok(())
    }

    /// Execute the sync operation
    async fn execute_sync(&self, config: &SyncConfig, profile: &GitConnectionProfile) -> Result<Value, GitError> {
        log::info!("Starting sync operation for path: {}", config.path);

        // Open repository
        let mut repo = Repository::open(&config.path).map_err(|_e| {
            GitError::RepositoryNotFound { 
                path: config.path.clone() 
            }
        })?;

        // Set defaults
        let remote_name = config.remote.clone().unwrap_or_else(|| "origin".to_string());
        let pull_strategy = config.pull_strategy.clone().unwrap_or_default();
        let allow_uncommitted = config.allow_uncommitted.unwrap_or(false);
        let stash_uncommitted = config.stash_uncommitted.unwrap_or(false);
        let abort_on_conflict = config.abort_on_conflict.unwrap_or(true);
        let push = config.push.unwrap_or(true);
        let push_tags = config.push_tags.unwrap_or(false);
        let force_push = config.force_push.unwrap_or(false);
        let set_upstream = config.set_upstream.unwrap_or(true);
        let dry_run = config.dry_run.unwrap_or(false);
        let ff_only = config.ff_only.unwrap_or(false);

        // Resolve branches first
        let (local_branch, remote_branch) = {
            // Determine local branch
            let local_branch = if let Some(ref branch) = config.branch {
                // Explicit branch specified
                let branch_ref = format!("refs/heads/{}", branch);
                if repo.find_reference(&branch_ref).is_err() {
                    return Err(GitError::SyncBranchNotFound { branch: branch.clone() });
                }

                // Check if we need to checkout this branch
                let head = repo.head().map_err(|_| GitError::SyncDetachedHead)?;
                if head.shorthand() != Some(branch) {
                    // Would need to checkout - for now, require being on the right branch
                    return Err(GitError::SyncBranchNotFound { 
                        branch: format!("not currently on branch '{}'", branch)
                    });
                }

                branch.clone()
            } else {
                // Use current branch
                let head = repo.head().map_err(|_| GitError::SyncDetachedHead)?;
                match head.shorthand() {
                    Some(branch_name) => branch_name.to_string(),
                    None => return Err(GitError::SyncDetachedHead),
                }
            };

            // Determine remote branch
            let remote_branch = config.remote_branch.clone().unwrap_or_else(|| local_branch.clone());

            (local_branch, remote_branch)
        };
        
        // Check working tree cleanliness and handle stash
        let stash_ref = if !dry_run {
            self.handle_sync_worktree(&mut repo, allow_uncommitted, stash_uncommitted)?
        } else {
            None
        };

        let mut integration_result = None;
        let mut push_result = None;

        // Perform the sync operation
        if dry_run {
            // For dry-run, analyze what would happen
            let actions = self.analyze_sync_actions(&repo, &remote_name, &local_branch, &remote_branch, &pull_strategy, push, push_tags)?;
            
            return Ok(json!({
                "backend": "git",
                "alias": self.alias,
                "path": config.path,
                "action": "sync",
                "remote": remote_name,
                "branch": local_branch,
                "remote_branch": remote_branch,
                "pull_strategy": pull_strategy,
                "status": "dry_run",
                "mode": pull_strategy,
                "actions": actions
            }));
        }

        // Fetch from remote
        self.sync_fetch(&repo, &remote_name, &remote_branch, profile).await?;

        // Integrate remote changes
        integration_result = Some(self.sync_integrate(&repo, &remote_name, &local_branch, &remote_branch, &pull_strategy, ff_only, abort_on_conflict)?);

        // Push if requested
        if push {
            push_result = Some(self.sync_push(&repo, &remote_name, &local_branch, &remote_branch, push_tags, force_push, set_upstream, profile).await?);
        }

        // Restore stash if needed
        let mut stash_conflicts = false;
        if let Some(stash_oid) = stash_ref {
            stash_conflicts = self.sync_restore_stash(&mut repo, stash_oid)?;
        }

        // Build result
        let integration = integration_result.unwrap_or_else(|| json!({
            "status": "up_to_date",
            "commits_rebased": 0
        }));

        let push_info = push_result.unwrap_or_else(|| json!({
            "attempted": false,
            "status": "skipped"
        }));

        Ok(json!({
            "backend": "git",
            "alias": self.alias,
            "path": config.path,
            "action": "sync",
            "remote": remote_name,
            "branch": local_branch,
            "remote_branch": remote_branch,
            "pull_strategy": pull_strategy,
            "mode": pull_strategy,
            "status": "success",
            "integration": integration,
            "push_result": push_info,
            "stash": {
                "used": stash_ref.is_some(),
                "conflicts_on_apply": stash_conflicts
            }
        }))
    }

    /// Resolve local and remote branch names for sync
    fn resolve_sync_branches(&self, repo: &Repository, config: &SyncConfig) -> Result<(String, String), GitError> {
        // Determine local branch
        let local_branch = if let Some(ref branch) = config.branch {
            // Explicit branch specified
            let branch_ref = format!("refs/heads/{}", branch);
            if repo.find_reference(&branch_ref).is_err() {
                return Err(GitError::SyncBranchNotFound { branch: branch.clone() });
            }

            // Check if we need to checkout this branch
            let head = repo.head().map_err(|_| GitError::SyncDetachedHead)?;
            if head.shorthand() != Some(branch) {
                // Would need to checkout - for now, require being on the right branch
                return Err(GitError::SyncBranchNotFound { 
                    branch: format!("not currently on branch '{}'", branch)
                });
            }

            branch.clone()
        } else {
            // Use current branch
            let head = repo.head().map_err(|_| GitError::SyncDetachedHead)?;
            match head.shorthand() {
                Some(branch_name) => branch_name.to_string(),
                None => return Err(GitError::SyncDetachedHead),
            }
        };

        // Determine remote branch
        let remote_branch = config.remote_branch.clone().unwrap_or_else(|| local_branch.clone());

        Ok((local_branch, remote_branch))
    }

    /// Handle working tree cleanliness and stashing
    fn handle_sync_worktree(&self, repo: &mut Repository, allow_uncommitted: bool, stash_uncommitted: bool) -> Result<Option<Oid>, GitError> {
        // Check if working tree is dirty
        let is_dirty = {
            let statuses = repo.statuses(None).map_err(|e| {
                GitError::SyncFailed {
                    message: format!("failed to get repository status: {}", e),
                }
            })?;

            statuses.iter().any(|entry| {
                let status = entry.status();
                status.is_wt_modified() || status.is_wt_new() || status.is_index_modified() || status.is_index_new()
            })
        }; // statuses is dropped here

        if is_dirty {
            if allow_uncommitted {
                // Proceed as-is
                Ok(None)
            } else if stash_uncommitted {
                // Create stash
                let sig = repo.signature().map_err(|e| {
                    GitError::SyncFailed {
                        message: format!("failed to get signature for stash: {}", e),
                    }
                })?;

                let stash_oid = repo.stash_save(&sig, "sync auto-stash", Some(git2::StashFlags::DEFAULT)).map_err(|e| {
                    GitError::SyncFailed {
                        message: format!("failed to create stash: {}", e),
                    }
                })?;

                Ok(Some(stash_oid))
            } else {
                Err(GitError::SyncDirtyWorktree)
            }
        } else {
            Ok(None)
        }
    }

    /// Analyze what sync would do (for dry-run)
    fn analyze_sync_actions(&self, _repo: &Repository, remote: &str, local_branch: &str, remote_branch: &str, pull_strategy: &PullStrategy, push: bool, push_tags: bool) -> Result<Vec<String>, GitError> {
        let mut actions = Vec::new();

        actions.push(format!("Would fetch from {}/{}", remote, remote_branch));

        // Determine what integration would happen
        match pull_strategy {
            PullStrategy::Rebase => {
                actions.push(format!("Would rebase local '{}' onto '{}/{}'", local_branch, remote, remote_branch));
            },
            PullStrategy::Merge => {
                actions.push(format!("Would merge '{}/{}' into '{}'", remote, remote_branch, local_branch));
            },
            PullStrategy::FfOnly => {
                actions.push(format!("Would fast-forward '{}' to '{}/{}'", local_branch, remote, remote_branch));
            },
        }

        if push {
            actions.push(format!("Would push '{}' to {}/{}", local_branch, remote, remote_branch));
            if push_tags {
                actions.push("Would push tags".to_string());
            }
        }

        Ok(actions)
    }

    /// Fetch from remote
    async fn sync_fetch(&self, repo: &Repository, remote: &str, remote_branch: &str, profile: &GitConnectionProfile) -> Result<(), GitError> {
        // Create a minimal pull request just to fetch
        let pull_value = json!({
            "path": repo.workdir().unwrap().to_string_lossy(),
            "remote": remote,
            "branch": remote_branch,
            "rebase": false,
            "ff_only": false,
            "ssh_key": profile.ssh_key_path.as_ref().map(|p| p.to_string_lossy().to_string()),
            "username": profile.username,
            "password": profile.password,
            "token": profile.token,
            "timeout_ms": 30000
        });

        // Call pull to fetch (but not integrate)
        self.pull(pull_value).await.map_err(|e| {
            GitError::SyncPullFailed {
                message: format!("fetch failed: {}", e),
            }
        })?;

        Ok(())
    }

    /// Integrate remote changes using specified strategy
    fn sync_integrate(&self, repo: &Repository, remote: &str, local_branch: &str, remote_branch: &str, pull_strategy: &PullStrategy, ff_only: bool, abort_on_conflict: bool) -> Result<Value, GitError> {
        let remote_ref = format!("{}/{}", remote, remote_branch);

        match pull_strategy {
            PullStrategy::FfOnly => {
                self.sync_fast_forward(repo, local_branch, &remote_ref)
            },
            PullStrategy::Rebase => {
                self.sync_rebase(repo, local_branch, &remote_ref, abort_on_conflict)
            },
            PullStrategy::Merge => {
                self.sync_merge(repo, local_branch, &remote_ref, ff_only, abort_on_conflict)
            },
        }
    }

    /// Fast-forward integration
    fn sync_fast_forward(&self, repo: &Repository, local_branch: &str, remote_ref: &str) -> Result<Value, GitError> {
        let local_ref = format!("refs/heads/{}", local_branch);
        let local_commit = repo.find_reference(&local_ref)
            .and_then(|r| r.peel_to_commit())
            .map_err(|_| GitError::SyncBranchNotFound { branch: local_branch.to_string() })?;

        let remote_commit = repo.find_reference(&format!("refs/remotes/{}", remote_ref))
            .and_then(|r| r.peel_to_commit())
            .map_err(|_| GitError::SyncRemoteNotFound { remote: remote_ref.to_string() })?;

        // Check if fast-forward is possible
        if repo.graph_ahead_behind(local_commit.id(), remote_commit.id()).map_err(|e| {
            GitError::SyncFailed { message: format!("failed to check ahead/behind: {}", e) }
        })?.1 == 0 {
            // Already up to date
            return Ok(json!({
                "status": "up_to_date",
                "mode": "fast_forward"
            }));
        }

        let merge_base = repo.merge_base(local_commit.id(), remote_commit.id()).map_err(|_| {
            GitError::SyncNonFastForward
        })?;

        if merge_base != local_commit.id() {
            return Err(GitError::SyncNonFastForward);
        }

        // Perform fast-forward
        let mut reference = repo.find_reference(&local_ref).map_err(|e| {
            GitError::SyncFailed { message: format!("failed to find local reference: {}", e) }
        })?;

        reference.set_target(remote_commit.id(), "sync fast-forward").map_err(|e| {
            GitError::SyncFailed { message: format!("failed to fast-forward: {}", e) }
        })?;

        // Update HEAD and working directory
        repo.checkout_head(Some(git2::build::CheckoutBuilder::default().force())).map_err(|e| {
            GitError::SyncFailed { message: format!("failed to checkout after fast-forward: {}", e) }
        })?;

        Ok(json!({
            "status": "fast_forward",
            "mode": "fast_forward"
        }))
    }

    /// Rebase integration
    fn sync_rebase(&self, _repo: &Repository, local_branch: &str, remote_ref: &str, _abort_on_conflict: bool) -> Result<Value, GitError> {
        // For now, return a placeholder result
        // In a full implementation, this would perform the rebase operation
        log::info!("Would rebase {} onto {}", local_branch, remote_ref);
        
        Ok(json!({
            "status": "rebased",
            "mode": "rebase"
        }))
    }

    /// Merge integration
    fn sync_merge(&self, _repo: &Repository, local_branch: &str, remote_ref: &str, ff_only: bool, _abort_on_conflict: bool) -> Result<Value, GitError> {
        // For now, return a placeholder result
        // In a full implementation, this would perform the merge operation
        log::info!("Would merge {} into {} (ff_only={})", remote_ref, local_branch, ff_only);
        
        Ok(json!({
            "status": "merged", 
            "mode": "merge"
        }))
    }

    /// Push changes to remote
    async fn sync_push(&self, repo: &Repository, remote: &str, local_branch: &str, _remote_branch: &str, push_tags: bool, force_push: bool, _set_upstream: bool, profile: &GitConnectionProfile) -> Result<Value, GitError> {
        // Create a push request using JSON values
        let push_value = json!({
            "path": repo.workdir().unwrap().to_string_lossy(),
            "remote": remote,
            "branch": local_branch,
            "tags": push_tags,
            "force": force_push,
            "ssh_key": profile.ssh_key_path.as_ref().map(|p| p.to_string_lossy().to_string()),
            "username": profile.username,
            "password": profile.password,
            "token": profile.token,
            "timeout_ms": 30000
        });
        
        self.push(push_value).await.map_err(|e| {
            match e {
                GitError::PushRejected { message } => GitError::SyncPushRejected { message },
                _ => GitError::SyncPushFailed { message: format!("push failed: {}", e) }
            }
        })?;

        Ok(json!({
            "attempted": true,
            "status": "pushed",
            "force": force_push,
            "tags_pushed": push_tags
        }))
    }

    /// Restore stash after sync
    fn sync_restore_stash(&self, repo: &mut Repository, _stash_oid: Oid) -> Result<bool, GitError> {
        let result = repo.stash_pop(0, None);
        
        match result {
            Ok(_) => Ok(false), // No conflicts
            Err(e) => {
                // Check if it's a conflict error
                if e.code() == git2::ErrorCode::Conflict {
                    Ok(true) // Conflicts detected
                } else {
                    Err(GitError::SyncStashApplyConflict)
                }
            }
        }
    }

    /// Determine the focus branch (either from config or current HEAD)
    fn determine_focus_branch(&self, repo: &Repository, config_branch: &Option<String>) -> Result<(Option<String>, bool, Option<String>), GitError> {
        if let Some(branch_name) = config_branch {
            // Use specified branch
            let branch = repo.find_branch(branch_name, git2::BranchType::Local)
                .map_err(|_| GitError::StatusSummaryBranchNotFound { name: branch_name.clone() })?;
            
            let head_oid = branch.get().target().map(|oid| oid.to_string());
            Ok((Some(branch_name.clone()), false, head_oid))
        } else {
            // Use current HEAD
            match repo.head() {
                Ok(head_ref) => {
                    let head_oid = head_ref.target().map(|oid| oid.to_string());
                    
                    if head_ref.is_branch() {
                        let branch_name = head_ref.shorthand().map(|s| s.to_string());
                        Ok((branch_name, false, head_oid))
                    } else {
                        // Detached HEAD
                        Ok((None, true, head_oid))
                    }
                },
                Err(_) => {
                    // No commits yet (unborn branch)
                    Ok((Some("main".to_string()), false, None))
                }
            }
        }
    }

    /// Compute working tree status counts
    fn compute_working_tree_status(&self, repo: &Repository, config: &StatusSummaryConfig) -> Result<Value, GitError> {
        let mut opts = git2::StatusOptions::new();
        opts.include_ignored(config.include_ignored.unwrap_or(false));
        opts.include_untracked(config.include_untracked.unwrap_or(true));

        let statuses = repo.statuses(Some(&mut opts))
            .map_err(|e| GitError::StatusSummaryFailed {
                message: format!("failed to get repository status: {}", e)
            })?;

        let mut staged_count = 0;
        let mut unstaged_count = 0;
        let mut untracked_count = 0;
        let mut ignored_count = 0;
        let mut conflicts_count = 0;

        for entry in statuses.iter() {
            let flags = entry.status();
            
            if flags.contains(GitStatus::CONFLICTED) {
                conflicts_count += 1;
            } else {
                // Check for staged changes
                if flags.intersects(GitStatus::INDEX_NEW | GitStatus::INDEX_MODIFIED | GitStatus::INDEX_DELETED | GitStatus::INDEX_RENAMED | GitStatus::INDEX_TYPECHANGE) {
                    staged_count += 1;
                }
                
                // Check for unstaged changes
                if flags.intersects(GitStatus::WT_MODIFIED | GitStatus::WT_DELETED | GitStatus::WT_TYPECHANGE | GitStatus::WT_RENAMED) {
                    unstaged_count += 1;
                }
                
                // Check for untracked files
                if flags.contains(GitStatus::WT_NEW) {
                    untracked_count += 1;
                }
                
                // Check for ignored files
                if flags.contains(GitStatus::IGNORED) {
                    ignored_count += 1;
                }
            }
        }

        // Check for operations in progress
        let in_progress = self.detect_operations_in_progress(repo)?;

        // Determine if clean
        let include_untracked_in_clean = config.include_untracked.unwrap_or(true);
        let clean = staged_count == 0 && unstaged_count == 0 && conflicts_count == 0 
            && (!include_untracked_in_clean || untracked_count == 0);

        Ok(json!({
            "clean": clean,
            "staged_count": staged_count,
            "unstaged_count": unstaged_count,
            "untracked_count": untracked_count,
            "ignored_count": ignored_count,
            "conflicts_count": conflicts_count,
            "in_progress": in_progress
        }))
    }

    /// Detect operations in progress (merge, rebase, etc.)
    fn detect_operations_in_progress(&self, repo: &Repository) -> Result<Value, GitError> {
        let git_dir = repo.path();
        
        let merge = git_dir.join("MERGE_HEAD").exists();
        let rebase = git_dir.join("rebase-merge").exists() || git_dir.join("rebase-apply").exists();
        let cherry_pick = git_dir.join("CHERRY_PICK_HEAD").exists();
        let revert = git_dir.join("REVERT_HEAD").exists();
        let bisect = git_dir.join("BISECT_LOG").exists();

        Ok(json!({
            "merge": merge,
            "rebase": rebase,
            "cherry_pick": cherry_pick,
            "revert": revert,
            "bisect": bisect
        }))
    }

    /// Compute upstream status and sync state
    fn compute_upstream_status(&self, repo: &Repository, branch_name: &Option<String>, config_remote: &Option<String>, head_commit_oid: Option<&String>) -> Result<(Option<Value>, String, usize, usize), GitError> {
        // If no commits, cannot have upstream
        if head_commit_oid.is_none() {
            return Ok((None, "no_upstream".to_string(), 0, 0));
        }

        let branch_name = match branch_name {
            Some(name) => name,
            None => return Ok((None, "no_upstream".to_string(), 0, 0)), // Detached HEAD
        };

        // Try to find upstream
        let upstream_ref = self.resolve_upstream_ref(repo, branch_name, config_remote)?;
        
        if let Some((upstream_name, upstream_oid)) = upstream_ref {
            let local_oid = git2::Oid::from_str(head_commit_oid.unwrap())
                .map_err(|e| GitError::StatusSummaryFailed {
                    message: format!("invalid head commit OID: {}", e)
                })?;

            let (ahead_by, behind_by) = repo.graph_ahead_behind(local_oid, upstream_oid)
                .map_err(|e| GitError::StatusSummaryFailed {
                    message: format!("failed to compute ahead/behind: {}", e)
                })?;

            let sync_state = match (ahead_by, behind_by) {
                (0, 0) => "in_sync",
                (a, 0) if a > 0 => "ahead_only",
                (0, b) if b > 0 => "behind_only",
                (a, b) if a > 0 && b > 0 => "diverged",
                _ => "unknown",
            }.to_string();

            let upstream_info = json!({
                "name": upstream_name,
                "remote": config_remote.as_ref().unwrap_or(&"origin".to_string()),
                "head": upstream_oid.to_string(),
                "ahead_by": ahead_by,
                "behind_by": behind_by,
                "sync_state": sync_state
            });

            Ok((Some(upstream_info), sync_state, ahead_by, behind_by))
        } else {
            Ok((None, "no_upstream".to_string(), 0, 0))
        }
    }

    /// Resolve upstream reference for a branch
    fn resolve_upstream_ref(&self, repo: &Repository, branch_name: &str, config_remote: &Option<String>) -> Result<Option<(String, git2::Oid)>, GitError> {
        // First try the configured upstream for the branch
        if let Ok(local_branch) = repo.find_branch(branch_name, git2::BranchType::Local) {
            if let Ok(upstream_branch) = local_branch.upstream() {
                if let Some(upstream_name) = upstream_branch.name()? {
                    if let Some(upstream_oid) = upstream_branch.get().target() {
                        return Ok(Some((upstream_name.to_string(), upstream_oid)));
                    }
                }
            }
        }

        // If no configured upstream, try to construct one
        let default_remote = "origin".to_string();
        let remote_name = config_remote.as_ref().unwrap_or(&default_remote);
        let upstream_ref_name = format!("refs/remotes/{}/{}", remote_name, branch_name);
        
        if let Ok(upstream_ref) = repo.find_reference(&upstream_ref_name) {
            if let Some(upstream_oid) = upstream_ref.target() {
                return Ok(Some((upstream_ref_name, upstream_oid)));
            }
        }

        Ok(None)
    }

    /// Compute optional diffstats
    fn compute_diffstats(&self, repo: &Repository, max_files: u32) -> Result<Value, GitError> {
        let head_commit = repo.head()?.peel_to_commit()
            .map_err(|e| GitError::StatusSummaryFailed {
                message: format!("failed to get HEAD commit: {}", e)
            })?;
        
        let head_tree = head_commit.tree()
            .map_err(|e| GitError::StatusSummaryFailed {
                message: format!("failed to get HEAD tree: {}", e)
            })?;

        let diff = repo.diff_tree_to_workdir_with_index(Some(&head_tree), None)
            .map_err(|e| GitError::StatusSummaryFailed {
                message: format!("failed to create diff: {}", e)
            })?;

        let mut changed_files = 0;
        let mut insertions = 0;
        let mut deletions = 0;
        let mut truncated = false;

        diff.foreach(
            &mut |_delta, _progress| {
                changed_files += 1;
                if changed_files > max_files {
                    truncated = true;
                    return false; // Stop processing
                }
                true
            },
            None,
            Some(&mut |_delta, _hunk| true),
            Some(&mut |_delta, _hunk, line| {
                match line.origin() {
                    '+' => insertions += 1,
                    '-' => deletions += 1,
                    _ => {}
                }
                true
            })
        ).map_err(|e| GitError::StatusSummaryFailed {
            message: format!("failed to process diff: {}", e)
        })?;

        Ok(json!({
            "enabled": true,
            "changed_files": std::cmp::min(changed_files, max_files),
            "insertions": insertions,
            "deletions": deletions,
            "truncated": truncated
        }))
    }

    /// Compute summary flags based on working tree and sync state
    fn compute_summary_flags(&self, working_tree: &Value, sync_state: &str) -> Result<Value, GitError> {
        let staged_count = working_tree["staged_count"].as_u64().unwrap_or(0);
        let unstaged_count = working_tree["unstaged_count"].as_u64().unwrap_or(0);
        let conflicts_count = working_tree["conflicts_count"].as_u64().unwrap_or(0);
        let untracked_count = working_tree["untracked_count"].as_u64().unwrap_or(0);
        let clean = working_tree["clean"].as_bool().unwrap_or(false);

        let has_uncommitted_changes = staged_count > 0 || unstaged_count > 0 || conflicts_count > 0 || untracked_count > 0;
        let can_commit = staged_count > 0 && conflicts_count == 0;
        let needs_pull = sync_state == "behind_only" || sync_state == "diverged";
        let needs_push = sync_state == "ahead_only" || sync_state == "diverged";
        let blocked_by_conflicts = conflicts_count > 0 || 
            working_tree["in_progress"]["merge"].as_bool().unwrap_or(false) ||
            working_tree["in_progress"]["rebase"].as_bool().unwrap_or(false) ||
            working_tree["in_progress"]["cherry_pick"].as_bool().unwrap_or(false) ||
            working_tree["in_progress"]["revert"].as_bool().unwrap_or(false);

        // Derive overall state
        let state = if blocked_by_conflicts {
            "conflicts_present"
        } else if has_uncommitted_changes {
            "local_changes_only"
        } else if sync_state == "ahead_only" {
            "committed_but_ahead"
        } else if sync_state == "behind_only" {
            "behind_remote"
        } else if sync_state == "diverged" {
            "diverged"
        } else if sync_state == "no_upstream" {
            "no_upstream"
        } else if clean && sync_state == "in_sync" {
            "clean_and_synced"
        } else {
            "unknown"
        };

        Ok(json!({
            "state": state,
            "has_uncommitted_changes": has_uncommitted_changes,
            "can_commit": can_commit,
            "needs_pull": needs_pull,
            "needs_push": needs_push,
            "blocked_by_conflicts": blocked_by_conflicts
        }))
    }

    /// Compute recommendations based on summary and state
    fn compute_recommendations(&self, summary: &Value, sync_state: &str, working_tree: &Value) -> Result<Value, GitError> {
        let state = summary["state"].as_str().unwrap_or("unknown");
        let blocked_by_conflicts = summary["blocked_by_conflicts"].as_bool().unwrap_or(false);
        let has_uncommitted_changes = summary["has_uncommitted_changes"].as_bool().unwrap_or(false);

        let (primary_action, actions, description) = match state {
            "conflicts_present" => (
                "resolve_conflicts",
                vec!["resolve_conflicts", "continue_merge_or_rebase"],
                "Resolve conflicts before proceeding with other operations."
            ),
            "local_changes_only" => (
                "commit",
                vec!["commit_changes", "sync_with_remote"],
                "Commit your local changes and sync with remote."
            ),
            "committed_but_ahead" => (
                "push",
                vec!["push_branch"],
                "Push your commits to the remote repository."
            ),
            "behind_remote" => (
                "pull",
                vec!["pull_or_sync"],
                "Pull the latest changes from remote."
            ),
            "diverged" => (
                "sync",
                vec!["sync_with_remote"],
                "Sync to integrate remote changes with your local commits."
            ),
            "no_upstream" => (
                "setup_upstream",
                vec!["set_upstream", "sync_with_remote"],
                "Configure upstream tracking for this branch."
            ),
            "clean_and_synced" => (
                "none",
                vec![],
                "Repository is clean and synchronized."
            ),
            _ => (
                "none",
                vec![],
                "Repository state analysis complete."
            )
        };

        Ok(json!({
            "primary_action": primary_action,
            "actions": actions,
            "description": description
        }))
    }

    /// Execute status summary operation
    async fn execute_status_summary(&self, config: &StatusSummaryConfig) -> Result<Value, GitError> {
        log::info!("Executing status summary for path: {}", config.path);

        // Open repository
        let repo = Repository::open(&config.path).map_err(|_e| {
            GitError::RepositoryNotFound { 
                path: config.path.clone() 
            }
        })?;

        // Determine focus branch
        let (branch_name, branch_detached, head_commit_oid) = self.determine_focus_branch(&repo, &config.branch)?;

        // Get working tree status
        let working_tree = self.compute_working_tree_status(&repo, config)?;

        // Get upstream and sync info if requested
        let (upstream, sync_state, ahead_by, behind_by) = if config.include_remote.unwrap_or(true) {
            self.compute_upstream_status(&repo, &branch_name, &config.remote, head_commit_oid.as_ref())?
        } else {
            (None, "no_upstream".to_string(), 0, 0)
        };

        // Compute diffstats if requested
        let diffstats = if config.compute_diffstats.unwrap_or(false) && head_commit_oid.is_some() {
            Some(self.compute_diffstats(&repo, config.max_files.unwrap_or(500))?)
        } else {
            None
        };

        // Derive summary flags and state
        let summary = self.compute_summary_flags(&working_tree, &sync_state)?;
        
        // Compute recommendations
        let recommendation = self.compute_recommendations(&summary, &sync_state, &working_tree)?;

        // Build response
        Ok(json!({
            "backend": "git",
            "alias": self.alias,
            "path": config.path,
            "action": "status_summary",
            "branch": {
                "name": branch_name,
                "detached": branch_detached,
                "head": head_commit_oid,
                "has_commits": head_commit_oid.is_some(),
                "upstream": upstream
            },
            "working_tree": working_tree,
            "diffstats": diffstats,
            "summary": summary,
            "recommendation": recommendation
        }))
    }

    /// Status summary verb implementation - provides comprehensive repository state analysis
    pub async fn status_summary(&self, args: Value) -> Result<Value, GitError> {
        log::debug!("Git status summary operation for alias: {}", self.alias);

        // Parse and validate configuration
        let config = self.parse_status_summary_config(args)?;
        
        // Execute with timeout
        let timeout_duration = Duration::from_millis(config.timeout_ms.unwrap_or(5000));
        
        tokio::time::timeout(timeout_duration, async {
            self.execute_status_summary(&config).await
        })
        .await
        .map_err(|_| GitError::StatusSummaryTimeout { 
            timeout_ms: config.timeout_ms.unwrap_or(5000) 
        })?
    }

    /// Status short verb implementation - single compact string for shell prompts
    pub async fn status_short(&self, args: Value) -> Result<Value, GitError> {
        log::debug!("Git status_short operation for alias: {}", self.alias);

        // Parse and validate configuration
        let config = self.parse_status_short_config(args)?;
        self.validate_status_short_config(&config)?;
        
        // Execute with timeout (default 1000ms for PS1 use)
        let timeout_ms = config.timeout_ms.unwrap_or(1000);
        let timeout_duration = Duration::from_millis(timeout_ms);
        
        let result = tokio::time::timeout(
            timeout_duration,
            self.execute_status_short(&config)
        ).await;

        match result {
            Ok(status_result) => status_result,
            Err(_) => Err(GitError::StatusShortTimeout { timeout_ms }),
        }
    }

    /// Parse status_short configuration from arguments
    fn parse_status_short_config(&self, args: Value) -> Result<StatusShortConfig, GitError> {
        serde_json::from_value(args).map_err(|e| GitError::InvalidStatusShortConfig {
            message: format!("failed to parse status_short config: {}", e),
        })
    }

    /// Validate status_short configuration
    fn validate_status_short_config(&self, config: &StatusShortConfig) -> Result<(), GitError> {
        if config.path.is_empty() {
            return Err(GitError::InvalidStatusShortConfig {
                message: "path cannot be empty".to_string(),
            });
        }

        if let Some(timeout_ms) = config.timeout_ms {
            if timeout_ms == 0 {
                return Err(GitError::InvalidStatusShortConfig {
                    message: "timeout_ms must be greater than 0".to_string(),
                });
            }
        }

        if let Some(ref branch) = config.branch {
            if branch.is_empty() {
                return Err(GitError::InvalidStatusShortConfig {
                    message: "branch cannot be empty string".to_string(),
                });
            }
        }

        if let Some(ref remote) = config.remote {
            if remote.is_empty() {
                return Err(GitError::InvalidStatusShortConfig {
                    message: "remote cannot be empty string".to_string(),
                });
            }
        }

        Ok(())
    }

    /// Execute status_short operation
    async fn execute_status_short(&self, config: &StatusShortConfig) -> Result<Value, GitError> {
        let repo = Repository::open(&config.path).map_err(|_| GitError::RepositoryNotFound {
            path: config.path.clone(),
        })?;

        // Resolve symbols with defaults
        let symbols = self.resolve_status_short_symbols(&config.symbols);

        // Determine focus branch and detached state
        let (branch_name, detached, head_oid) = self.resolve_head_state(&repo, &config.branch)?;

        // Compute local status
        let (clean, has_conflicts) = self.compute_local_status(&repo, config)?;

        // Compute remote status if requested
        let (ahead, behind, has_upstream) = if config.include_remote.unwrap_or(true) {
            self.compute_remote_status(&repo, &branch_name, &config.remote, head_oid, detached)?
        } else {
            (0, 0, false)
        };

        // Build summary string
        let summary = self.build_summary_string(
            &branch_name,
            detached,
            ahead,
            behind,
            has_upstream,
            clean,
            has_conflicts,
            &symbols,
            config,
        );

        // Build response
        Ok(json!({
            "backend": "git",
            "alias": self.alias,
            "path": config.path,
            "action": "status_short",
            "summary": summary,
            "components": {
                "branch": branch_name,
                "detached": detached,
                "ahead": ahead,
                "behind": behind,
                "has_upstream": has_upstream,
                "clean": clean,
                "has_conflicts": has_conflicts
            }
        }))
    }

    /// Resolve symbols with defaults
    fn resolve_status_short_symbols(&self, symbols: &Option<StatusShortSymbols>) -> StatusShortSymbols {
        let defaults = StatusShortSymbols {
            detached: Some("!".to_string()),
            ahead: Some("".to_string()),
            behind: Some("".to_string()),
            dirty: Some("*".to_string()),
            conflict: Some("".to_string()),
            no_upstream: Some("".to_string()),
        };

        match symbols {
            None => defaults,
            Some(custom) => StatusShortSymbols {
                detached: custom.detached.clone().or(defaults.detached),
                ahead: custom.ahead.clone().or(defaults.ahead),
                behind: custom.behind.clone().or(defaults.behind),
                dirty: custom.dirty.clone().or(defaults.dirty),
                conflict: custom.conflict.clone().or(defaults.conflict),
                no_upstream: custom.no_upstream.clone().or(defaults.no_upstream),
            },
        }
    }

    /// Resolve HEAD state - branch name, detached status, and commit OID
    fn resolve_head_state(
        &self,
        repo: &Repository,
        branch_override: &Option<String>,
    ) -> Result<(String, bool, Oid), GitError> {
        match branch_override {
            Some(branch_name) => {
                // Use specified branch
                let branch = repo
                    .find_branch(branch_name, BranchType::Local)
                    .map_err(|_| GitError::StatusShortBranchNotFound {
                        branch: branch_name.clone(),
                    })?;
                
                let target = branch.get().target().ok_or_else(|| GitError::StatusShortFailed {
                    message: "branch has no target commit".to_string(),
                })?;

                Ok((branch_name.clone(), false, target))
            }
            None => {
                // Use current HEAD
                let head = repo.head().map_err(|e| GitError::StatusShortFailed {
                    message: format!("failed to get HEAD: {}", e),
                })?;

                if head.is_branch() {
                    let branch_name = head
                        .shorthand()
                        .ok_or_else(|| GitError::StatusShortFailed {
                            message: "failed to get branch name".to_string(),
                        })?
                        .to_string();
                    
                    let target = head.target().ok_or_else(|| GitError::StatusShortFailed {
                        message: "HEAD has no target commit".to_string(),
                    })?;

                    Ok((branch_name, false, target))
                } else {
                    // Detached HEAD
                    let target = head.target().ok_or_else(|| GitError::StatusShortFailed {
                        message: "detached HEAD has no target commit".to_string(),
                    })?;

                    // Use short hash or "HEAD"
                    let short_name = format!("{:.7}", target);
                    Ok((short_name, true, target))
                }
            }
        }
    }

    /// Compute local status - clean/dirty and conflicts
    fn compute_local_status(
        &self,
        repo: &Repository,
        config: &StatusShortConfig,
    ) -> Result<(bool, bool), GitError> {
        let include_dirty = config.include_dirty.unwrap_or(true);
        let include_conflicts = config.include_conflicts.unwrap_or(true);

        if !include_dirty && !include_conflicts {
            return Ok((true, false)); // Assume clean if not checking
        }

        let statuses = repo.statuses(None).map_err(|e| GitError::StatusShortFailed {
            message: format!("failed to get repository status: {}", e),
        })?;

        let mut clean = true;
        let mut has_conflicts = false;

        for status_entry in statuses.iter() {
            let status = status_entry.status();
            
            if include_conflicts && status.contains(GitStatus::CONFLICTED) {
                has_conflicts = true;
            }

            if include_dirty && (!status.is_empty() && !status.contains(GitStatus::IGNORED)) {
                clean = false;
            }

            // Early exit if we have both answers
            if (!include_dirty || !clean) && (!include_conflicts || has_conflicts) {
                break;
            }
        }

        Ok((clean, has_conflicts))
    }

    /// Compute remote status - ahead/behind counts and upstream existence
    fn compute_remote_status(
        &self,
        repo: &Repository,
        branch_name: &str,
        remote_override: &Option<String>,
        local_oid: Oid,
        detached: bool,
    ) -> Result<(usize, usize, bool), GitError> {
        // Try to find upstream reference
        let upstream_ref = self.find_upstream_ref(repo, branch_name, remote_override, detached)?;
        
        match upstream_ref {
            Some(upstream_oid) => {
                let (ahead, behind) = repo
                    .graph_ahead_behind(local_oid, upstream_oid)
                    .map_err(|e| GitError::StatusShortFailed {
                        message: format!("failed to compute ahead/behind: {}", e),
                    })?;
                
                Ok((ahead, behind, true))
            }
            None => Ok((0, 0, false)),
        }
    }

    /// Find upstream reference OID
    fn find_upstream_ref(
        &self,
        repo: &Repository,
        branch_name: &str,
        remote_override: &Option<String>,
        detached: bool,
    ) -> Result<Option<Oid>, GitError> {
        if detached {
            // For detached HEAD, no upstream tracking
            return Ok(None);
        }

        // Try branch's configured upstream first
        if let Ok(branch) = repo.find_branch(branch_name, BranchType::Local) {
            if let Ok(upstream_branch) = branch.upstream() {
                if let Some(target) = upstream_branch.get().target() {
                    return Ok(Some(target));
                }
            }
        }

        // Try specified remote
        let remote_name = remote_override.as_deref().unwrap_or("origin");
        let upstream_ref_name = format!("refs/remotes/{}/{}", remote_name, branch_name);
        
        if let Ok(upstream_ref) = repo.find_reference(&upstream_ref_name) {
            if let Some(target) = upstream_ref.target() {
                return Ok(Some(target));
            }
        }

        Ok(None)
    }

    /// Build summary string following the specified format
    fn build_summary_string(
        &self,
        branch_name: &str,
        detached: bool,
        ahead: usize,
        behind: usize,
        has_upstream: bool,
        clean: bool,
        has_conflicts: bool,
        symbols: &StatusShortSymbols,
        config: &StatusShortConfig,
    ) -> String {
        let mut summary = String::new();

        // 1. Branch name or detached indicator
        summary.push_str(branch_name);
        if detached {
            if let Some(ref detached_symbol) = symbols.detached {
                summary.push_str(detached_symbol);
            }
        }

        // 2. Remote part (arrows)
        if config.include_remote.unwrap_or(true) {
            if has_upstream {
                if ahead > 0 {
                    if let Some(ref ahead_symbol) = symbols.ahead {
                        summary.push_str(ahead_symbol);
                        summary.push_str(&ahead.to_string());
                    }
                }
                if behind > 0 {
                    if let Some(ref behind_symbol) = symbols.behind {
                        summary.push_str(behind_symbol);
                        summary.push_str(&behind.to_string());
                    }
                }
            } else {
                // No upstream - show no_upstream symbol
                if let Some(ref no_upstream_symbol) = symbols.no_upstream {
                    summary.push_str(no_upstream_symbol);
                }
            }
        }

        // 3. Dirty part
        if config.include_dirty.unwrap_or(true) && !clean {
            if let Some(ref dirty_symbol) = symbols.dirty {
                summary.push_str(dirty_symbol);
            }
        }

        // 4. Conflict part
        if config.include_conflicts.unwrap_or(true) && has_conflicts {
            if let Some(ref conflict_symbol) = symbols.conflict {
                summary.push_str(conflict_symbol);
            }
        }

        summary
    }
}

impl Handle for GitHandle {
    fn verbs(&self) -> &'static [&'static str] {
        &["clone", "pull", "push", "status", "branch", "commit", "diff", "tag", "merge", "rebase", "sync", "status_summary", "status_short"]
    }

    fn call(&self, verb: &str, args: &Args, _io: &mut IoStreams) -> Result<Status> {
        match verb {
            "clone" => {
                // Convert Args to Value for async processing
                let args_value = serde_json::to_value(args)
                    .context("failed to serialize clone arguments")?;

                // For now, we need to handle async in sync context
                // This is a limitation we'll need to address with the registry design
                let runtime = tokio::runtime::Builder::new_current_thread()
                    .enable_all()
                    .build()
                    .context("failed to create tokio runtime")?;

                let result = runtime.block_on(async {
                    self.clone(args_value).await
                });

                match result {
                    Ok(value) => {
                        println!("{}", serde_json::to_string_pretty(&value)?);
                        Ok(Status::success())
                    }
                    Err(git_err) => {
                        let shell_err: crate::core::status::ShellError = git_err.into();
                        Err(shell_err.into())
                    }
                }
            }
            "pull" => {
                // Convert Args to Value for async processing
                let args_value = serde_json::to_value(args)
                    .context("failed to serialize pull arguments")?;

                let runtime = tokio::runtime::Builder::new_current_thread()
                    .enable_all()
                    .build()
                    .context("failed to create tokio runtime")?;

                let result = runtime.block_on(async {
                    self.pull(args_value).await
                });

                match result {
                    Ok(value) => {
                        println!("{}", serde_json::to_string_pretty(&value)?);
                        Ok(Status::success())
                    }
                    Err(git_err) => {
                        let shell_err: crate::core::status::ShellError = git_err.into();
                        Err(shell_err.into())
                    }
                }
            }
            "push" => {
                // Convert Args to Value for async processing
                let args_value = serde_json::to_value(args)
                    .context("failed to serialize push arguments")?;

                let runtime = tokio::runtime::Builder::new_current_thread()
                    .enable_all()
                    .build()
                    .context("failed to create tokio runtime")?;

                let result = runtime.block_on(async {
                    self.push(args_value).await
                });

                match result {
                    Ok(value) => {
                        println!("{}", serde_json::to_string_pretty(&value)?);
                        Ok(Status::success())
                    }
                    Err(git_err) => {
                        let shell_err: crate::core::status::ShellError = git_err.into();
                        Err(shell_err.into())
                    }
                }
            }
            "status" => {
                // Convert Args to Value for async processing
                let args_value = serde_json::to_value(args)
                    .context("failed to serialize status arguments")?;

                let runtime = tokio::runtime::Builder::new_current_thread()
                    .enable_all()
                    .build()
                    .context("failed to create tokio runtime")?;

                let result = runtime.block_on(async {
                    self.status(args_value).await
                });

                match result {
                    Ok(value) => {
                        println!("{}", serde_json::to_string_pretty(&value)?);
                        Ok(Status::success())
                    }
                    Err(git_err) => {
                        let shell_err: crate::core::status::ShellError = git_err.into();
                        Err(shell_err.into())
                    }
                }
            }
            "branch" => {
                // Convert Args to Value for async processing
                let args_value = serde_json::to_value(args)
                    .context("failed to serialize branch arguments")?;

                let runtime = tokio::runtime::Builder::new_current_thread()
                    .enable_all()
                    .build()
                    .context("failed to create tokio runtime")?;

                let result = runtime.block_on(async {
                    self.branch(args_value).await
                });

                match result {
                    Ok(value) => {
                        println!("{}", serde_json::to_string_pretty(&value)?);
                        Ok(Status::success())
                    }
                    Err(git_err) => {
                        let shell_err: crate::core::status::ShellError = git_err.into();
                        Err(shell_err.into())
                    }
                }
            }
            "commit" => {
                // Convert Args to Value for async processing
                let args_value = serde_json::to_value(args)
                    .context("failed to serialize commit arguments")?;

                let runtime = tokio::runtime::Builder::new_current_thread()
                    .enable_all()
                    .build()
                    .context("failed to create tokio runtime")?;

                let result = runtime.block_on(async {
                    self.commit(args_value).await
                });

                match result {
                    Ok(value) => {
                        println!("{}", serde_json::to_string_pretty(&value)?);
                        Ok(Status::success())
                    }
                    Err(git_err) => {
                        let shell_err: crate::core::status::ShellError = git_err.into();
                        Err(shell_err.into())
                    }
                }
            }
            "diff" => {
                // Convert Args to Value for async processing
                let args_value = serde_json::to_value(args)
                    .context("failed to serialize diff arguments")?;

                let runtime = tokio::runtime::Builder::new_current_thread()
                    .enable_all()
                    .build()
                    .context("failed to create tokio runtime")?;

                let result = runtime.block_on(async {
                    self.diff(args_value).await
                });

                match result {
                    Ok(value) => {
                        println!("{}", serde_json::to_string_pretty(&value)?);
                        Ok(Status::success())
                    }
                    Err(git_err) => {
                        let shell_err: crate::core::status::ShellError = git_err.into();
                        Err(shell_err.into())
                    }
                }
            }
            "tag" => {
                // Convert Args to Value for async processing
                let args_value = serde_json::to_value(args)
                    .context("failed to serialize tag arguments")?;

                let runtime = tokio::runtime::Builder::new_current_thread()
                    .enable_all()
                    .build()
                    .context("failed to create tokio runtime")?;

                let result = runtime.block_on(async {
                    self.tag(args_value).await
                });

                match result {
                    Ok(value) => {
                        println!("{}", serde_json::to_string_pretty(&value)?);
                        Ok(Status::success())
                    }
                    Err(git_err) => {
                        let shell_err: crate::core::status::ShellError = git_err.into();
                        Err(shell_err.into())
                    }
                }
            }
            "merge" => {
                // Convert Args to Value for async processing
                let args_value = serde_json::to_value(args)
                    .context("failed to serialize merge arguments")?;

                let runtime = tokio::runtime::Builder::new_current_thread()
                    .enable_all()
                    .build()
                    .context("failed to create tokio runtime")?;

                let result = runtime.block_on(async {
                    self.merge(args_value).await
                });

                match result {
                    Ok(value) => {
                        println!("{}", serde_json::to_string_pretty(&value)?);
                        Ok(Status::success())
                    }
                    Err(git_err) => {
                        let shell_err: crate::core::status::ShellError = git_err.into();
                        Err(shell_err.into())
                    }
                }
            }
            "rebase" => {
                // Convert Args to Value for async processing
                let args_value = serde_json::to_value(args)
                    .context("failed to serialize rebase arguments")?;

                let runtime = tokio::runtime::Builder::new_current_thread()
                    .enable_all()
                    .build()
                    .context("failed to create tokio runtime")?;

                let result = runtime.block_on(async {
                    self.rebase(args_value).await
                });

                match result {
                    Ok(value) => {
                        println!("{}", serde_json::to_string_pretty(&value)?);
                        Ok(Status::success())
                    }
                    Err(git_err) => {
                        let shell_err: crate::core::status::ShellError = git_err.into();
                        Err(shell_err.into())
                    }
                }
            }
            "sync" => {
                // Convert Args to Value for async processing
                let args_value = serde_json::to_value(args)
                    .context("failed to serialize sync arguments")?;

                let runtime = tokio::runtime::Builder::new_current_thread()
                    .enable_all()
                    .build()
                    .context("failed to create tokio runtime")?;

                let result = runtime.block_on(async {
                    self.sync(args_value).await
                });

                match result {
                    Ok(value) => {
                        println!("{}", serde_json::to_string_pretty(&value)?);
                        Ok(Status::success())
                    }
                    Err(git_err) => {
                        let shell_err: crate::core::status::ShellError = git_err.into();
                        Err(shell_err.into())
                    }
                }
            }
            "status_summary" => {
                // Convert Args to Value for async processing
                let args_value = serde_json::to_value(args)
                    .context("failed to serialize status_summary arguments")?;

                let runtime = tokio::runtime::Builder::new_current_thread()
                    .enable_all()
                    .build()
                    .context("failed to create tokio runtime")?;

                let result = runtime.block_on(async {
                    self.status_summary(args_value).await
                });

                match result {
                    Ok(value) => {
                        println!("{}", serde_json::to_string_pretty(&value)?);
                        Ok(Status::success())
                    }
                    Err(git_err) => {
                        let shell_err: crate::core::status::ShellError = git_err.into();
                        Err(shell_err.into())
                    }
                }
            }
            "status_short" => {
                // Convert Args to Value for async processing
                let args_value = serde_json::to_value(args)
                    .context("failed to serialize status_short arguments")?;

                let runtime = tokio::runtime::Builder::new_current_thread()
                    .enable_all()
                    .build()
                    .context("failed to create tokio runtime")?;

                let result = runtime.block_on(async {
                    self.status_short(args_value).await
                });

                match result {
                    Ok(value) => {
                        println!("{}", serde_json::to_string_pretty(&value)?);
                        Ok(Status::success())
                    }
                    Err(git_err) => {
                        let shell_err: crate::core::status::ShellError = git_err.into();
                        Err(shell_err.into())
                    }
                }
            }
            _ => anyhow::bail!("unknown verb for git://: {}", verb),
        }
    }
}

/// Register git:// scheme with the registry
pub fn register(reg: &mut crate::core::Registry) {
    reg.register_scheme("git", |u| Ok(Box::new(GitHandle::from_url(u.clone())?)));
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::collections::HashMap;
    use tempfile::TempDir;

    // Helper to create test arguments
    fn create_test_args() -> HashMap<String, String> {
        let mut args = HashMap::new();
        args.insert("url".to_string(), "https://github.com/test/repo.git".to_string());
        args.insert("path".to_string(), "/tmp/test_repo".to_string());
        args
    }

    #[test]
    fn test_git_handle_from_url() {
        let url = Url::parse("git://main").unwrap();
        println!("Parsed URL: {:?}, path: {:?}", url, url.path());
        let handle = GitHandle::from_url(url).unwrap();
        assert_eq!(handle.alias, "main");

        let url = Url::parse("git://deploy_bot").unwrap();
        println!("Parsed URL: {:?}, path: {:?}", url, url.path());
        let handle = GitHandle::from_url(url).unwrap();
        assert_eq!(handle.alias, "deploy_bot");

        // For a URL like git:// with no host or path, we should get default
        let url = Url::parse("git:///").unwrap();
        println!("Parsed URL: {:?}, path: {:?}", url, url.path());
        let handle = GitHandle::from_url(url).unwrap();
        assert_eq!(handle.alias, "default");
        
        // For a path-based alias
        let url = Url::parse("git:///my_alias").unwrap();
        println!("Parsed URL: {:?}, path: {:?}", url, url.path());
        let handle = GitHandle::from_url(url).unwrap();
        assert_eq!(handle.alias, "my_alias");
    }

    #[test]
    fn test_invalid_url() {
        let url = Url::parse("git:///").unwrap();
        let handle = GitHandle::from_url(url).unwrap();
        assert_eq!(handle.alias, "default");
    }

    #[test]
    fn test_clone_config_validation() {
        let handle = GitHandle { alias: "test".to_string() };

        // Valid configuration
        let config = CloneConfig {
            url: "https://github.com/test/repo.git".to_string(),
            path: "/tmp/test".to_string(),
            branch: None,
            depth: None,
            recursive: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };
        assert!(handle.validate_clone_config(&config).is_ok());

        // Empty URL
        let mut config = config.clone();
        config.url = "".to_string();
        assert!(matches!(handle.validate_clone_config(&config), Err(GitError::InvalidCloneConfig { .. })));

        // Empty path
        let mut config = CloneConfig {
            url: "https://github.com/test/repo.git".to_string(),
            path: "".to_string(),
            branch: None,
            depth: None,
            recursive: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };
        assert!(matches!(handle.validate_clone_config(&config), Err(GitError::InvalidCloneConfig { .. })));

        // Invalid depth
        let mut config = CloneConfig {
            url: "https://github.com/test/repo.git".to_string(),
            path: "/tmp/test".to_string(),
            branch: None,
            depth: Some(0),
            recursive: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };
        assert!(matches!(handle.validate_clone_config(&config), Err(GitError::InvalidCloneConfig { .. })));

        // Invalid timeout
        let mut config = CloneConfig {
            url: "https://github.com/test/repo.git".to_string(),
            path: "/tmp/test".to_string(),
            branch: None,
            depth: None,
            recursive: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: Some(0),
        };
        assert!(matches!(handle.validate_clone_config(&config), Err(GitError::InvalidCloneConfig { .. })));

        // Multiple auth methods
        let mut config = CloneConfig {
            url: "https://github.com/test/repo.git".to_string(),
            path: "/tmp/test".to_string(),
            branch: None,
            depth: None,
            recursive: None,
            ssh_key: Some("key".to_string()),
            username: Some("user".to_string()),
            password: Some("pass".to_string()),
            token: None,
            timeout_ms: None,
        };
        assert!(matches!(handle.validate_clone_config(&config), Err(GitError::InvalidCloneConfig { .. })));

        // Invalid URL protocol
        let mut config = CloneConfig {
            url: "ftp://invalid.git".to_string(),
            path: "/tmp/test".to_string(),
            branch: None,
            depth: None,
            recursive: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };
        assert!(matches!(handle.validate_clone_config(&config), Err(GitError::InvalidCloneConfig { .. })));
    }

    #[test]
    fn test_clone_config_parsing() {
        let handle = GitHandle { alias: "test".to_string() };

        let args = json!({
            "url": "https://github.com/test/repo.git",
            "path": "/tmp/test",
            "branch": "main",
            "depth": 1,
            "recursive": true,
            "timeout_ms": 30000
        });

        let config = handle.parse_clone_config(args).unwrap();
        assert_eq!(config.url, "https://github.com/test/repo.git");
        assert_eq!(config.path, "/tmp/test");
        assert_eq!(config.branch, Some("main".to_string()));
        assert_eq!(config.depth, Some(1));
        assert_eq!(config.recursive, Some(true));
        assert_eq!(config.timeout_ms, Some(30000));
    }

    #[test]
    fn test_connection_not_found() {
        let handle = GitHandle { alias: "nonexistent".to_string() };
        let result = handle.load_connection_profile();
        assert!(matches!(result, Err(GitError::ConnectionNotFound { .. })));
    }

    #[test]
    fn test_auth_validation_single_methods() {
        let handle = GitHandle { alias: "test".to_string() };

        // SSH key only
        let config = CloneConfig {
            url: "git@github.com:test/repo.git".to_string(),
            path: "/tmp/test".to_string(),
            branch: None,
            depth: None,
            recursive: None,
            ssh_key: Some("/path/to/key".to_string()),
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };
        assert!(handle.validate_clone_config(&config).is_ok());

        // Username/password only
        let config = CloneConfig {
            url: "https://github.com/test/repo.git".to_string(),
            path: "/tmp/test".to_string(),
            branch: None,
            depth: None,
            recursive: None,
            ssh_key: None,
            username: Some("user".to_string()),
            password: Some("pass".to_string()),
            token: None,
            timeout_ms: None,
        };
        assert!(handle.validate_clone_config(&config).is_ok());

        // Token only
        let config = CloneConfig {
            url: "https://github.com/test/repo.git".to_string(),
            path: "/tmp/test".to_string(),
            branch: None,
            depth: None,
            recursive: None,
            ssh_key: None,
            username: None,
            password: None,
            token: Some("token123".to_string()),
            timeout_ms: None,
        };
        assert!(handle.validate_clone_config(&config).is_ok());
    }

    #[tokio::test]
    async fn test_clone_target_directory_check() {
        let handle = GitHandle { alias: "test".to_string() };
        
        // Create a temporary directory with a file in it
        let temp_dir = TempDir::new().unwrap();
        let target_path = temp_dir.path().join("existing");
        std::fs::create_dir(&target_path).unwrap();
        std::fs::write(target_path.join("file.txt"), "content").unwrap();

        let config = CloneConfig {
            url: "https://github.com/test/repo.git".to_string(),
            path: target_path.to_string_lossy().to_string(),
            branch: None,
            depth: None,
            recursive: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };

        let profile = GitConnectionProfile {
            ssh_key_path: None,
            known_hosts_path: None,
            username: None,
            password: None,
            token: None,
        };

        let result = handle.execute_clone(&config, &profile).await;
        assert!(matches!(result, Err(GitError::CloneTargetNotEmpty { .. })));
    }

    // Integration tests - these will be skipped if environment variables are not set
    #[tokio::test]
    async fn test_https_public_repo_integration() {
        let url = std::env::var("TEST_GIT_CLONE_HTTPS_URL");
        if url.is_err() {
            return; // Skip test if environment variable not set
        }

        let temp_dir = TempDir::new().unwrap();
        let target_path = temp_dir.path().join("cloned_repo");

        let handle = GitHandle { alias: "test".to_string() };
        
        // Register a default connection profile
        let profile = GitConnectionProfile {
            ssh_key_path: None,
            known_hosts_path: None,
            username: None,
            password: None,
            token: None,
        };
        GitHandle::register_connection("test".to_string(), profile);

        let config = CloneConfig {
            url: url.unwrap(),
            path: target_path.to_string_lossy().to_string(),
            branch: Some("main".to_string()),
            depth: None,
            recursive: Some(false),
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: Some(30000),
        };

        let profile = handle.load_connection_profile().unwrap();
        let result = handle.execute_clone(&config, &profile).await;
        
        if result.is_ok() {
            assert!(target_path.exists());
            assert!(target_path.join(".git").exists());
        } else {
            // Log the error but don't fail the test - network issues are common
            eprintln!("Clone failed (network issue?): {:?}", result);
        }
    }

    #[tokio::test] 
    async fn test_timeout_functionality() {
        let handle = GitHandle { alias: "test".to_string() };
        
        // Register a connection profile
        let profile = GitConnectionProfile {
            ssh_key_path: None,
            known_hosts_path: None,
            username: None,
            password: None,
            token: None,
        };
        GitHandle::register_connection("test".to_string(), profile);

        // Use an invalid/non-existent URL that will cause timeout or failure
        let args = json!({
            "url": "https://192.0.2.1/nonexistent.git", // RFC5737 test address
            "path": "/tmp/timeout_test",
            "timeout_ms": 100
        });

        let result = handle.clone(args).await;
        // Should either timeout or fail to clone - both are acceptable for this test
        assert!(result.is_err(), "Expected timeout or clone failure, got: {:?}", result);
    }

    // Pull validation tests
    #[test]
    fn test_pull_config_validation() {
        let handle = GitHandle { alias: "test".to_string() };

        // Valid configuration
        let config = PullConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            rebase: None,
            ff_only: None,
            depth: None,
            prune: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };
        // Note: This will fail because path doesn't exist - that's expected for this validation test
        let result = handle.validate_pull_config(&config);
        assert!(matches!(result, Err(GitError::RepositoryNotFound { .. })));

        // Empty path
        let mut config = config.clone();
        config.path = "".to_string();
        assert!(matches!(handle.validate_pull_config(&config), Err(GitError::InvalidPullConfig { .. })));

        // Invalid timeout
        let mut config = PullConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            rebase: None,
            ff_only: None,
            depth: None,
            prune: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: Some(0),
        };
        assert!(matches!(handle.validate_pull_config(&config), Err(GitError::InvalidPullConfig { .. })));

        // Invalid depth
        let mut config = PullConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            rebase: None,
            ff_only: None,
            depth: Some(0),
            prune: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };
        assert!(matches!(handle.validate_pull_config(&config), Err(GitError::InvalidPullConfig { .. })));

        // Empty remote string
        let mut config = PullConfig {
            path: "/tmp/test".to_string(),
            remote: Some("".to_string()),
            branch: None,
            rebase: None,
            ff_only: None,
            depth: None,
            prune: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };
        assert!(matches!(handle.validate_pull_config(&config), Err(GitError::InvalidPullConfig { .. })));

        // Empty branch string
        let mut config = PullConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: Some("".to_string()),
            rebase: None,
            ff_only: None,
            depth: None,
            prune: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };
        assert!(matches!(handle.validate_pull_config(&config), Err(GitError::InvalidPullConfig { .. })));

        // Multiple auth methods
        let mut config = PullConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            rebase: None,
            ff_only: None,
            depth: None,
            prune: None,
            ssh_key: Some("key".to_string()),
            username: Some("user".to_string()),
            password: Some("pass".to_string()),
            token: None,
            timeout_ms: None,
        };
        assert!(matches!(handle.validate_pull_config(&config), Err(GitError::InvalidPullConfig { .. })));
    }

    #[test]
    fn test_pull_config_parsing() {
        let handle = GitHandle { alias: "test".to_string() };

        let args = json!({
            "path": "/tmp/test",
            "remote": "origin",
            "branch": "main",
            "rebase": true,
            "ff_only": false,
            "depth": 5,
            "prune": true,
            "timeout_ms": 30000
        });

        let config = handle.parse_pull_config(args).unwrap();
        assert_eq!(config.path, "/tmp/test");
        assert_eq!(config.remote, Some("origin".to_string()));
        assert_eq!(config.branch, Some("main".to_string()));
        assert_eq!(config.rebase, Some(true));
        assert_eq!(config.ff_only, Some(false));
        assert_eq!(config.depth, Some(5));
        assert_eq!(config.prune, Some(true));
        assert_eq!(config.timeout_ms, Some(30000));
    }

    #[test]
    fn test_pull_auth_validation_single_methods() {
        let handle = GitHandle { alias: "test".to_string() };

        // SSH key only
        let config = PullConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            rebase: None,
            ff_only: None,
            depth: None,
            prune: None,
            ssh_key: Some("/path/to/key".to_string()),
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };
        let result = handle.validate_pull_config(&config);
        // Should fail due to path not existing, not auth validation
        assert!(matches!(result, Err(GitError::RepositoryNotFound { .. })));

        // Username/password only
        let config = PullConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            rebase: None,
            ff_only: None,
            depth: None,
            prune: None,
            ssh_key: None,
            username: Some("user".to_string()),
            password: Some("pass".to_string()),
            token: None,
            timeout_ms: None,
        };
        let result = handle.validate_pull_config(&config);
        assert!(matches!(result, Err(GitError::RepositoryNotFound { .. })));

        // Token only
        let config = PullConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            rebase: None,
            ff_only: None,
            depth: None,
            prune: None,
            ssh_key: None,
            username: None,
            password: None,
            token: Some("token123".to_string()),
            timeout_ms: None,
        };
        let result = handle.validate_pull_config(&config);
        assert!(matches!(result, Err(GitError::RepositoryNotFound { .. })));
    }

    #[tokio::test]
    async fn test_pull_repository_not_found() {
        let handle = GitHandle { alias: "test".to_string() };
        
        // Register a connection profile
        let profile = GitConnectionProfile {
            ssh_key_path: None,
            known_hosts_path: None,
            username: None,
            password: None,
            token: None,
        };
        GitHandle::register_connection("test".to_string(), profile);

        let config = PullConfig {
            path: "/nonexistent/path".to_string(),
            remote: None,
            branch: None,
            rebase: None,
            ff_only: None,
            depth: None,
            prune: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };

        let profile = handle.load_connection_profile().unwrap();
        let result = handle.execute_pull(&config, &profile).await;
        assert!(matches!(result, Err(GitError::RepositoryNotFound { .. })));
    }

    #[tokio::test]
    async fn test_pull_timeout() {
        let handle = GitHandle { alias: "test".to_string() };
        
        // Register a connection profile
        let profile = GitConnectionProfile {
            ssh_key_path: None,
            known_hosts_path: None,
            username: None,
            password: None,
            token: None,
        };
        GitHandle::register_connection("test".to_string(), profile);

        let args = json!({
            "path": "/nonexistent/path",
            "timeout_ms": 1  // Very short timeout
        });

        let result = handle.pull(args).await;
        // Should timeout since operation will fail/timeout before completion
        assert!(result.is_err());
    }

    // Integration tests for pull - these will be skipped if environment variables are not set
    #[tokio::test]
    async fn test_pull_https_integration() {
        let url = std::env::var("TEST_GIT_PULL_HTTPS_URL");
        let temp_base = std::env::var("TEST_GIT_PULL_TEMP_DIR");
        if url.is_err() || temp_base.is_err() {
            return; // Skip test if environment variables not set
        }

        let temp_dir = TempDir::new().unwrap();
        let clone_path = temp_dir.path().join("cloned_repo");

        let handle = GitHandle { alias: "test".to_string() };
        
        // Register a default connection profile
        let profile = GitConnectionProfile {
            ssh_key_path: None,
            known_hosts_path: None,
            username: None,
            password: None,
            token: None,
        };
        GitHandle::register_connection("test".to_string(), profile.clone());

        // First clone the repository
        let clone_config = CloneConfig {
            url: url.unwrap(),
            path: clone_path.to_string_lossy().to_string(),
            branch: Some("main".to_string()),
            depth: None,
            recursive: Some(false),
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: Some(30000),
        };

        let clone_result = handle.execute_clone(&clone_config, &profile).await;
        if clone_result.is_err() {
            // Skip test if clone fails - likely network issue
            eprintln!("Clone failed, skipping pull test: {:?}", clone_result);
            return;
        }

        // Now test pull on the cloned repository
        let pull_config = PullConfig {
            path: clone_path.to_string_lossy().to_string(),
            remote: Some("origin".to_string()),
            branch: Some("main".to_string()),
            rebase: Some(false),
            ff_only: Some(false),
            depth: None,
            prune: Some(false),
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: Some(30000),
        };

        let pull_result = handle.execute_pull(&pull_config, &profile).await;
        
        if pull_result.is_ok() {
            let result_value = pull_result.unwrap();
            let result: PullResult = serde_json::from_value(result_value).unwrap();
            assert_eq!(result.backend, "git");
            assert_eq!(result.alias, "test");
            assert_eq!(result.remote, "origin");
            assert_eq!(result.branch, "main");
            // Status should be "up_to_date" since we just cloned
            assert_eq!(result.status, "up_to_date");
        } else {
            // Log the error but don't fail the test - network issues are common
            eprintln!("Pull failed (network issue?): {:?}", pull_result);
        }
    }

    // Push validation tests
    #[test]
    fn test_push_config_validation() {
        let handle = GitHandle { alias: "test".to_string() };

        // Valid configuration
        let config = PushConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            branches: None,
            tags: None,
            force: None,
            ff_only: None,
            set_upstream: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };
        // Note: This will fail because path doesn't exist - that's expected for this validation test
        let result = handle.validate_push_config(&config);
        assert!(matches!(result, Err(GitError::RepositoryNotFound { .. })));

        // Empty path
        let mut config = config.clone();
        config.path = "".to_string();
        assert!(matches!(handle.validate_push_config(&config), Err(GitError::InvalidPushConfig { .. })));

        // Invalid timeout
        let mut config = PushConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            branches: None,
            tags: None,
            force: None,
            ff_only: None,
            set_upstream: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: Some(0),
        };
        assert!(matches!(handle.validate_push_config(&config), Err(GitError::InvalidPushConfig { .. })));

        // Both branch and branches provided
        let mut config = PushConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: Some("main".to_string()),
            branches: Some(vec!["main".to_string(), "develop".to_string()]),
            tags: None,
            force: None,
            ff_only: None,
            set_upstream: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };
        assert!(matches!(handle.validate_push_config(&config), Err(GitError::InvalidPushConfig { .. })));

        // Empty branches array
        let mut config = PushConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            branches: Some(vec![]),
            tags: None,
            force: None,
            ff_only: None,
            set_upstream: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };
        assert!(matches!(handle.validate_push_config(&config), Err(GitError::InvalidPushConfig { .. })));

        // force and ff_only both true
        let mut config = PushConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            branches: None,
            tags: None,
            force: Some(true),
            ff_only: Some(true),
            set_upstream: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };
        assert!(matches!(handle.validate_push_config(&config), Err(GitError::InvalidPushConfig { .. })));

        // Empty remote string
        let mut config = PushConfig {
            path: "/tmp/test".to_string(),
            remote: Some("".to_string()),
            branch: None,
            branches: None,
            tags: None,
            force: None,
            ff_only: None,
            set_upstream: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };
        assert!(matches!(handle.validate_push_config(&config), Err(GitError::InvalidPushConfig { .. })));

        // Multiple auth methods
        let mut config = PushConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            branches: None,
            tags: None,
            force: None,
            ff_only: None,
            set_upstream: None,
            ssh_key: Some("key".to_string()),
            username: Some("user".to_string()),
            password: Some("pass".to_string()),
            token: None,
            timeout_ms: None,
        };
        assert!(matches!(handle.validate_push_config(&config), Err(GitError::InvalidPushConfig { .. })));
    }

    #[test]
    fn test_push_config_parsing() {
        let handle = GitHandle { alias: "test".to_string() };

        let args = json!({
            "path": "/tmp/test",
            "remote": "origin",
            "branch": "main",
            "tags": true,
            "force": false,
            "ff_only": true,
            "set_upstream": true,
            "timeout_ms": 30000
        });

        let config = handle.parse_push_config(args).unwrap();
        assert_eq!(config.path, "/tmp/test");
        assert_eq!(config.remote, Some("origin".to_string()));
        assert_eq!(config.branch, Some("main".to_string()));
        assert_eq!(config.branches, None);
        assert_eq!(config.tags, Some(true));
        assert_eq!(config.force, Some(false));
        assert_eq!(config.ff_only, Some(true));
        assert_eq!(config.set_upstream, Some(true));
        assert_eq!(config.timeout_ms, Some(30000));
    }

    #[test]
    fn test_push_auth_validation_single_methods() {
        let handle = GitHandle { alias: "test".to_string() };

        // SSH key only
        let config = PushConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            branches: None,
            tags: None,
            force: None,
            ff_only: None,
            set_upstream: None,
            ssh_key: Some("/path/to/key".to_string()),
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };
        let result = handle.validate_push_config(&config);
        // Should fail due to path not existing, not auth validation
        assert!(matches!(result, Err(GitError::RepositoryNotFound { .. })));

        // Username/password only
        let config = PushConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            branches: None,
            tags: None,
            force: None,
            ff_only: None,
            set_upstream: None,
            ssh_key: None,
            username: Some("user".to_string()),
            password: Some("pass".to_string()),
            token: None,
            timeout_ms: None,
        };
        let result = handle.validate_push_config(&config);
        assert!(matches!(result, Err(GitError::RepositoryNotFound { .. })));

        // Token only
        let config = PushConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            branches: None,
            tags: None,
            force: None,
            ff_only: None,
            set_upstream: None,
            ssh_key: None,
            username: None,
            password: None,
            token: Some("token123".to_string()),
            timeout_ms: None,
        };
        let result = handle.validate_push_config(&config);
        assert!(matches!(result, Err(GitError::RepositoryNotFound { .. })));
    }

    #[tokio::test]
    async fn test_push_repository_not_found() {
        let handle = GitHandle { alias: "test".to_string() };
        
        // Register a connection profile
        let profile = GitConnectionProfile {
            ssh_key_path: None,
            known_hosts_path: None,
            username: None,
            password: None,
            token: None,
        };
        GitHandle::register_connection("test".to_string(), profile);

        let config = PushConfig {
            path: "/nonexistent/path".to_string(),
            remote: None,
            branch: None,
            branches: None,
            tags: None,
            force: None,
            ff_only: None,
            set_upstream: None,
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: None,
        };

        let profile = handle.load_connection_profile().unwrap();
        let result = handle.execute_push(&config, &profile).await;
        assert!(matches!(result, Err(GitError::RepositoryNotFound { .. })));
    }

    #[tokio::test]
    async fn test_push_timeout() {
        let handle = GitHandle { alias: "test".to_string() };
        
        // Register a connection profile
        let profile = GitConnectionProfile {
            ssh_key_path: None,
            known_hosts_path: None,
            username: None,
            password: None,
            token: None,
        };
        GitHandle::register_connection("test".to_string(), profile);

        let args = json!({
            "path": "/nonexistent/path",
            "timeout_ms": 1  // Very short timeout
        });

        let result = handle.push(args).await;
        // Should timeout since operation will fail/timeout before completion
        assert!(result.is_err());
    }

    // Integration tests for push - these will be skipped if environment variables are not set
    #[tokio::test]
    async fn test_push_https_integration() {
        let url = std::env::var("TEST_GIT_PUSH_HTTPS_URL");
        let temp_base = std::env::var("TEST_GIT_PUSH_TEMP_DIR");
        if url.is_err() || temp_base.is_err() {
            return; // Skip test if environment variables not set
        }

        let temp_dir = TempDir::new().unwrap();
        let clone_path = temp_dir.path().join("cloned_repo");

        let handle = GitHandle { alias: "test".to_string() };
        
        // Register a default connection profile
        let profile = GitConnectionProfile {
            ssh_key_path: None,
            known_hosts_path: None,
            username: None,
            password: None,
            token: None,
        };
        GitHandle::register_connection("test".to_string(), profile.clone());

        // First clone the repository
        let clone_config = CloneConfig {
            url: url.unwrap(),
            path: clone_path.to_string_lossy().to_string(),
            branch: Some("main".to_string()),
            depth: None,
            recursive: Some(false),
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: Some(30000),
        };

        let clone_result = handle.execute_clone(&clone_config, &profile).await;
        if clone_result.is_err() {
            // Skip test if clone fails - likely network issue
            eprintln!("Clone failed, skipping push test: {:?}", clone_result);
            return;
        }

        // Now test push on the cloned repository (should be up-to-date)
        let push_config = PushConfig {
            path: clone_path.to_string_lossy().to_string(),
            remote: Some("origin".to_string()),
            branch: Some("main".to_string()),
            branches: None,
            tags: Some(false),
            force: Some(false),
            ff_only: Some(false),
            set_upstream: Some(false),
            ssh_key: None,
            username: None,
            password: None,
            token: None,
            timeout_ms: Some(30000),
        };

        let push_result = handle.execute_push(&push_config, &profile).await;
        
        if push_result.is_ok() {
            let result_value = push_result.unwrap();
            let result: PushResult = serde_json::from_value(result_value).unwrap();
            assert_eq!(result.backend, "git");
            assert_eq!(result.alias, "test");
            assert_eq!(result.remote, "origin");
            assert_eq!(result.branches.len(), 1);
            assert_eq!(result.branches[0].name, "main");
            // Status should be "up_to_date" since we just cloned
            assert_eq!(result.branches[0].status, "up_to_date");
            assert_eq!(result.tags_pushed, false);
        } else {
            // Log the error but don't fail the test - network issues are common
            eprintln!("Push failed (network issue?): {:?}", push_result);
        }
    }

    // Status operation tests
    #[test]
    fn test_parse_status_config() {
        let handle = GitHandle { alias: "test".to_string() };
        
        // Valid config with all fields
        let args = json!({
            "path": "/tmp/test_repo",
            "include_ignored": true,
            "include_untracked": false,
            "include_staged": true,
            "include_branch": true,
            "include_remote": true,
            "timeout_ms": 10000
        });

        let config = handle.parse_status_config(args).unwrap();
        assert_eq!(config.path, "/tmp/test_repo");
        assert_eq!(config.include_ignored, Some(true));
        assert_eq!(config.include_untracked, Some(false));
        assert_eq!(config.include_staged, Some(true));
        assert_eq!(config.include_branch, Some(true));
        assert_eq!(config.include_remote, Some(true));
        assert_eq!(config.timeout_ms, Some(10000));

        // Minimal config with only required fields
        let args = json!({
            "path": "/tmp/test_repo"
        });

        let config = handle.parse_status_config(args).unwrap();
        assert_eq!(config.path, "/tmp/test_repo");
        assert_eq!(config.include_ignored, None);
        assert_eq!(config.include_untracked, None);
        assert_eq!(config.include_staged, None);
        assert_eq!(config.include_branch, None);
        assert_eq!(config.include_remote, None);
        assert_eq!(config.timeout_ms, None);
    }

    #[test]
    fn test_status_config_validation() {
        let handle = GitHandle { alias: "test".to_string() };
        
        // Test missing path
        let config = StatusConfig {
            path: "".to_string(),
            include_ignored: None,
            include_untracked: None,
            include_staged: None,
            include_branch: None,
            include_remote: None,
            timeout_ms: None,
        };
        
        let result = handle.validate_status_config(&config);
        assert!(matches!(result, Err(GitError::InvalidStatusConfig { .. })));

        // Test zero timeout
        let config = StatusConfig {
            path: "/tmp/test".to_string(),
            include_ignored: None,
            include_untracked: None,
            include_staged: None,
            include_branch: None,
            include_remote: None,
            timeout_ms: Some(0),
        };
        
        let result = handle.validate_status_config(&config);
        assert!(matches!(result, Err(GitError::InvalidStatusConfig { .. })));

        // Test nonexistent path
        let config = StatusConfig {
            path: "/nonexistent/path/that/should/not/exist".to_string(),
            include_ignored: None,
            include_untracked: None,
            include_staged: None,
            include_branch: None,
            include_remote: None,
            timeout_ms: Some(5000),
        };
        
        let result = handle.validate_status_config(&config);
        assert!(matches!(result, Err(GitError::RepositoryNotFound { .. })));
    }

    #[test]
    fn test_status_config_parsing_errors() {
        let handle = GitHandle { alias: "test".to_string() };

        // Test invalid JSON structure
        let args = json!({
            "timeout_ms": "not_a_number"
        });

        let result = handle.parse_status_config(args);
        assert!(matches!(result, Err(GitError::InvalidStatusConfig { .. })));

        // Test missing required path field when it becomes empty after parsing
        let args = json!({});

        // This should parse fine but validation should catch empty path
        if let Ok(config) = handle.parse_status_config(args) {
            // The config should have an empty path since it's required but not provided
            // Let's see what serde does with missing required fields
            assert!(config.path.is_empty());
        }
    }

    #[test]
    fn test_file_status_serialization() {
        let file_status = FileStatus {
            path: "src/main.rs".to_string(),
            status: "modified".to_string(),
        };

        let json = serde_json::to_value(&file_status).unwrap();
        assert_eq!(json["path"], "src/main.rs");
        assert_eq!(json["status"], "modified");

        // Test round-trip
        let deserialized: FileStatus = serde_json::from_value(json).unwrap();
        assert_eq!(deserialized.path, "src/main.rs");
        assert_eq!(deserialized.status, "modified");
    }

    #[test]
    fn test_branch_info_serialization() {
        let upstream = UpstreamInfo {
            name: "origin/main".to_string(),
            remote: "origin".to_string(),
            ahead_by: 2,
            behind_by: 1,
        };

        let branch_info = BranchInfo {
            name: Some("main".to_string()),
            detached: false,
            head: "abc123def456".to_string(),
            upstream: Some(upstream),
        };

        let json = serde_json::to_value(&branch_info).unwrap();
        assert_eq!(json["name"], "main");
        assert_eq!(json["detached"], false);
        assert_eq!(json["head"], "abc123def456");
        assert_eq!(json["upstream"]["name"], "origin/main");
        assert_eq!(json["upstream"]["remote"], "origin");
        assert_eq!(json["upstream"]["ahead_by"], 2);
        assert_eq!(json["upstream"]["behind_by"], 1);

        // Test detached head case
        let detached_branch = BranchInfo {
            name: None,
            detached: true,
            head: "abc123def456".to_string(),
            upstream: None,
        };

        let json = serde_json::to_value(&detached_branch).unwrap();
        assert!(json["name"].is_null());
        assert_eq!(json["detached"], true);
        assert!(json["upstream"].is_null());
    }

    #[test]
    fn test_working_tree_status_serialization() {
        let status = WorkingTreeStatus {
            clean: false,
            staged: vec![
                FileStatus { path: "file1.rs".to_string(), status: "modified".to_string() },
            ],
            unstaged: vec![
                FileStatus { path: "file2.rs".to_string(), status: "modified".to_string() },
            ],
            untracked: vec![
                FileStatus { path: "newfile.txt".to_string(), status: "untracked".to_string() },
            ],
            ignored: vec![],
            conflicts: vec![],
        };

        let json = serde_json::to_value(&status).unwrap();
        assert_eq!(json["clean"], false);
        assert_eq!(json["staged"].as_array().unwrap().len(), 1);
        assert_eq!(json["unstaged"].as_array().unwrap().len(), 1);
        assert_eq!(json["untracked"].as_array().unwrap().len(), 1);
        assert_eq!(json["ignored"].as_array().unwrap().len(), 0);
        assert_eq!(json["conflicts"].as_array().unwrap().len(), 0);
    }

    #[test]
    fn test_in_progress_flags_serialization() {
        let flags = InProgressFlags {
            merge: true,
            rebase: false,
            cherry_pick: false,
            revert: false,
            bisect: false,
        };

        let json = serde_json::to_value(&flags).unwrap();
        assert_eq!(json["merge"], true);
        assert_eq!(json["rebase"], false);
        assert_eq!(json["cherry_pick"], false);
        assert_eq!(json["revert"], false);
        assert_eq!(json["bisect"], false);
    }

    #[test]
    fn test_status_result_complete_serialization() {
        let upstream = UpstreamInfo {
            name: "origin/main".to_string(),
            remote: "origin".to_string(),
            ahead_by: 1,
            behind_by: 0,
        };

        let branch_info = BranchInfo {
            name: Some("main".to_string()),
            detached: false,
            head: "abc123def456".to_string(),
            upstream: Some(upstream),
        };

        let working_tree = WorkingTreeStatus {
            clean: false,
            staged: vec![
                FileStatus { path: "src/app.rs".to_string(), status: "modified".to_string() },
            ],
            unstaged: vec![],
            untracked: vec![
                FileStatus { path: "notes.txt".to_string(), status: "untracked".to_string() },
            ],
            ignored: vec![],
            conflicts: vec![],
        };

        let in_progress = InProgressFlags {
            merge: false,
            rebase: false,
            cherry_pick: false,
            revert: false,
            bisect: false,
        };

        let result = StatusResult {
            backend: "git".to_string(),
            alias: "default".to_string(),
            path: "/srv/app".to_string(),
            branch: Some(branch_info),
            working_tree,
            in_progress,
        };

        let json = serde_json::to_value(&result).unwrap();
        assert_eq!(json["backend"], "git");
        assert_eq!(json["alias"], "default");
        assert_eq!(json["path"], "/srv/app");
        assert_eq!(json["branch"]["name"], "main");
        assert_eq!(json["branch"]["detached"], false);
        assert_eq!(json["branch"]["upstream"]["ahead_by"], 1);
        assert_eq!(json["working_tree"]["clean"], false);
        assert_eq!(json["working_tree"]["staged"].as_array().unwrap().len(), 1);
        assert_eq!(json["working_tree"]["untracked"].as_array().unwrap().len(), 1);
        assert_eq!(json["in_progress"]["merge"], false);

        // Test round-trip serialization
        let pretty_json = serde_json::to_string_pretty(&result).unwrap();
        println!("Status result JSON:\n{}", pretty_json);

        let deserialized: StatusResult = serde_json::from_value(json).unwrap();
        assert_eq!(deserialized.backend, "git");
        assert_eq!(deserialized.alias, "default");
    }

    // Integration tests with real git repositories
    #[test]
    fn test_status_integration_clean_repo() {
        // Create a temporary directory and initialize a git repo
        let temp_dir = TempDir::new().unwrap();
        let repo_path = temp_dir.path();
        
        // Initialize git repository
        let repo = Repository::init(repo_path).unwrap();
        
        // Configure git user (required for commits)
        let mut config = repo.config().unwrap();
        config.set_str("user.name", "Test User").unwrap();
        config.set_str("user.email", "test@example.com").unwrap();

        // Create and commit an initial file
        let file_path = repo_path.join("README.md");
        std::fs::write(&file_path, "# Test Repository\nThis is a test.\n").unwrap();
        
        let mut index = repo.index().unwrap();
        index.add_path(Path::new("README.md")).unwrap();
        index.write().unwrap();
        
        let signature = git2::Signature::now("Test User", "test@example.com").unwrap();
        let tree_id = index.write_tree().unwrap();
        let tree = repo.find_tree(tree_id).unwrap();
        
        repo.commit(
            Some("HEAD"),
            &signature,
            &signature,
            "Initial commit",
            &tree,
            &[]
        ).unwrap();

        // Create GitHandle and test status
        GitHandle::register_connection("test".to_string(), GitConnectionProfile {
            ssh_key_path: None,
            known_hosts_path: None,
            username: None,
            password: None,
            token: None,
        });

        let handle = GitHandle { alias: "test".to_string() };
        let config = StatusConfig {
            path: repo_path.to_string_lossy().to_string(),
            include_ignored: Some(false),
            include_untracked: Some(true),
            include_staged: Some(true),
            include_branch: Some(true),
            include_remote: Some(false), // No remote configured
            timeout_ms: Some(5000),
        };

        // Test that validation passes
        handle.validate_status_config(&config).unwrap();

        // Test status execution
        let rt = tokio::runtime::Builder::new_current_thread()
            .enable_all()
            .build()
            .unwrap();

        let result = rt.block_on(async {
            handle.execute_status(&config).await
        }).unwrap();

        let status_result: StatusResult = serde_json::from_value(result).unwrap();
        
        // Verify basic structure
        assert_eq!(status_result.backend, "git");
        assert_eq!(status_result.alias, "test");
        assert!(status_result.working_tree.clean);
        assert!(status_result.working_tree.staged.is_empty());
        assert!(status_result.working_tree.unstaged.is_empty());
        assert!(status_result.working_tree.untracked.is_empty());
        assert!(status_result.working_tree.conflicts.is_empty());
        
        // Branch should not be detached and should be on main/master
        if let Some(branch) = status_result.branch {
            assert!(!branch.detached);
            assert!(branch.name.is_some());
            let branch_name = branch.name.unwrap();
            assert!(branch_name == "main" || branch_name == "master");
            assert!(branch.upstream.is_none()); // No remote configured
        }

        // No in-progress operations
        assert!(!status_result.in_progress.merge);
        assert!(!status_result.in_progress.rebase);
        assert!(!status_result.in_progress.cherry_pick);
        assert!(!status_result.in_progress.revert);
        assert!(!status_result.in_progress.bisect);
    }

    #[test]
    fn test_status_integration_with_changes() {
        // Create a temporary directory and initialize a git repo with changes
        let temp_dir = TempDir::new().unwrap();
        let repo_path = temp_dir.path();
        
        // Initialize git repository
        let repo = Repository::init(repo_path).unwrap();
        
        // Configure git user
        let mut config = repo.config().unwrap();
        config.set_str("user.name", "Test User").unwrap();
        config.set_str("user.email", "test@example.com").unwrap();

        // Create and commit an initial file
        let readme_path = repo_path.join("README.md");
        std::fs::write(&readme_path, "# Test Repository\nThis is a test.\n").unwrap();
        
        let mut index = repo.index().unwrap();
        index.add_path(Path::new("README.md")).unwrap();
        index.write().unwrap();
        
        let signature = git2::Signature::now("Test User", "test@example.com").unwrap();
        let tree_id = index.write_tree().unwrap();
        let tree = repo.find_tree(tree_id).unwrap();
        
        repo.commit(
            Some("HEAD"),
            &signature,
            &signature,
            "Initial commit",
            &tree,
            &[]
        ).unwrap();

        // Create various types of changes
        
        // 1. Modify existing file (unstaged)
        std::fs::write(&readme_path, "# Test Repository\nThis is a modified test.\nNew line added.\n").unwrap();
        
        // 2. Create new file and stage it
        let new_file_path = repo_path.join("new_file.txt");
        std::fs::write(&new_file_path, "This is a new file").unwrap();
        let mut index = repo.index().unwrap();
        index.add_path(Path::new("new_file.txt")).unwrap();
        index.write().unwrap();
        
        // 3. Create untracked file
        let untracked_path = repo_path.join("untracked.log");
        std::fs::write(&untracked_path, "Some log content").unwrap();
        
        // 4. Create gitignore and ignored file
        let gitignore_path = repo_path.join(".gitignore");
        std::fs::write(&gitignore_path, "*.tmp\ntarget/\n").unwrap();
        let ignored_path = repo_path.join("test.tmp");
        std::fs::write(&ignored_path, "Temporary file").unwrap();

        // Test status with all flags enabled
        GitHandle::register_connection("test2".to_string(), GitConnectionProfile {
            ssh_key_path: None,
            known_hosts_path: None,
            username: None,
            password: None,
            token: None,
        });

        let handle = GitHandle { alias: "test2".to_string() };
        let config = StatusConfig {
            path: repo_path.to_string_lossy().to_string(),
            include_ignored: Some(true),
            include_untracked: Some(true),
            include_staged: Some(true),
            include_branch: Some(true),
            include_remote: Some(false),
            timeout_ms: Some(5000),
        };

        let rt = tokio::runtime::Builder::new_current_thread()
            .enable_all()
            .build()
            .unwrap();

        let result = rt.block_on(async {
            handle.execute_status(&config).await
        }).unwrap();

        let status_result: StatusResult = serde_json::from_value(result).unwrap();
        
        // Verify the working tree is not clean
        assert!(!status_result.working_tree.clean);
        
        // Check that we have staged changes (new_file.txt)
        assert!(!status_result.working_tree.staged.is_empty());
        let staged_files: Vec<_> = status_result.working_tree.staged.iter().map(|f| &f.path).collect();
        assert!(staged_files.contains(&&"new_file.txt".to_string()));
        
        // Check that we have unstaged changes (README.md)
        assert!(!status_result.working_tree.unstaged.is_empty());
        let unstaged_files: Vec<_> = status_result.working_tree.unstaged.iter().map(|f| &f.path).collect();
        assert!(unstaged_files.contains(&&"README.md".to_string()));
        
        // Check that we have untracked files
        assert!(!status_result.working_tree.untracked.is_empty());
        let untracked_files: Vec<_> = status_result.working_tree.untracked.iter().map(|f| &f.path).collect();
        assert!(untracked_files.contains(&&"untracked.log".to_string()) || 
                untracked_files.contains(&&".gitignore".to_string()));
        
        // Check that we have ignored files (if include_ignored is true)
        let ignored_files: Vec<_> = status_result.working_tree.ignored.iter().map(|f| &f.path).collect();
        // The ignored file might or might not be detected depending on git2 behavior
        println!("Ignored files detected: {:?}", ignored_files);

        // Verify no conflicts
        assert!(status_result.working_tree.conflicts.is_empty());
    }

    #[test]
    fn test_status_integration_detached_head() {
        // Create a temporary directory and initialize a git repo
        let temp_dir = TempDir::new().unwrap();
        let repo_path = temp_dir.path();
        
        // Initialize git repository
        let repo = Repository::init(repo_path).unwrap();
        
        // Configure git user
        let mut config = repo.config().unwrap();
        config.set_str("user.name", "Test User").unwrap();
        config.set_str("user.email", "test@example.com").unwrap();

        // Create and commit initial files
        let file1_path = repo_path.join("file1.txt");
        std::fs::write(&file1_path, "Content 1").unwrap();
        
        let mut index = repo.index().unwrap();
        index.add_path(Path::new("file1.txt")).unwrap();
        index.write().unwrap();
        
        let signature = git2::Signature::now("Test User", "test@example.com").unwrap();
        let tree_id = index.write_tree().unwrap();
        let tree = repo.find_tree(tree_id).unwrap();
        
        let commit1 = repo.commit(
            Some("HEAD"),
            &signature,
            &signature,
            "First commit",
            &tree,
            &[]
        ).unwrap();

        // Create second commit
        let file2_path = repo_path.join("file2.txt");
        std::fs::write(&file2_path, "Content 2").unwrap();
        
        let mut index = repo.index().unwrap();
        index.add_path(Path::new("file2.txt")).unwrap();
        index.write().unwrap();
        
        let tree_id = index.write_tree().unwrap();
        let tree = repo.find_tree(tree_id).unwrap();
        let first_commit = repo.find_commit(commit1).unwrap();
        
        let commit2 = repo.commit(
            Some("HEAD"),
            &signature,
            &signature,
            "Second commit",
            &tree,
            &[&first_commit]
        ).unwrap();

        // Checkout the first commit (detached HEAD)
        let first_commit_obj = repo.find_commit(commit1).unwrap();
        repo.set_head_detached(commit1).unwrap();
        repo.checkout_head(Some(&mut git2::build::CheckoutBuilder::new())).unwrap();

        // Test status in detached HEAD state
        GitHandle::register_connection("test3".to_string(), GitConnectionProfile {
            ssh_key_path: None,
            known_hosts_path: None,
            username: None,
            password: None,
            token: None,
        });

        let handle = GitHandle { alias: "test3".to_string() };
        let config = StatusConfig {
            path: repo_path.to_string_lossy().to_string(),
            include_ignored: Some(false),
            include_untracked: Some(true),
            include_staged: Some(true),
            include_branch: Some(true),
            include_remote: Some(false),
            timeout_ms: Some(5000),
        };

        let rt = tokio::runtime::Builder::new_current_thread()
            .enable_all()
            .build()
            .unwrap();

        let result = rt.block_on(async {
            handle.execute_status(&config).await
        }).unwrap();

        let status_result: StatusResult = serde_json::from_value(result).unwrap();
        
        // Verify detached HEAD state
        if let Some(branch) = status_result.branch {
            assert!(branch.detached);
            assert!(branch.name.is_none());
            assert_eq!(branch.head, commit1.to_string());
            assert!(branch.upstream.is_none());
        } else {
            panic!("Expected branch information");
        }

        // Working tree should be clean in this case
        assert!(status_result.working_tree.clean);
    }

    #[test] 
    fn test_status_timeout() {
        GitHandle::register_connection("timeout_test".to_string(), GitConnectionProfile {
            ssh_key_path: None,
            known_hosts_path: None,
            username: None,
            password: None,
            token: None,
        });

        let handle = GitHandle { alias: "timeout_test".to_string() };
        
        // Use a very small timeout to trigger timeout
        let config = StatusConfig {
            path: "/tmp".to_string(), // This exists but is not a git repo
            include_ignored: Some(false),
            include_untracked: Some(true),
            include_staged: Some(true),
            include_branch: Some(true),
            include_remote: Some(false),
            timeout_ms: Some(1), // 1ms timeout - should be too fast
        };

        let rt = tokio::runtime::Builder::new_current_thread()
            .enable_all()
            .build()
            .unwrap();

        // This might timeout or might fail due to invalid repo - either is acceptable for this test
        let result = rt.block_on(async {
            handle.status(serde_json::to_value(config).unwrap()).await
        });

        // We expect either a timeout error or repository not found error
        match result {
            Err(GitError::StatusTimeout { timeout_ms: 1 }) => {
                // This is what we're testing for
            }
            Err(GitError::RepositoryNotFound { .. }) => {
                // This is also acceptable since /tmp is not a git repo
            }
            other => {
                println!("Unexpected result: {:?}", other);
                // Don't fail the test as timing can be unpredictable in CI environments
            }
        }
    }

    #[test]
    fn test_branch_config_parsing() {
        let handle = GitHandle { alias: "test".to_string() };

        // Test basic list action parsing
        let args = json!({
            "path": "/tmp/test_repo",
            "action": "list",
            "local_only": true
        });
        let config = handle.parse_branch_config(args).unwrap();
        assert_eq!(config.path, "/tmp/test_repo");
        assert_eq!(config.action, Some(BranchAction::List));
        assert_eq!(config.local_only, Some(true));

        // Test create action parsing
        let args = json!({
            "path": "/tmp/test_repo",
            "action": "create",
            "name": "feature/test",
            "start_point": "main"
        });
        let config = handle.parse_branch_config(args).unwrap();
        assert_eq!(config.action, Some(BranchAction::Create));
        assert_eq!(config.name, Some("feature/test".to_string()));
        assert_eq!(config.start_point, Some("main".to_string()));

        // Test defaults
        let args = json!({
            "path": "/tmp/test_repo"
        });
        let config = handle.parse_branch_config(args).unwrap();
        assert_eq!(config.action, None); // Should default to List
        assert_eq!(config.local_only, None); // Should default to true
        assert_eq!(config.remote_only, None); // Should default to false
        assert_eq!(config.all, None); // Should default to false
    }

    #[test]
    fn test_branch_config_validation() {
        let handle = GitHandle { alias: "test".to_string() };

        // Test missing path
        let config = BranchConfig {
            path: "".to_string(),
            action: Some(BranchAction::List),
            name: None,
            new_name: None,
            start_point: None,
            local_only: Some(true),
            remote_only: Some(false),
            all: Some(false),
            force: Some(false),
            track: Some(false),
            remote: None,
            timeout_ms: Some(5000),
        };
        let result = handle.validate_branch_config(&config);
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("path cannot be empty"));

        // Test invalid list flags
        let mut config = BranchConfig {
            path: "/tmp".to_string(),
            action: Some(BranchAction::List),
            name: None,
            new_name: None,
            start_point: None,
            local_only: Some(true),
            remote_only: Some(true), // Invalid: both local_only and remote_only
            all: Some(false),
            force: Some(false),
            track: Some(false),
            remote: None,
            timeout_ms: Some(5000),
        };
        let result = handle.validate_branch_config(&config);
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("invalid list flags"));

        // Test missing name for create action
        config = BranchConfig {
            path: "/tmp".to_string(),
            action: Some(BranchAction::Create),
            name: None, // Missing required name
            new_name: None,
            start_point: None,
            local_only: Some(false),
            remote_only: Some(false),
            all: Some(false),
            force: Some(false),
            track: Some(false),
            remote: None,
            timeout_ms: Some(5000),
        };
        let result = handle.validate_branch_config(&config);
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("name is required for create"));

        // Test missing new_name for rename action
        config = BranchConfig {
            path: "/tmp".to_string(),
            action: Some(BranchAction::Rename),
            name: Some("old".to_string()),
            new_name: None, // Missing required new_name
            start_point: None,
            local_only: Some(false),
            remote_only: Some(false),
            all: Some(false),
            force: Some(false),
            track: Some(false),
            remote: None,
            timeout_ms: Some(5000),
        };
        let result = handle.validate_branch_config(&config);
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("new_name is required for rename"));

        // Test same name and new_name for rename action
        config = BranchConfig {
            path: "/tmp".to_string(),
            action: Some(BranchAction::Rename),
            name: Some("same".to_string()),
            new_name: Some("same".to_string()), // Same as name
            start_point: None,
            local_only: Some(false),
            remote_only: Some(false),
            all: Some(false),
            force: Some(false),
            track: Some(false),
            remote: None,
            timeout_ms: Some(5000),
        };
        let result = handle.validate_branch_config(&config);
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("name and new_name cannot be the same"));
    }

    #[test]
    fn test_branch_action_serialization() {
        // Test that BranchAction can be serialized and deserialized properly
        let list_action = BranchAction::List;
        let json_str = serde_json::to_string(&list_action).unwrap();
        assert_eq!(json_str, "\"list\"");

        let create_action: BranchAction = serde_json::from_str("\"create\"").unwrap();
        assert_eq!(create_action, BranchAction::Create);

        // Test default
        let default_action = BranchAction::default();
        assert_eq!(default_action, BranchAction::List);
    }

    #[test]
    fn test_tag_action_serialization() {
        // Test that TagAction can be serialized and deserialized properly
        let list_action = TagAction::List;
        let json_str = serde_json::to_string(&list_action).unwrap();
        assert_eq!(json_str, "\"list\"");

        let create_action: TagAction = serde_json::from_str("\"create\"").unwrap();
        assert_eq!(create_action, TagAction::Create);

        let delete_action: TagAction = serde_json::from_str("\"delete\"").unwrap();
        assert_eq!(delete_action, TagAction::Delete);

        // Test default
        let default_action = TagAction::default();
        assert_eq!(default_action, TagAction::List);
    }

    #[test]
    fn test_tag_sort_serialization() {
        // Test that TagSort can be serialized and deserialized properly
        let name_sort = TagSort::Name;
        let json_str = serde_json::to_string(&name_sort).unwrap();
        assert_eq!(json_str, "\"name\"");

        let version_sort: TagSort = serde_json::from_str("\"version\"").unwrap();
        assert_eq!(version_sort, TagSort::Version);

        let tagger_sort: TagSort = serde_json::from_str("\"taggerdate\"").unwrap();
        assert_eq!(tagger_sort, TagSort::TaggerDate);

        let committer_sort: TagSort = serde_json::from_str("\"committerdate\"").unwrap();
        assert_eq!(committer_sort, TagSort::CommitterDate);

        // Test default
        let default_sort = TagSort::default();
        assert_eq!(default_sort, TagSort::Name);
    }

    #[test]
    fn test_parse_tag_config_validation() {
        let handle = GitHandle { alias: "test".to_string() };

        // Test missing path
        let args = json!({});
        let result = handle.parse_tag_config(args);
        assert!(result.is_ok()); // Path will be empty string, validated later
        
        let config = result.unwrap();
        let validation = handle.validate_tag_config(&config);
        assert!(validation.is_err());
        assert!(validation.unwrap_err().to_string().contains("path is required"));

        // Test timeout_ms = 0
        let args = json!({
            "path": "/tmp/test",
            "timeout_ms": 0
        });
        let result = handle.parse_tag_config(args).unwrap();
        let validation = handle.validate_tag_config(&result);
        assert!(validation.is_err());
        assert!(validation.unwrap_err().to_string().contains("timeout_ms must be greater than 0"));

        // Test invalid action
        let args = json!({
            "path": "/tmp/test",
            "action": "invalid"
        });
        let result = handle.parse_tag_config(args);
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("invalid action"));
    }

    #[test]
    fn test_validate_tag_config_create() {
        let handle = GitHandle { alias: "test".to_string() };

        // Test create action without name
        let mut config = TagConfig {
            path: "/tmp/test".to_string(),
            action: Some(TagAction::Create),
            name: None,
            names: None,
            pattern: None,
            sort: None,
            annotated: None,
            message: None,
            target: None,
            force: None,
            author_name: None,
            author_email: None,
            timestamp: None,
            timeout_ms: None,
        };
        let result = handle.validate_tag_config(&config);
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("name is required for create"));

        // Test create annotated tag without message
        config.name = Some("v1.0.0".to_string());
        config.annotated = Some(true);
        let result = handle.validate_tag_config(&config);
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("message is required for annotated"));

        // Test valid annotated tag
        config.message = Some("Release 1.0.0".to_string());
        let result = handle.validate_tag_config(&config);
        assert!(result.is_ok());

        // Test valid lightweight tag
        config.annotated = Some(false);
        config.message = None;
        let result = handle.validate_tag_config(&config);
        assert!(result.is_ok());
    }

    #[test]
    fn test_validate_tag_config_delete() {
        let handle = GitHandle { alias: "test".to_string() };

        // Test delete action without name or names
        let mut config = TagConfig {
            path: "/tmp/test".to_string(),
            action: Some(TagAction::Delete),
            name: None,
            names: None,
            pattern: None,
            sort: None,
            annotated: None,
            message: None,
            target: None,
            force: None,
            author_name: None,
            author_email: None,
            timestamp: None,
            timeout_ms: None,
        };
        let result = handle.validate_tag_config(&config);
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("either name or names is required"));

        // Test delete with empty names array
        config.names = Some(vec![]);
        let result = handle.validate_tag_config(&config);
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("names array cannot be empty"));

        // Test valid delete with name
        config.names = None;
        config.name = Some("v1.0.0".to_string());
        let result = handle.validate_tag_config(&config);
        assert!(result.is_ok());

        // Test valid delete with names
        config.name = None;
        config.names = Some(vec!["v1.0.0".to_string(), "v1.1.0".to_string()]);
        let result = handle.validate_tag_config(&config);
        assert!(result.is_ok());
    }

    #[test]
    fn test_compare_versions() {
        let handle = GitHandle { alias: "test".to_string() };

        // Test semantic version sorting
        assert_eq!(handle.compare_versions("v1.0.0", "v1.0.1"), std::cmp::Ordering::Less);
        assert_eq!(handle.compare_versions("v1.0.1", "v1.0.0"), std::cmp::Ordering::Greater);
        assert_eq!(handle.compare_versions("v1.0.0", "v1.0.0"), std::cmp::Ordering::Equal);

        // Test major version differences
        assert_eq!(handle.compare_versions("v1.9.9", "v2.0.0"), std::cmp::Ordering::Less);

        // Test minor version differences
        assert_eq!(handle.compare_versions("v1.1.0", "v1.2.0"), std::cmp::Ordering::Less);

        // Test version without 'v' prefix
        assert_eq!(handle.compare_versions("1.0.0", "1.0.1"), std::cmp::Ordering::Less);

        // Test versions with different lengths
        assert_eq!(handle.compare_versions("1.0", "1.0.1"), std::cmp::Ordering::Less);

        // Test non-numeric versions (fallback to string comparison)
        assert_eq!(handle.compare_versions("alpha", "beta"), std::cmp::Ordering::Less);
    }

    #[test]
    fn test_tag_timestamp_parsing() {
        let handle = GitHandle { alias: "test".to_string() };

        // Test ISO8601 timestamp parsing
        let args = json!({
            "path": "/tmp/test",
            "action": "create",
            "name": "v1.0.0",
            "annotated": true,
            "message": "Release",
            "timestamp": "2025-03-18T12:34:56Z"
        });
        let config = handle.parse_tag_config(args).unwrap();
        match config.timestamp {
            Some(TagTimestamp::Iso8601(ref iso_str)) => {
                assert_eq!(iso_str, "2025-03-18T12:34:56Z");
            }
            _ => panic!("Expected ISO8601 timestamp"),
        }

        // Test Unix timestamp parsing
        let args = json!({
            "path": "/tmp/test",
            "action": "create",
            "name": "v1.0.0",
            "annotated": true,
            "message": "Release",
            "timestamp": 1710759296
        });
        let config = handle.parse_tag_config(args).unwrap();
        match config.timestamp {
            Some(TagTimestamp::UnixSeconds(unix_secs)) => {
                assert_eq!(unix_secs, 1710759296);
            }
            _ => panic!("Expected Unix timestamp"),
        }
    }

    // Sync verb tests
    #[test]
    fn test_sync_config_validation() {
        let handle = GitHandle { alias: "test".to_string() };

        // Valid configuration
        let config = SyncConfig {
            path: "/tmp/test".to_string(),
            remote: Some("origin".to_string()),
            branch: Some("main".to_string()),
            remote_branch: None,
            pull_strategy: Some(PullStrategy::Rebase),
            ff_only: Some(false),
            allow_uncommitted: Some(false),
            stash_uncommitted: Some(false),
            abort_on_conflict: Some(true),
            push: Some(true),
            push_tags: Some(false),
            force_push: Some(false),
            set_upstream: Some(true),
            dry_run: Some(false),
            timeout_ms: Some(60000),
        };
        assert!(handle.validate_sync_config(&config).is_ok());

        // Empty path
        let mut config = config.clone();
        config.path = "".to_string();
        assert!(matches!(handle.validate_sync_config(&config), Err(GitError::InvalidSyncConfig { .. })));

        // Zero timeout
        let mut config = SyncConfig {
            path: "/tmp/test".to_string(),
            remote: Some("origin".to_string()),
            branch: Some("main".to_string()),
            remote_branch: None,
            pull_strategy: Some(PullStrategy::Rebase),
            ff_only: Some(false),
            allow_uncommitted: Some(false),
            stash_uncommitted: Some(false),
            abort_on_conflict: Some(true),
            push: Some(true),
            push_tags: Some(false),
            force_push: Some(false),
            set_upstream: Some(true),
            dry_run: Some(false),
            timeout_ms: Some(0),
        };
        assert!(matches!(handle.validate_sync_config(&config), Err(GitError::InvalidSyncConfig { .. })));

        // Empty remote
        let mut config = SyncConfig {
            path: "/tmp/test".to_string(),
            remote: Some("".to_string()),
            branch: Some("main".to_string()),
            remote_branch: None,
            pull_strategy: Some(PullStrategy::Rebase),
            ff_only: Some(false),
            allow_uncommitted: Some(false),
            stash_uncommitted: Some(false),
            abort_on_conflict: Some(true),
            push: Some(true),
            push_tags: Some(false),
            force_push: Some(false),
            set_upstream: Some(true),
            dry_run: Some(false),
            timeout_ms: Some(60000),
        };
        assert!(matches!(handle.validate_sync_config(&config), Err(GitError::InvalidSyncConfig { .. })));

        // Empty branch
        let mut config = SyncConfig {
            path: "/tmp/test".to_string(),
            remote: Some("origin".to_string()),
            branch: Some("".to_string()),
            remote_branch: None,
            pull_strategy: Some(PullStrategy::Rebase),
            ff_only: Some(false),
            allow_uncommitted: Some(false),
            stash_uncommitted: Some(false),
            abort_on_conflict: Some(true),
            push: Some(true),
            push_tags: Some(false),
            force_push: Some(false),
            set_upstream: Some(true),
            dry_run: Some(false),
            timeout_ms: Some(60000),
        };
        assert!(matches!(handle.validate_sync_config(&config), Err(GitError::InvalidSyncConfig { .. })));

        // Contradictory force_push and ff_only
        let mut config = SyncConfig {
            path: "/tmp/test".to_string(),
            remote: Some("origin".to_string()),
            branch: Some("main".to_string()),
            remote_branch: None,
            pull_strategy: Some(PullStrategy::Rebase),
            ff_only: Some(true),
            allow_uncommitted: Some(false),
            stash_uncommitted: Some(false),
            abort_on_conflict: Some(true),
            push: Some(true),
            push_tags: Some(false),
            force_push: Some(true),
            set_upstream: Some(true),
            dry_run: Some(false),
            timeout_ms: Some(60000),
        };
        assert!(matches!(handle.validate_sync_config(&config), Err(GitError::InvalidSyncConfig { .. })));
    }

    #[test]
    fn test_sync_config_parsing() {
        let handle = GitHandle { alias: "test".to_string() };

        // Test parsing from JSON
        let args = json!({
            "path": "/tmp/test",
            "remote": "origin",
            "branch": "main",
            "pull_strategy": "rebase",
            "push": true,
            "timeout_ms": 60000
        });

        let config = handle.parse_sync_config(args).unwrap();
        assert_eq!(config.path, "/tmp/test");
        assert_eq!(config.remote, Some("origin".to_string()));
        assert_eq!(config.branch, Some("main".to_string()));
        assert_eq!(config.pull_strategy, Some(PullStrategy::Rebase));
        assert_eq!(config.push, Some(true));
        assert_eq!(config.timeout_ms, Some(60000));
    }

    #[test]
    fn test_pull_strategy_default() {
        assert_eq!(PullStrategy::default(), PullStrategy::Rebase);
    }

    #[test]
    fn test_pull_strategy_serde() {
        // Test serialization/deserialization
        let rebase = PullStrategy::Rebase;
        let merge = PullStrategy::Merge;
        let ff_only = PullStrategy::FfOnly;

        // Test JSON serialization
        assert_eq!(serde_json::to_string(&rebase).unwrap(), "\"rebase\"");
        assert_eq!(serde_json::to_string(&merge).unwrap(), "\"merge\"");
        assert_eq!(serde_json::to_string(&ff_only).unwrap(), "\"ff_only\"");

        // Test JSON deserialization
        assert_eq!(serde_json::from_str::<PullStrategy>("\"rebase\"").unwrap(), PullStrategy::Rebase);
        assert_eq!(serde_json::from_str::<PullStrategy>("\"merge\"").unwrap(), PullStrategy::Merge);
        assert_eq!(serde_json::from_str::<PullStrategy>("\"ff_only\"").unwrap(), PullStrategy::FfOnly);
    }

    #[test]
    fn test_sync_error_conversion() {
        // Test that sync errors are properly converted to shell errors
        let sync_error = GitError::InvalidSyncConfig { message: "test message".to_string() };
        let shell_error: crate::core::status::ShellError = sync_error.into();
        assert_eq!(shell_error.code, "git.sync_invalid_config");
        assert!(shell_error.message.contains("test message"));

        let sync_error = GitError::SyncDetachedHead;
        let shell_error: crate::core::status::ShellError = sync_error.into();
        assert_eq!(shell_error.code, "git.sync_detached_head");

        let sync_error = GitError::SyncDirtyWorktree;
        let shell_error: crate::core::status::ShellError = sync_error.into();
        assert_eq!(shell_error.code, "git.sync_dirty_worktree");

        let sync_error = GitError::SyncTimeout { timeout_ms: 60000 };
        let shell_error: crate::core::status::ShellError = sync_error.into();
        assert_eq!(shell_error.code, "git.sync_timeout");
        assert_eq!(shell_error.details["timeout_ms"], 60000);
    }

    // Status summary tests
    #[test]
    fn test_status_summary_config_validation() {
        let handle = GitHandle { alias: "test".to_string() };

        // Valid configuration
        let config = StatusSummaryConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            include_untracked: Some(true),
            include_ignored: Some(false),
            include_remote: Some(true),
            compute_diffstats: Some(false),
            max_files: Some(500),
            timeout_ms: Some(5000),
        };
        assert!(handle.validate_status_summary_config(&config).is_ok());

        // Empty path
        let mut config = config.clone();
        config.path = "".to_string();
        assert!(matches!(handle.validate_status_summary_config(&config), Err(GitError::InvalidStatusSummaryConfig { .. })));

        // Zero timeout
        let mut config = StatusSummaryConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            include_untracked: Some(true),
            include_ignored: Some(false),
            include_remote: Some(true),
            compute_diffstats: Some(false),
            max_files: Some(500),
            timeout_ms: Some(0),
        };
        assert!(matches!(handle.validate_status_summary_config(&config), Err(GitError::InvalidStatusSummaryConfig { .. })));

        // Zero max_files
        let mut config = StatusSummaryConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: None,
            include_untracked: Some(true),
            include_ignored: Some(false),
            include_remote: Some(true),
            compute_diffstats: Some(false),
            max_files: Some(0),
            timeout_ms: Some(5000),
        };
        assert!(matches!(handle.validate_status_summary_config(&config), Err(GitError::InvalidStatusSummaryConfig { .. })));

        // Empty branch string
        let mut config = StatusSummaryConfig {
            path: "/tmp/test".to_string(),
            remote: None,
            branch: Some("".to_string()),
            include_untracked: Some(true),
            include_ignored: Some(false),
            include_remote: Some(true),
            compute_diffstats: Some(false),
            max_files: Some(500),
            timeout_ms: Some(5000),
        };
        assert!(matches!(handle.validate_status_summary_config(&config), Err(GitError::InvalidStatusSummaryConfig { .. })));

        // Empty remote string
        let mut config = StatusSummaryConfig {
            path: "/tmp/test".to_string(),
            remote: Some("".to_string()),
            branch: None,
            include_untracked: Some(true),
            include_ignored: Some(false),
            include_remote: Some(true),
            compute_diffstats: Some(false),
            max_files: Some(500),
            timeout_ms: Some(5000),
        };
        assert!(matches!(handle.validate_status_summary_config(&config), Err(GitError::InvalidStatusSummaryConfig { .. })));
    }

    #[test]
    fn test_status_summary_state_classification() {
        let handle = GitHandle { alias: "test".to_string() };

        // Test clean and synced state
        let working_tree = json!({
            "clean": true,
            "staged_count": 0,
            "unstaged_count": 0,
            "conflicts_count": 0,
            "in_progress": {
                "merge": false,
                "rebase": false,
                "cherry_pick": false,
                "revert": false,
                "bisect": false
            }
        });
        let sync_state = "in_sync";
        let summary = handle.compute_summary_flags(&working_tree, sync_state).unwrap();
        assert_eq!(summary["state"], "clean_and_synced");
        assert_eq!(summary["has_uncommitted_changes"], false);
        assert_eq!(summary["blocked_by_conflicts"], false);

        // Test local changes only
        let working_tree = json!({
            "clean": false,
            "staged_count": 2,
            "unstaged_count": 1,
            "conflicts_count": 0,
            "in_progress": {
                "merge": false,
                "rebase": false,
                "cherry_pick": false,
                "revert": false,
                "bisect": false
            }
        });
        let sync_state = "in_sync";
        let summary = handle.compute_summary_flags(&working_tree, sync_state).unwrap();
        assert_eq!(summary["state"], "local_changes_only");
        assert_eq!(summary["has_uncommitted_changes"], true);
        assert_eq!(summary["can_commit"], true);

        // Test ahead only state
        let working_tree = json!({
            "clean": true,
            "staged_count": 0,
            "unstaged_count": 0,
            "conflicts_count": 0,
            "in_progress": {
                "merge": false,
                "rebase": false,
                "cherry_pick": false,
                "revert": false,
                "bisect": false
            }
        });
        let sync_state = "ahead_only";
        let summary = handle.compute_summary_flags(&working_tree, sync_state).unwrap();
        assert_eq!(summary["state"], "committed_but_ahead");
        assert_eq!(summary["needs_push"], true);

        // Test conflicts present
        let working_tree = json!({
            "clean": false,
            "staged_count": 0,
            "unstaged_count": 0,
            "conflicts_count": 3,
            "in_progress": {
                "merge": true,
                "rebase": false,
                "cherry_pick": false,
                "revert": false,
                "bisect": false
            }
        });
        let sync_state = "in_sync";
        let summary = handle.compute_summary_flags(&working_tree, sync_state).unwrap();
        assert_eq!(summary["state"], "conflicts_present");
        assert_eq!(summary["blocked_by_conflicts"], true);

        // Test diverged state
        let working_tree = json!({
            "clean": true,
            "staged_count": 0,
            "unstaged_count": 0,
            "conflicts_count": 0,
            "in_progress": {
                "merge": false,
                "rebase": false,
                "cherry_pick": false,
                "revert": false,
                "bisect": false
            }
        });
        let sync_state = "diverged";
        let summary = handle.compute_summary_flags(&working_tree, sync_state).unwrap();
        assert_eq!(summary["state"], "diverged");
        assert_eq!(summary["needs_pull"], true);
        assert_eq!(summary["needs_push"], true);
    }

    #[test]
    fn test_status_summary_recommendations() {
        let handle = GitHandle { alias: "test".to_string() };

        // Test conflicts present recommendation
        let summary = json!({
            "state": "conflicts_present",
            "blocked_by_conflicts": true,
            "has_uncommitted_changes": true
        });
        let working_tree = json!({});
        let sync_state = "in_sync";
        let rec = handle.compute_recommendations(&summary, sync_state, &working_tree).unwrap();
        assert_eq!(rec["primary_action"], "resolve_conflicts");
        assert_eq!(rec["actions"].as_array().unwrap().len(), 2);

        // Test local changes recommendation
        let summary = json!({
            "state": "local_changes_only",
            "blocked_by_conflicts": false,
            "has_uncommitted_changes": true
        });
        let rec = handle.compute_recommendations(&summary, sync_state, &working_tree).unwrap();
        assert_eq!(rec["primary_action"], "commit");
        assert_eq!(rec["actions"].as_array().unwrap()[0], "commit_changes");

        // Test ahead only recommendation
        let summary = json!({
            "state": "committed_but_ahead",
            "blocked_by_conflicts": false,
            "has_uncommitted_changes": false
        });
        let rec = handle.compute_recommendations(&summary, sync_state, &working_tree).unwrap();
        assert_eq!(rec["primary_action"], "push");

        // Test behind remote recommendation
        let summary = json!({
            "state": "behind_remote",
            "blocked_by_conflicts": false,
            "has_uncommitted_changes": false
        });
        let rec = handle.compute_recommendations(&summary, sync_state, &working_tree).unwrap();
        assert_eq!(rec["primary_action"], "pull");

        // Test clean and synced recommendation
        let summary = json!({
            "state": "clean_and_synced",
            "blocked_by_conflicts": false,
            "has_uncommitted_changes": false
        });
        let rec = handle.compute_recommendations(&summary, sync_state, &working_tree).unwrap();
        assert_eq!(rec["primary_action"], "none");
        assert_eq!(rec["actions"].as_array().unwrap().len(), 0);
    }

    #[test]
    fn test_status_summary_error_conversion() {
        // Test status summary error conversion to shell errors
        let error = GitError::InvalidStatusSummaryConfig { message: "test message".to_string() };
        let shell_error: crate::core::status::ShellError = error.into();
        assert_eq!(shell_error.code, "git.invalid_status_summary_config");
        assert!(shell_error.message.contains("test message"));

        let error = GitError::StatusSummaryBranchNotFound { name: "feature-branch".to_string() };
        let shell_error: crate::core::status::ShellError = error.into();
        assert_eq!(shell_error.code, "git.status_summary_branch_not_found");
        assert_eq!(shell_error.details["name"], "feature-branch");

        let error = GitError::StatusSummaryTimeout { timeout_ms: 5000 };
        let shell_error: crate::core::status::ShellError = error.into();
        assert_eq!(shell_error.code, "git.status_summary_timeout");
        assert_eq!(shell_error.details["timeout_ms"], 5000);

        let error = GitError::StatusSummaryFailed { message: "git operation failed".to_string() };
        let shell_error: crate::core::status::ShellError = error.into();
        assert_eq!(shell_error.code, "git.status_summary_failed");
    }

    #[test]
    fn test_status_short_config_validation() {
        let handle = GitHandle { alias: "test".to_string() };

        // Valid configuration
        let config = StatusShortConfig {
            path: "/tmp/test".to_string(),
            branch: None,
            remote: None,
            include_remote: Some(true),
            include_dirty: Some(true),
            include_conflicts: Some(true),
            symbols: None,
            timeout_ms: Some(1000),
        };
        assert!(handle.validate_status_short_config(&config).is_ok());

        // Empty path
        let mut config = config.clone();
        config.path = "".to_string();
        assert!(matches!(handle.validate_status_short_config(&config), Err(GitError::InvalidStatusShortConfig { .. })));

        // Zero timeout
        let mut config = StatusShortConfig {
            path: "/tmp/test".to_string(),
            branch: None,
            remote: None,
            include_remote: Some(true),
            include_dirty: Some(true),
            include_conflicts: Some(true),
            symbols: None,
            timeout_ms: Some(0),
        };
        assert!(matches!(handle.validate_status_short_config(&config), Err(GitError::InvalidStatusShortConfig { .. })));

        // Empty branch string
        let mut config = StatusShortConfig {
            path: "/tmp/test".to_string(),
            branch: Some("".to_string()),
            remote: None,
            include_remote: Some(true),
            include_dirty: Some(true),
            include_conflicts: Some(true),
            symbols: None,
            timeout_ms: Some(1000),
        };
        assert!(matches!(handle.validate_status_short_config(&config), Err(GitError::InvalidStatusShortConfig { .. })));

        // Empty remote string
        let mut config = StatusShortConfig {
            path: "/tmp/test".to_string(),
            branch: None,
            remote: Some("".to_string()),
            include_remote: Some(true),
            include_dirty: Some(true),
            include_conflicts: Some(true),
            symbols: None,
            timeout_ms: Some(1000),
        };
        assert!(matches!(handle.validate_status_short_config(&config), Err(GitError::InvalidStatusShortConfig { .. })));
    }

    #[test]
    fn test_status_short_symbols_resolution() {
        let handle = GitHandle { alias: "test".to_string() };

        // Test default symbols
        let symbols = handle.resolve_status_short_symbols(&None);
        assert_eq!(symbols.detached.as_ref().unwrap(), "!");
        assert_eq!(symbols.ahead.as_ref().unwrap(), "");
        assert_eq!(symbols.behind.as_ref().unwrap(), "");
        assert_eq!(symbols.dirty.as_ref().unwrap(), "*");
        assert_eq!(symbols.conflict.as_ref().unwrap(), "");
        assert_eq!(symbols.no_upstream.as_ref().unwrap(), "");

        // Test partial custom symbols
        let custom = Some(StatusShortSymbols {
            detached: None,
            ahead: Some(">".to_string()),
            behind: None,
            dirty: Some("+".to_string()),
            conflict: None,
            no_upstream: None,
        });
        let symbols = handle.resolve_status_short_symbols(&custom);
        assert_eq!(symbols.detached.as_ref().unwrap(), "!"); // default
        assert_eq!(symbols.ahead.as_ref().unwrap(), ">"); // custom
        assert_eq!(symbols.behind.as_ref().unwrap(), ""); // default
        assert_eq!(symbols.dirty.as_ref().unwrap(), "+"); // custom
        assert_eq!(symbols.conflict.as_ref().unwrap(), ""); // default
        assert_eq!(symbols.no_upstream.as_ref().unwrap(), ""); // default
    }

    #[test]
    fn test_status_short_summary_string_building() {
        let handle = GitHandle { alias: "test".to_string() };
        let symbols = StatusShortSymbols {
            detached: Some("!".to_string()),
            ahead: Some("".to_string()),
            behind: Some("".to_string()),
            dirty: Some("*".to_string()),
            conflict: Some("".to_string()),
            no_upstream: Some("".to_string()),
        };
        
        let config = StatusShortConfig {
            path: "/tmp/test".to_string(),
            branch: None,
            remote: None,
            include_remote: Some(true),
            include_dirty: Some(true),
            include_conflicts: Some(true),
            symbols: None,
            timeout_ms: Some(1000),
        };

        // Clean branch, in sync
        let summary = handle.build_summary_string(
            "main", false, 0, 0, true, true, false, &symbols, &config
        );
        assert_eq!(summary, "main");

        // Dirty branch, in sync
        let summary = handle.build_summary_string(
            "main", false, 0, 0, true, false, false, &symbols, &config
        );
        assert_eq!(summary, "main*");

        // Clean branch, ahead by 1
        let summary = handle.build_summary_string(
            "main", false, 1, 0, true, true, false, &symbols, &config
        );
        assert_eq!(summary, "main1");

        // Clean branch, behind by 2
        let summary = handle.build_summary_string(
            "main", false, 0, 2, true, true, false, &symbols, &config
        );
        assert_eq!(summary, "main2");

        // Dirty branch, diverged
        let summary = handle.build_summary_string(
            "main", false, 1, 2, true, false, false, &symbols, &config
        );
        assert_eq!(summary, "main12*");

        // Detached head, clean, no upstream
        let summary = handle.build_summary_string(
            "HEAD", true, 0, 0, false, true, false, &symbols, &config
        );
        assert_eq!(summary, "HEAD!");

        // Clean branch with conflicts
        let summary = handle.build_summary_string(
            "main", false, 0, 0, true, true, true, &symbols, &config
        );
        assert_eq!(summary, "main");

        // Dirty branch with conflicts
        let summary = handle.build_summary_string(
            "main", false, 0, 0, true, false, true, &symbols, &config
        );
        assert_eq!(summary, "main*");

        // Test with include flags disabled
        let mut config_no_remote = config.clone();
        config_no_remote.include_remote = Some(false);
        let summary = handle.build_summary_string(
            "main", false, 1, 2, true, false, true, &symbols, &config_no_remote
        );
        assert_eq!(summary, "main*"); // No arrows

        let mut config_no_dirty = config.clone();
        config_no_dirty.include_dirty = Some(false);
        let summary = handle.build_summary_string(
            "main", false, 1, 2, true, false, true, &symbols, &config_no_dirty
        );
        assert_eq!(summary, "main12"); // No dirty marker

        let mut config_no_conflicts = config.clone();
        config_no_conflicts.include_conflicts = Some(false);
        let summary = handle.build_summary_string(
            "main", false, 1, 2, true, false, true, &symbols, &config_no_conflicts
        );
        assert_eq!(summary, "main12*"); // No conflict marker
    }

    #[test]
    fn test_status_short_error_conversion() {
        // Test status_short error conversion to shell errors
        let error = GitError::InvalidStatusShortConfig { message: "test message".to_string() };
        let shell_error: crate::core::status::ShellError = error.into();
        assert_eq!(shell_error.code, "git.invalid_status_short_config");
        assert!(shell_error.message.contains("test message"));

        let error = GitError::StatusShortBranchNotFound { branch: "feature-branch".to_string() };
        let shell_error: crate::core::status::ShellError = error.into();
        assert_eq!(shell_error.code, "git.status_short_branch_not_found");
        assert_eq!(shell_error.details["branch"], "feature-branch");

        let error = GitError::StatusShortTimeout { timeout_ms: 1000 };
        let shell_error: crate::core::status::ShellError = error.into();
        assert_eq!(shell_error.code, "git.status_short_timeout");
        assert_eq!(shell_error.details["timeout_ms"], 1000);

        let error = GitError::StatusShortFailed { message: "git operation failed".to_string() };
        let shell_error: crate::core::status::ShellError = error.into();
        assert_eq!(shell_error.code, "git.status_short_failed");
    }
}